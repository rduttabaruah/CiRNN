{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ab8b105c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8b105c",
        "outputId": "92da2849-7535-47c9-e9df-b00fc549d559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7aa6745ef7b0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import os\n",
        "seed = 40\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "\n",
        "import random\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.profiler\n",
        "import torch.autograd.profiler as profiler\n",
        "import sklearn.preprocessing as preprocess\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "import optuna\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6be63e",
      "metadata": {
        "id": "9c6be63e"
      },
      "source": [
        "# Context Integrated RNN - CiRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85c75a2",
      "metadata": {
        "id": "e85c75a2",
        "outputId": "7b93158f-017b-4782-ea43-78b28f928fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get CPU or GPU device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class ContextGRU(torch.nn.Module):\n",
        "    \"\"\"\n",
        "     simple GRU cell network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, context_dim):\n",
        "        super(ContextGRU, self).__init__()\n",
        "\n",
        "        self.n_x = input_dim\n",
        "        self.n_h = hidden_dim\n",
        "        self.n_y = output_dim\n",
        "        self.n_z = context_dim\n",
        "        #self.m = 9  #dimension of basis function vector (polynomial features) for 3 context features\n",
        "        self.m = 5  #dimension of basis function vector (polynomial features) for 2 context features\n",
        "\n",
        "\n",
        "        # reset gate components\n",
        "        self.linear_reset_w1 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r1 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "\n",
        "\n",
        "        self.linear_reset_w2 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r2 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_1 = nn.Sigmoid()\n",
        "\n",
        "        # update gate components\n",
        "        self.linear_gate_w3 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_gate_r3 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_2 = nn.Sigmoid()\n",
        "\n",
        "        self.activation_3 = nn.Tanh()\n",
        "\n",
        "        #output\n",
        "        self.linear_output = nn.Linear(self.n_h, self.n_y, bias=True)\n",
        "\n",
        "\n",
        "    def reset_gate(self, xg, h):  #xg is the kronecker product of x and  basis function G(z)\n",
        "        x_1 = self.linear_reset_w1(xg)\n",
        "        h_1 = self.linear_reset_r1(h)\n",
        "        # gate update\n",
        "        r = self.activation_1(x_1 + h_1)\n",
        "        return r\n",
        "\n",
        "    def update_gate(self, xg, h):\n",
        "        x_2 = self.linear_reset_w2(xg)\n",
        "        h_2 = self.linear_reset_r2(h)\n",
        "        s = self.activation_2( h_2 + x_2)\n",
        "        return s\n",
        "\n",
        "\n",
        "    def update_component(self, xg, h, r):\n",
        "        x_3 = self.linear_gate_w3(xg)\n",
        "        h_3 = r * self.linear_gate_r3(h)\n",
        "        h_tilda = self.activation_3(x_3+h_3)\n",
        "        return h_tilda\n",
        "\n",
        "\n",
        "    def compute_output(self,h):\n",
        "        y_pred = self.linear_output(h)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def cell_forward(self, x, h, G):\n",
        "\n",
        "        \"\"\"\n",
        "        Implements a single forward step of the Context GRU-cell\n",
        "\n",
        "        Input Arguments:\n",
        "            x (mini-batch): input x at time step t , (n,n_x) : (batch_size, input_dim)\n",
        "            h : hidden state at time step t-1, (n,n_h) : (batch_size, hidden_dim)\n",
        "            G : vector of basis funcitons (m,n)\n",
        "\n",
        "        Returns:\n",
        "            h_new: hidden state at time step t, (n,n_h)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # kronecker product of x and G(zt)\n",
        "        n = x.shape[0]\n",
        "        xg = torch.zeros(n,self.n_x*self.m).to(device)\n",
        "\n",
        "        for i in range(n):\n",
        "\n",
        "            xg[i,:] = torch.kron(x[i,:],G[:,i])\n",
        "\n",
        "\n",
        "        # Equation 1. reset gate vector\n",
        "        r = self.reset_gate(xg, h)\n",
        "\n",
        "        # Equation 2: the update gate - the shared update gate vector z\n",
        "        s = self.update_gate(xg, h)\n",
        "\n",
        "        # Equation 3: The almost output component\n",
        "        h_tilda = self.update_component(xg,h,r)\n",
        "\n",
        "        # Equation 4: the new hidden state\n",
        "        h_new = (1-s) * h_tilda  + s * h\n",
        "\n",
        "        #output\n",
        "\n",
        "        y_pred = self.compute_output(h)\n",
        "\n",
        "        return h_new, y_pred\n",
        "\n",
        "\n",
        "    def forward(self, x, z):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the forward propagation of the recurrent neural network\n",
        "\n",
        "        Input Arguments:\n",
        "        x (mini_batch): primary input for every time-step in mini-batches of shape (n, T, n_x)\n",
        "        z (mini_batch): context input for every time-step in mini-batches of shape (n,T,n_z)\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            h -- Hidden states for every time-step, numpy array of shape (n, T, n_h)\n",
        "            y_pred -- Predictions for every time-step, numpy array of shape (n, T, n_y),\n",
        "            here T is 1 for Seq to Vec RNN\n",
        "        \"\"\"\n",
        "\n",
        "        # Retrieve dimensions from shapes of x\n",
        "        #print(x.shape)\n",
        "        #print(z.shape)\n",
        "        n,T,n_x = x.shape\n",
        "        n_y = self.n_y\n",
        "        n_h = self.n_h\n",
        "        n_z = self.n_z\n",
        "\n",
        "\n",
        "\n",
        "        # initialize \"h\"\n",
        "\n",
        "        h = self.init_hidden(n,T,n_h)\n",
        "\n",
        "        #y_pred = np.zeros((m,T_x,n_y))\n",
        "        #y_pred is single value for one sample, m=1\n",
        "\n",
        "        #basis function vector\n",
        "        G = self.apply_basis(z[:,0,:])  #G: size of (n,m)\n",
        "\n",
        "        #for initial time step the hidden state is 0\n",
        "        h_temp = h.clone()\n",
        "        h_init = h_temp[:,0,:]\n",
        "        h_curr, y_curr = self.cell_forward(x[:,0,:],h_init,torch.t(G))\n",
        "\n",
        "        # loop over all time-steps\n",
        "        for t in range(1,T):\n",
        "\n",
        "            #compute the vector of basis functions\n",
        "\n",
        "            G = self.apply_basis(z[:,t,:])  #G: size of (n,m)\n",
        "\n",
        "            # Update next hidden state\n",
        "            # ignore yt_pred for seq to vector\n",
        "            h[:,t,:]= h_curr\n",
        "            h_temp = h.clone()\n",
        "            h_prev = h_temp[:,t,:]  #h_prev: (n,n_h)\n",
        "            h_curr, y_curr = self.cell_forward(x[:,t,:],h_prev, torch.t(G))\n",
        "\n",
        "            #y_pred[t,:] = yt_pred\n",
        "\n",
        "\n",
        "        #compute the predicted output from the last cell i.e at last time step T\n",
        "        y_pred = torch.zeros(n,1,1,device = 'cuda:0')\n",
        "\n",
        "        #get the value of y_pred from the last cell\n",
        "        y_pred[:,0,:] = y_curr\n",
        "\n",
        "        #print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "        return h, y_pred\n",
        "\n",
        "\n",
        "    def init_hidden(self, n:int,T:int, n_h:int):\n",
        "        #initialise the hidden state\n",
        "        #n : batch-size\n",
        "        #T : Input sequence length\n",
        "        #returns h of size (n,T,n_h)\n",
        "        return torch.zeros(n,T,n_h,device = 'cuda:0')\n",
        "\n",
        "\n",
        "    def apply_basis(self,zt):\n",
        "        '''\n",
        "        apply the basis function: polynomial degree 2\n",
        "        [z0, z1, z2, z0z0, z0z1, z0z2....]\n",
        "        input arguments:\n",
        "            zt: context vector (n,n_z) for mini-batch of size n and n_z context dim\n",
        "        Returns:\n",
        "            G : tensor of basis functions, (m,n)\n",
        "\n",
        "        for 3 context features m = 11\n",
        "        '''\n",
        "\n",
        "        #poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
        "        poly = PolynomialFeatures(2, include_bias=False)\n",
        "        G = torch.tensor(poly.fit_transform(zt.cpu().numpy())).to(device) #fit_transform returns nd array\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return G\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999d31f3",
      "metadata": {
        "id": "999d31f3"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train_step(self, x, y, z):\n",
        "\n",
        "       # with profiler.record_function(\"TRAIN STEP FUNCTION\"):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        h, yhat = self.model(x, z)\n",
        "\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        #with profiler.record_function(\"LOSS_BACKWARD\"):\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size, n_epochs=50, np_features=1, nc_features=1):\n",
        "        '''\n",
        "        np_features = # primary input features\n",
        "        nc_features = # context input features\n",
        "        '''\n",
        "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "        times = []\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "            start_epoch = time.time()\n",
        "\n",
        "            batch_losses = []\n",
        "            for x_batch, z_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.view([batch_size,-1, np_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                z_batch = z_batch.view([batch_size,-1, nc_features]).to(device)\n",
        "\n",
        "                #with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                loss = self.train_step(x_batch, y_batch, z_batch)\n",
        "                #print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                batch_losses.append(loss)\n",
        "\n",
        "\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, z_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, np_features]).to(device, non_blocking=True)\n",
        "                    y_val = y_val.to(device)\n",
        "                    z_val = z_val.view([batch_size, -1, nc_features]).to(device,non_blocking=True)\n",
        "                    self.model.eval()\n",
        "\n",
        "                    # with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                    h,yhat = self.model(x_val, z_val)\n",
        "                    # print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch % 5 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            end_epoch = time.time()\n",
        "            elapsed = end_epoch - start_epoch\n",
        "            times.append(elapsed)\n",
        "\n",
        "        total_time = sum(times)\n",
        "        avg_time = sum(times)/n_epochs\n",
        "\n",
        "        print(f\"Average Training time: {avg_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "        print(f\"Total Training time: {total_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "\n",
        "        #torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "        return validation_loss  #this will be used by otuna to optimize\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, np_features=1, nc_features = 1):\n",
        "            with torch.no_grad():\n",
        "                predictions = []\n",
        "                values = []\n",
        "                for x_test, z_test, y_test in test_loader:\n",
        "\n",
        "                    x_test = x_test.view([batch_size,-1, np_features]).to(device, non_blocking=True)\n",
        "                    y_test = y_test.to(device)\n",
        "                    z_test = z_test.view([batch_size,-1, nc_features]).to(device, non_blocking=True)\n",
        "                    self.model.eval()\n",
        "                    h,yhat = self.model(x_test, z_test)\n",
        "                    predictions.append(yhat.detach().cpu().numpy())\n",
        "                    values.append(y_test.detach().cpu().numpy())\n",
        "\n",
        "            return predictions, values\n",
        "\n",
        "    def plot_losses(self):\n",
        "            plt.plot(self.train_losses, label=\"Training loss\")\n",
        "            plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Losses\")\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.ylabel(\"Loss(MSE)\")\n",
        "            plt.show()\n",
        "            plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0211805",
      "metadata": {
        "id": "f0211805"
      },
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3febeddf",
      "metadata": {
        "id": "3febeddf"
      },
      "outputs": [],
      "source": [
        "#data load function\n",
        "#4 sets of data: FD001, FD002, FD003, FD004\n",
        "#FD001 and FD003 same operating condition 1\n",
        "#FD002 and FD004 same operating condition 6\n",
        "\n",
        "def dataload(filename):\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca73a50",
      "metadata": {
        "id": "4ca73a50"
      },
      "outputs": [],
      "source": [
        "#define path\n",
        "#path ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c0d28aa6",
      "metadata": {
        "id": "c0d28aa6"
      },
      "outputs": [],
      "source": [
        "train_FD003 = dataload(path+'train_FD003')\n",
        "test_FD003 = dataload(path+'test_FD003')\n",
        "#drop the frst unnamed column\n",
        "train_FD003.drop(columns = train_FD003.columns[0],axis=1, inplace=True)\n",
        "test_FD003.drop(columns = test_FD003.columns[0],axis=1, inplace=True)\n",
        "train_FD003.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b1b404",
      "metadata": {
        "id": "69b1b404"
      },
      "source": [
        "## 2. Data Prepreprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6e38b43",
      "metadata": {
        "id": "e6e38b43"
      },
      "outputs": [],
      "source": [
        "# selected features after data analysis\n",
        "\n",
        "feature_list1 = ['unit_number','time_cycles','setting_1', 'setting_2',\n",
        "                's_2','s_3','s_4','s_7','s_8','s_9','s_11','s_12','s_13',\n",
        "                 's_15','s_17','s_20','s_21','RUL']   #feature list for FD001\n",
        "\n",
        "feature_list3 = ['unit_number','time_cycles','setting_1', 'setting_2',\n",
        "                's_2','s_3','s_4','s_7','s_8','s_9','s_11','s_15','s_17',\n",
        "                 's_20','s_21','RUL'] #feature list for FD003\n",
        "\n",
        "feature_list4 = ['unit_number','time_cycles','setting_1','setting_2','setting_3',\n",
        "                's_2','s_8','s_14','s_16','RUL'] #feature list for FD004"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb158818",
      "metadata": {
        "id": "fb158818"
      },
      "source": [
        "### a) Smoothing - moving average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf6727f",
      "metadata": {
        "id": "caf6727f"
      },
      "outputs": [],
      "source": [
        "#Trailing moving average\n",
        "#trail_ma(t) = mean(obs(t-2), obs(t-1), obs(t))\n",
        "\n",
        "def moving_average(x, w):\n",
        "    #x: time series\n",
        "    #w: sliding window size\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3d8406",
      "metadata": {
        "id": "1a3d8406"
      },
      "source": [
        "### b) Normalisation - Transform and Inverse transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80d6598",
      "metadata": {
        "id": "b80d6598"
      },
      "outputs": [],
      "source": [
        "def data_transform(data,option ='std'):\n",
        "#data is numpy array\n",
        "#option is set to std for standardization or minmax\n",
        "\n",
        "    n = data.shape[0]\n",
        "\n",
        "    if option == 'std' :\n",
        "\n",
        "        #perform standardization of data\n",
        "        miu = np.mean(data,axis = 0)\n",
        "        sigma = np.std(data,axis=0,dtype=float)\n",
        "        temp_data = data-np.tile(miu,(n,1))\n",
        "        std_data = np.divide(temp_data,np.tile(sigma,(n,1)))\n",
        "\n",
        "        return std_data, miu, sigma\n",
        "\n",
        "    elif option == 'minmax':\n",
        "\n",
        "        #perform min-max normalization\n",
        "        max_val = np.max(data,0)\n",
        "        #print(max_val)\n",
        "        min_val = np.min(data,0)\n",
        "        #print(min_val)\n",
        "        rng = max_val-min_val\n",
        "        norm_data = np.divide(data - np.tile(min_val,(n,1)),np.tile(rng,(n,1)))\n",
        "\n",
        "        return norm_data, min_val, rng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f929d8",
      "metadata": {
        "id": "c3f929d8"
      },
      "outputs": [],
      "source": [
        "## Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def inv_trans(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # params:list of parameters applied while normalization\n",
        "    # data is 1-D column vector\n",
        "#     print(data)\n",
        "#     print(param1)\n",
        "#     print(param2)\n",
        "\n",
        "    if option == \"std\":\n",
        "         #perform standardization of data\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data = data*sigma + miu\n",
        "\n",
        "        return inv_data\n",
        "\n",
        "    else : #MinMax normalization\n",
        "\n",
        "        #perform min-max normalization\n",
        "        min_val = param1\n",
        "        rng = param2\n",
        "        inv_data = data*rng+min_val\n",
        "        return inv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b29c4780",
      "metadata": {
        "id": "b29c4780"
      },
      "source": [
        "### c) Denormalization (target) - 1 level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81216c35",
      "metadata": {
        "id": "81216c35"
      },
      "outputs": [],
      "source": [
        "# Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def d_norm_1(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # param:parameters applied while normalization (training data statistics)\n",
        "    # data is 1-D column vector\n",
        "\n",
        "\n",
        "\n",
        "    if option == \"std\":  #z-score denormalization\n",
        "\n",
        "\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data1 = data*sigma+miu\n",
        "\n",
        "\n",
        "    else : #MinMax denormalization\n",
        "\n",
        "            m = param1\n",
        "            r = param2\n",
        "            inv_data1 = data*r+m\n",
        "\n",
        "    #print (inv_data1.to_numpy())\n",
        "\n",
        "    return inv_data1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607299bc",
      "metadata": {
        "id": "607299bc"
      },
      "source": [
        "### Minmax data normalisation and smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b14adb",
      "metadata": {
        "id": "89b14adb",
        "outputId": "626d3466-cff2-4683-cc8f-63277f1b8657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24520, 16)\n"
          ]
        }
      ],
      "source": [
        "#Train data normalisation and smoothing\n",
        "\n",
        "select_data_train = np.array(train_FD003[feature_list3].copy(deep=True))\n",
        "train_data, p1, p2 = data_transform(select_data_train[:,2:],option = 'minmax') #drop unit_number and time_cycles\n",
        "\n",
        "# select_data_train = np.array(train_FD004[feature_list4].copy(deep=True))\n",
        "# train_data, p1, p2 = data_transform(select_data_train[:,2:],option = 'minmax') #drop unit_number and time_cycles\n",
        "\n",
        "\n",
        "#add unit_number and time_cycles to train_data\n",
        "train_data = np.concatenate((select_data_train[:,0:2], train_data), axis = 1)\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = train_FD003['unit_number'].unique()\n",
        "#unit_numbers = train_FD004['unit_number'].unique()\n",
        "\n",
        "l = len(feature_list3)\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = train_data[train_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_train = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_train[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_train[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(l-3): #number of features - unit_number, time_cycles and RUL\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_train[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = train_data[train_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_train1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_train1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_train1[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(l-3): #4 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_train1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_train = np.concatenate((smooth_data_train,smooth_data_train1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_train.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_train[smooth_data_train[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d32e259",
      "metadata": {
        "id": "2d32e259",
        "outputId": "548896da-2e17-4ea0-fa11-72dd6dd04312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16396, 16)\n"
          ]
        }
      ],
      "source": [
        "#Test data normalisation and smoothing\n",
        "\n",
        "#1. Normalize using training data statistics\n",
        "#select_data_test = np.array(test_FD004[feature_list4].copy(deep=True))\n",
        "select_data_test = np.array(test_FD003[feature_list3].copy(deep=True))\n",
        "\n",
        "#perform min-max normalization\n",
        "min_val = p1\n",
        "rng = p2\n",
        "test_data = (select_data_test[:,2:]-min_val)/rng\n",
        "\n",
        "#add the unit_number and time_cycles\n",
        "test_data = np.concatenate((select_data_test[:,0:2], test_data), axis = 1)\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = test_FD003['unit_number'].unique()\n",
        "\n",
        "l = len(feature_list3)\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = test_data[test_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_test = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_test[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_test[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "\n",
        "for i in range(l-3): #4 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_test[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "\n",
        "    grp_data = test_data[test_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "\n",
        "    smooth_data_test1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_test1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_test1[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "\n",
        "    for i in range(l-3): #4 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_test1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_test = np.concatenate((smooth_data_test,smooth_data_test1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_test.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_test[smooth_data_test[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1465b2c",
      "metadata": {
        "id": "c1465b2c"
      },
      "source": [
        "## 3. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f2a335",
      "metadata": {
        "id": "02f2a335"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for RNN model such that the data is presented as (num_samples,seq_length,num_features)\n",
        "\n",
        "def data_preparation(data,n_past,n_future):\n",
        "    '''\n",
        "    input:\n",
        "        data :[unit_number, time_cycles,context inputs, primary inputs, output]\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'setting_1','setting_2', 'setting_3'\n",
        "        primary input (X): 's_2','s_8','s_14','s_16'\n",
        "        ouput/target (Y): 'RUL' at time step t\n",
        "        Engine unit and time cycles (U)\n",
        "    '''\n",
        "\n",
        "    n,m = data.shape\n",
        "    #print((n,m))\n",
        "\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    engine_data = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "\n",
        "        engine_data.append(data[i-t:i,0:2])  # first two are unit_number, time_cycles\n",
        "        context_data.append(data[i-t:i,2:4]) # then settings data\n",
        "        input_data.append(data[i-t:i, 4:m-1])  #next attributes are sensor data\n",
        "        output_data.append([data[i+k-1:i+k,m-1]])  #last column is the RUL\n",
        "\n",
        "\n",
        "\n",
        "    U = np.array(engine_data)\n",
        "    X = np.array(input_data)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(n,m)\n",
        "#    print(X.shape)\n",
        "#     print(Y.shape)\n",
        "#     print(Z.shape)\n",
        "\n",
        "\n",
        "    return U, X, Y, Z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e287f36",
      "metadata": {
        "id": "7e287f36"
      },
      "outputs": [],
      "source": [
        "#for test set label is also provided\n",
        "\n",
        "def data_preparation_test(data,n_past,n_future):\n",
        "\n",
        "    '''\n",
        "    input:\n",
        "        data :[unit_number, time_cycles,context inputs, primary inputs, output, label]\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'setting_1','setting_2''\n",
        "        primary input (X): 's_2','s_3','s_4','s_7','s8','s9','s11', 's15', 's17', 's20', 's21'\n",
        "        ouput/target (Y): 'RUL' at time step t\n",
        "        Engine unit and time cycles (U)\n",
        "        label : label at time step t required for denormalisation of dat\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    n,m = data.shape\n",
        "    #print(n,m)\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    engine_data = []\n",
        "\n",
        "    label_data = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "        engine_data.append(data[i-t:i,0:2])        # first two are unit_number, time_cycles\n",
        "        context_data.append(data[i-t:i,2:5])       # then settings data\n",
        "        input_data.append(data[i-t:i, 5:m-2])      # next attributes are sensor data\n",
        "        output_data.append(data[i+k-1:i+k,m-2])    # second last column is the RUL\n",
        "        label_data.append(data[i+k-1:i+k,m-1])     # last column is label\n",
        "\n",
        "\n",
        "    U = np.array(engine_data)\n",
        "    X = np.array(input_data)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "    label = np.array(label_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return U, X, Y, Z, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed53f02",
      "metadata": {
        "id": "9ed53f02"
      },
      "source": [
        "### a) Data preparation Training and validation (Minmax normalised data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a23adcba",
      "metadata": {
        "id": "a23adcba",
        "outputId": "0769b565-43e9-42e7-e4b3-35a67cd6ee64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21299, 10, 11)\n",
            "(21299, 10, 2)\n",
            "(21299, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "prediction n_future = step ahead with n_past samples\n",
        "NOTE: n_future is set to 1 as the predicted step will not be k step ahead it will be at t+1\n",
        "unit_number is also present in columns, it will be used for selecting rows for validation set\n",
        "sensor_list = ['s_2','s_8','s_14','s_16']\n",
        "'''\n",
        "\n",
        "'''\n",
        "------------data normalised using cluster statistics----------------------------------------\n",
        "'''\n",
        "\n",
        "\n",
        "data = smooth_data_train\n",
        "\n",
        "\n",
        "'''\n",
        "The train and test data is availble. Divide the given train data into two parts train and validation,\n",
        "considering the engine unit number.\n",
        "'''\n",
        "seq_len = 10 #sequence length (tune with 10,15,20)\n",
        "\n",
        "\n",
        "#take last rows equivalent to double the seq_len from each of the engine unit as validation data\n",
        "list_unit = train_FD003['unit_number'].unique()\n",
        "eng_data = data[data[:,0]==list_unit[0]]\n",
        "data_train = eng_data[:-2*seq_len,:]\n",
        "data_val = eng_data[-2*seq_len:,:]\n",
        "\n",
        "\n",
        "for i in range(1,len(list_unit)):\n",
        "    eng_data = data[data[:,0]==list_unit[i]]\n",
        "    data_train = np.concatenate((data_train,eng_data[:-2*seq_len,:]), axis=0)\n",
        "    data_val = np.concatenate((data_val,eng_data[-2*seq_len:,:]), axis=0)\n",
        "\n",
        "# print(data_train.shape)\n",
        "# print(data_val.shape)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "grp_data = data_train[data_train[:,0] == 1]\n",
        "U_train, X_train, Y_train, Z_train= data_preparation(grp_data,seq_len,1)  #last parameter 0 means context features excluded\n",
        "grp_data = data_val[data_val[:,0]==1]\n",
        "U_val, X_val, Y_val, Z_val = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "\n",
        "\n",
        "list_unit = list_unit[1:]\n",
        "for i in range(1,len(list_unit)):\n",
        "    grp_data = data_train[data_train[:,0] == list_unit[i]]\n",
        "    U_train1, X_train1, Y_train1, Z_train1 = data_preparation(grp_data,seq_len,1)\n",
        "    grp_data = data_val[data_val[:,0]==i]\n",
        "    U_val1, X_val1, Y_val1, Z_val1 = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    U_train = np.concatenate((U_train,U_train1),axis = 0)\n",
        "    X_train = np.concatenate((X_train,X_train1),axis = 0)\n",
        "    Y_train = np.concatenate((Y_train,Y_train1),axis = 0)\n",
        "    Z_train = np.concatenate((Z_train,Z_train1),axis = 0)\n",
        "\n",
        "\n",
        "    U_val = np.concatenate((U_val,U_val1),axis = 0)\n",
        "    X_val = np.concatenate((X_val,X_val1),axis = 0)\n",
        "    Y_val = np.concatenate((Y_val,Y_val1),axis = 0)\n",
        "    Z_val = np.concatenate((Z_val,Z_val1),axis = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Z_train.shape)\n",
        "print(Y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0528e02b",
      "metadata": {
        "id": "0528e02b"
      },
      "source": [
        "## 4. Loading data into PyTorch Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aa5510f9",
      "metadata": {
        "id": "aa5510f9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "#transform the arrays into torch tensors\n",
        "train_features = torch.Tensor(X_train)  #drop unit_number and test_cycles\n",
        "train_targets = torch.Tensor(Y_train)\n",
        "train_cx_features = torch.Tensor(Z_train)\n",
        "\n",
        "val_features = torch.Tensor(X_val)\n",
        "val_targets = torch.Tensor(Y_val)\n",
        "val_cx_features = torch.Tensor(Z_val)\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features,train_cx_features, train_targets)\n",
        "val = TensorDataset(val_features, val_cx_features,val_targets)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples,context,targets = examples.next()\n",
        "print(samples.shape, context.shape,targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5. Hyperparameter tuning using Optuna"
      ],
      "metadata": {
        "id": "ZU3TNBLzrTuw"
      },
      "id": "ZU3TNBLzrTuw"
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter optimization with optuna\n",
        "\n",
        "input_dim = X_train.shape[2]\n",
        "output_dim = Y_train.shape[2]\n",
        "context_dim = Z_train.shape[2]\n",
        "\n",
        "weight_decay = 1e-6\n",
        "dropout = 0.1\n",
        "n_epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    params1 = {\n",
        "              'input_dim':input_dim,\n",
        "              'output_dim': output_dim,\n",
        "              'context_dim': context_dim,\n",
        "              'hidden_dim':trial.suggest_int('hidden_size',10,30,5),\n",
        "              }\n",
        "\n",
        "    params2 = {\n",
        "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
        "                'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              }\n",
        "\n",
        "    #model = get_model('gru',params1)\n",
        "    model = ContextGRU(input_dim, params1['hidden_dim'], output_dim, context_dim)\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"], weight_decay=weight_decay)\n",
        "    optimizer = getattr(optim, params2['optimizer'])(model.parameters(), lr= params2['learning_rate'], weight_decay=weight_decay)\n",
        "    opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "    train_loss = opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "    opt.plot_losses()\n",
        "\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "\n",
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))\n",
        "\n"
      ],
      "metadata": {
        "id": "y5a6O9AGtGY3"
      },
      "id": "y5a6O9AGtGY3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f263054",
      "metadata": {
        "id": "4f263054"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76c3ad92",
      "metadata": {
        "id": "76c3ad92"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "input_dim = X_train.shape[2]\n",
        "output_dim = Y_train.shape[2]\n",
        "context_dim = Z_train.shape[2]\n",
        "\n",
        "hidden_dim = 20  #tune the parameter 10,15,20\n",
        "layer_dim = 1\n",
        "batch_size = 128  #tune the parameter 64,128,256\n",
        "dropout = 0.2\n",
        "n_epochs = 80\n",
        "learning_rate = 0.0003 #tune the parameter with optuna\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model = ContextGRU(input_dim, hidden_dim, output_dim, context_dim)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "params_list = model.parameters()\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "#optimizer = optim.Adam(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "optimizer = optim.RMSprop(params_list, lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=weight_decay)\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "opt.plot_losses()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fc8332",
      "metadata": {
        "id": "21fc8332"
      },
      "source": [
        "## 6. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129995e3",
      "metadata": {
        "id": "129995e3"
      },
      "source": [
        "### Testing (minmax normalisation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f3170cf",
      "metadata": {
        "id": "3f3170cf"
      },
      "outputs": [],
      "source": [
        "#Data prepartion for test data\n",
        "#colums: unit_number,time_cycles,setting_1,setting_2,setting_3,s_1,s_2,s_8,s_13,s_14,s_19,RUL,labels\n",
        "\n",
        "seq_len = 20  #sequence length for lstm\n",
        "\n",
        "\n",
        "data_test = smooth_data_test  #label is the last column, needed for denormalization\n",
        "\n",
        "\n",
        "list_unit = test_FD003['unit_number'].unique()\n",
        "\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]  #parameter for 'RUL'  (mean/miu)\n",
        "par2 = p2[-1]  #parameter for 'RUL'  (range/sigma)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "#list_unit = [83]\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "for i in list_unit:\n",
        "\n",
        "\n",
        "    grp_data = data_test[data_test[:,0] == i]\n",
        "    U_test, X_test, Y_test, Z_test = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "    if len(X_test) == 0:\n",
        "        continue\n",
        "\n",
        "    test_features = torch.Tensor(X_test)\n",
        "    test_targets = torch.Tensor(Y_test)\n",
        "    test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "    test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "    #test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "    #flatten the multi-dimension array to 1-D array\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "    #Apply inverse transform\n",
        "    #reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "    #target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "    #pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "\n",
        "    #1 level denormalise the target\n",
        "    target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "    pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "    #plot_results(i, target_val,pred_val)\n",
        "\n",
        "    result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "    result_rmse.append(result_metrics['rmse'])\n",
        "    result_r2.append(result_metrics['r2'])\n",
        "    score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "#calculate average and std of rmse,and score\n",
        "\n",
        "avg_rmse = np.mean(result_rmse)\n",
        "std_rmse = np.std(result_rmse)\n",
        "\n",
        "avg_score = np.mean(score)\n",
        "std_score = np.std(score)\n",
        "\n",
        "print(f\"[Average RMSE: {avg_rmse:.4f}\\t Std RMSE: {std_rmse:.4f}]\")\n",
        "print(f\"[Average SCORE: {avg_score:.4f}\\t Std SCORE: {std_score:.4f}]\")\n",
        "\n",
        "min_rmse = min(result_rmse)\n",
        "max_rmse = max(result_rmse)\n",
        "min_score = min(score)\n",
        "max_score = max(score)\n",
        "print(f\"[Engine unit#: {result_rmse.index(min_rmse)+1}\\t Min RMSE: {min_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {result_rmse.index(max_rmse)+1}\\t Max RMSE: {max_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(min_score)+1}\\t Min score: {min_score:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(max_score)+1}\\t Max score: {max_score:.4f}]\")\n",
        "\n",
        "print(torch.mode(torch.tensor(result_rmse),0))\n",
        "print(torch.mode(torch.tensor(score),0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b41d497e",
      "metadata": {
        "id": "b41d497e"
      },
      "outputs": [],
      "source": [
        "# Test the whole data (not engine-wise)\n",
        "#Data prepartion for test data\n",
        "\n",
        "seq_len = 10  #sequence length for lstm\n",
        "#cols = [0,1,2,3,4,5,6,13,18,19,24,26]   #0: unit number,1:time_cycles, 2,3,4 : 3 settings, 5,6,13,18,19: sensor data, 26:RUL\n",
        "test_arr_data = test_norm_data.copy(deep = True)\n",
        "\n",
        "#remove labels for prediction task\n",
        "#test_arr_data.drop('label',axis=1, inplace = True)\n",
        "data_test = test_arr_data.to_numpy()\n",
        "\n",
        "#data_test = smooth_data_test\n",
        "\n",
        "#parameters required for inverse transform (cluster statistics)\n",
        "# cpar1 = param1\n",
        "# cpar2 = param2\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]\n",
        "par2 = p2[-1]\n",
        "\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "\n",
        "U_test, X_test, Y_test, Z_test, Y_labels = data_preparation_test(data_test,seq_len,1)\n",
        "\n",
        "test_features = torch.Tensor(X_test)\n",
        "test_targets = torch.Tensor(Y_test)\n",
        "test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "#test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "#flatten the multi-dimension array to 1-D array\n",
        "vals = np.concatenate(values, axis=0).ravel()\n",
        "preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "\n",
        "#Apply denormalization transform\n",
        "#reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "# target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels, cpar1, cpar2, par1,par2)\n",
        "# pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels, cpar1, cpar2,par1,par2)\n",
        "\n",
        "\n",
        "target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "\n",
        "#plot_results(i, target_val,pred_val)\n",
        "\n",
        "#smooth the values\n",
        "#sm_pred_val = moving_average(pred_val, 10) #3 is window size\n",
        "\n",
        "result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "result_rmse.append(result_metrics['rmse'])\n",
        "result_r2.append(result_metrics['r2'])\n",
        "score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "print(result_rmse)\n",
        "print(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e21c8c",
      "metadata": {
        "id": "a5e21c8c",
        "outputId": "35cfadf4-1de6-43ae-a5f0-c0617f1b75c3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# sns.set_palette(\"bright\")\n",
        "# sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "plot_results(10, target_val[0:1000],pred_val[0:1000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c6e910",
      "metadata": {
        "id": "22c6e910"
      },
      "outputs": [],
      "source": [
        "#Plot the results Engine Unit wise\n",
        "def plot_results(unit_num, target_val,pred_val):\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    #plt.subplot(1,2,1).set_title(\"Engine Unit #\" + str(unit_num))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(target_val,'r')\n",
        "    plt.plot(pred_val,'b')\n",
        "    plt.xlabel('Time (Cycles)')\n",
        "    plt.ylabel('RUL')\n",
        "    plt.legend(['Actual RUL','Predicted RUL'])\n",
        "\n",
        "#     plt.subplot(1,2,2).set_title(\"Engine Unit #\" + str(unit_num))\n",
        "#     plt.plot(target_val,pred_val,'.r')\n",
        "#     plt.xlabel('Actual RUL')\n",
        "#     plt.ylabel('Predcited RUL')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f129080",
      "metadata": {
        "id": "5f129080"
      },
      "source": [
        "### Calculate Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f8b7eb",
      "metadata": {
        "id": "79f8b7eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calculate_metrics(actual, predicted):\n",
        "\n",
        "    return {'mae' : mean_absolute_error(actual,predicted),\n",
        "            'rmse' : mean_squared_error(actual,predicted) ** 0.5,\n",
        "            'r2' : r2_score(actual,predicted)}\n",
        "\n",
        "# result_metrics = calculate_metrics(target_val, pred_val)\n",
        "# print(result_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1976db26",
      "metadata": {
        "id": "1976db26"
      },
      "source": [
        "### Calculate Asymmetric score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772cc745",
      "metadata": {
        "id": "772cc745"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "#call this function for each unit, and sum to get the overall score\n",
        "def calculate_score(actual, predicted):\n",
        "#calcualate score for one engine unit\n",
        "    s = 0\n",
        "    a1 = 10 #constant\n",
        "    a2 = 13\n",
        "    s_list = []\n",
        "    d_list = predicted - actual\n",
        "    for i in range(len(actual)):\n",
        "        d = predicted[i]-actual[i]\n",
        "\n",
        "        if d >= 0:\n",
        "            #s = s+(math.exp(d/a2)-1)\n",
        "            s = (math.exp(d/a2)-1)\n",
        "            s_list.append(s)\n",
        "\n",
        "        else:\n",
        "\n",
        "            #s = s+(math.exp(-d/a1)-1)\n",
        "            s = (math.exp(-d/a1)-1)\n",
        "            s_list.append(s)\n",
        "\n",
        "#     plt.figure()\n",
        "#     plt.plot(d_list,s_list,'.')\n",
        "\n",
        "    return sum(s_list)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}