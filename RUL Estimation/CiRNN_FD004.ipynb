{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8b105c",
      "metadata": {
        "id": "ab8b105c",
        "outputId": "afdf4910-1499-48dd-a086-610bd14cdac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4f85959e90>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "seed = 40\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "\n",
        "import random\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.pyplot import *\n",
        "#style.use('ggplot')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.profiler\n",
        "import torch.autograd.profiler as profiler\n",
        "import sklearn.preprocessing as preprocess\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6be63e",
      "metadata": {
        "id": "9c6be63e"
      },
      "source": [
        "# Context Integrated RNN - CiRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85c75a2",
      "metadata": {
        "id": "e85c75a2",
        "outputId": "dfcd3395-ef66-49c1-aae2-70ac5e15e816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get CPU or GPU device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class ContextGRU(torch.nn.Module):\n",
        "    \"\"\"\n",
        "     simple GRU cell network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, context_dim):\n",
        "        super(ContextGRU, self).__init__()\n",
        "\n",
        "        self.n_x = input_dim\n",
        "        self.n_h = hidden_dim\n",
        "        self.n_y = output_dim\n",
        "        self.n_z = context_dim\n",
        "        self.m = 9  #dimension of basis function vector (polynomial features) for 3 context features\n",
        "\n",
        "\n",
        "        # reset gate components\n",
        "        self.linear_reset_w1 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r1 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "\n",
        "\n",
        "        self.linear_reset_w2 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r2 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_1 = nn.Sigmoid()\n",
        "\n",
        "        # update gate components\n",
        "        self.linear_gate_w3 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_gate_r3 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_2 = nn.Sigmoid()\n",
        "\n",
        "        self.activation_3 = nn.Tanh()\n",
        "\n",
        "        #output\n",
        "        self.linear_output = nn.Linear(self.n_h, self.n_y, bias=True)\n",
        "\n",
        "\n",
        "    def reset_gate(self, xg, h):  #xg is the kronecker product of x and  basis function G(z)\n",
        "        x_1 = self.linear_reset_w1(xg)\n",
        "        h_1 = self.linear_reset_r1(h)\n",
        "        # gate update\n",
        "        r = self.activation_1(x_1 + h_1)\n",
        "        return r\n",
        "\n",
        "    def update_gate(self, xg, h):\n",
        "        x_2 = self.linear_reset_w2(xg)\n",
        "        h_2 = self.linear_reset_r2(h)\n",
        "        s = self.activation_2( h_2 + x_2)\n",
        "        return s\n",
        "\n",
        "\n",
        "    def update_component(self, xg, h, r):\n",
        "        x_3 = self.linear_gate_w3(xg)\n",
        "        h_3 = r * self.linear_gate_r3(h)\n",
        "        h_tilda = self.activation_3(x_3+h_3)\n",
        "        return h_tilda\n",
        "\n",
        "\n",
        "    def compute_output(self,h):\n",
        "        y_pred = self.linear_output(h)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def cell_forward(self, x, h, G):\n",
        "\n",
        "        \"\"\"\n",
        "        Implements a single forward step of the Context GRU-cell\n",
        "\n",
        "        Input Arguments:\n",
        "            x (mini-batch): input x at time step t , (n,n_x) : (batch_size, input_dim)\n",
        "            h : hidden state at time step t-1, (n,n_h) : (batch_size, hidden_dim)\n",
        "            G : vector of basis funcitons (m,n)\n",
        "\n",
        "        Returns:\n",
        "            h_new: hidden state at time step t, (n,n_h)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # kronecker product of x and G(zt)\n",
        "        n = x.shape[0]\n",
        "        xg = torch.zeros(n,self.n_x*self.m).to(device)\n",
        "\n",
        "        for i in range(n):\n",
        "\n",
        "            xg[i,:] = torch.kron(x[i,:],G[:,i])\n",
        "\n",
        "\n",
        "        # Equation 1. reset gate vector\n",
        "        r = self.reset_gate(xg, h)\n",
        "\n",
        "        # Equation 2: the update gate - the shared update gate vector z\n",
        "        s = self.update_gate(xg, h)\n",
        "\n",
        "        # Equation 3: The almost output component\n",
        "        h_tilda = self.update_component(xg,h,r)\n",
        "\n",
        "        # Equation 4: the new hidden state\n",
        "        h_new = (1-s) * h_tilda  + s * h\n",
        "\n",
        "        #output\n",
        "\n",
        "        y_pred = self.compute_output(h)\n",
        "\n",
        "        return h_new, y_pred\n",
        "\n",
        "\n",
        "    def forward(self, x, z):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the forward propagation of the recurrent neural network\n",
        "\n",
        "        Input Arguments:\n",
        "        x (mini_batch): primary input for every time-step in mini-batches of shape (n, T, n_x)\n",
        "        z (mini_batch): context input for every time-step in mini-batches of shape (n,T,n_z)\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            h -- Hidden states for every time-step, numpy array of shape (n, T, n_h)\n",
        "            y_pred -- Predictions for every time-step, numpy array of shape (n, T, n_y),\n",
        "            here T is 1 for Seq to Vec RNN\n",
        "        \"\"\"\n",
        "\n",
        "        # Retrieve dimensions from shapes of x\n",
        "        #print(x.shape)\n",
        "        #print(z.shape)\n",
        "        n,T,n_x = x.shape\n",
        "        n_y = self.n_y\n",
        "        n_h = self.n_h\n",
        "        n_z = self.n_z\n",
        "\n",
        "\n",
        "\n",
        "        # initialize \"h\"\n",
        "\n",
        "        h = self.init_hidden(n,T,n_h)\n",
        "\n",
        "        #y_pred = np.zeros((m,T_x,n_y))\n",
        "        #y_pred is single value for one sample, m=1\n",
        "\n",
        "        #basis function vector\n",
        "        G = self.apply_basis(z[:,0,:])  #G: size of (n,m)\n",
        "\n",
        "        #for initial time step the hidden state is 0\n",
        "        h_temp = h.clone()\n",
        "        h_init = h_temp[:,0,:]\n",
        "        h_curr, y_curr = self.cell_forward(x[:,0,:],h_init,torch.t(G))\n",
        "\n",
        "        # loop over all time-steps\n",
        "        for t in range(1,T):\n",
        "\n",
        "            #compute the vector of basis functions\n",
        "\n",
        "            G = self.apply_basis(z[:,t,:])  #G: size of (n,m)\n",
        "\n",
        "            # Update next hidden state\n",
        "            # ignore yt_pred for seq to vector\n",
        "            h[:,t,:]= h_curr\n",
        "            h_temp = h.clone()\n",
        "            h_prev = h_temp[:,t,:]  #h_prev: (n,n_h)\n",
        "            h_curr, y_curr = self.cell_forward(x[:,t,:],h_prev, torch.t(G))\n",
        "\n",
        "            #y_pred[t,:] = yt_pred\n",
        "\n",
        "\n",
        "        #compute the predicted output from the last cell i.e at last time step T\n",
        "        y_pred = torch.zeros(n,1,1,device = 'cuda:0')\n",
        "\n",
        "        #get the value of y_pred from the last cell\n",
        "        y_pred[:,0,:] = y_curr\n",
        "\n",
        "        #print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "        return h, y_pred\n",
        "\n",
        "\n",
        "    def init_hidden(self, n:int,T:int, n_h:int):\n",
        "        #initialise the hidden state\n",
        "        #n : batch-size\n",
        "        #T : Input sequence length\n",
        "        #returns h of size (n,T,n_h)\n",
        "        return torch.zeros(n,T,n_h,device = 'cuda:0')\n",
        "\n",
        "\n",
        "    def apply_basis(self,zt):\n",
        "        '''\n",
        "        apply the basis function: polynomial degree 2\n",
        "        [z0, z1, z2, z0z0, z0z1, z0z2....]\n",
        "        input arguments:\n",
        "            zt: context vector (n,n_z) for mini-batch of size n and n_z context dim\n",
        "        Returns:\n",
        "            G : tensor of basis functions, (m,n)\n",
        "\n",
        "        for 3 context features m = 11\n",
        "        '''\n",
        "\n",
        "        #poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
        "        poly = PolynomialFeatures(2, include_bias=False)\n",
        "        G = torch.tensor(poly.fit_transform(zt.cpu().numpy())).to(device) #fit_transform returns nd array\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return G\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999d31f3",
      "metadata": {
        "id": "999d31f3"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train_step(self, x, y, z):\n",
        "\n",
        "       # with profiler.record_function(\"TRAIN STEP FUNCTION\"):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        h, yhat = self.model(x, z)\n",
        "\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        #with profiler.record_function(\"LOSS_BACKWARD\"):\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size, n_epochs=50, np_features=1, nc_features=1):\n",
        "        '''\n",
        "        np_features = # primary input features\n",
        "        nc_features = # context input features\n",
        "        '''\n",
        "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "        times = []\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "            start_epoch = time.time()\n",
        "\n",
        "            batch_losses = []\n",
        "            for x_batch, z_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.view([batch_size,-1, np_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                z_batch = z_batch.view([batch_size,-1, nc_features]).to(device)\n",
        "\n",
        "                #with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                loss = self.train_step(x_batch, y_batch, z_batch)\n",
        "                #print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                batch_losses.append(loss)\n",
        "\n",
        "\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, z_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, np_features]).to(device, non_blocking=True)\n",
        "                    y_val = y_val.to(device)\n",
        "                    z_val = z_val.view([batch_size, -1, nc_features]).to(device,non_blocking=True)\n",
        "                    self.model.eval()\n",
        "\n",
        "                    # with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                    h,yhat = self.model(x_val, z_val)\n",
        "                    # print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch % 5 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            end_epoch = time.time()\n",
        "            elapsed = end_epoch - start_epoch\n",
        "            times.append(elapsed)\n",
        "\n",
        "        total_time = sum(times)\n",
        "        avg_time = sum(times)/n_epochs\n",
        "\n",
        "        print(f\"Average Training time: {avg_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "        print(f\"Total Training time: {total_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "\n",
        "        #torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "        return validation_loss  #this will be used by otuna to optimize\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, np_features=1, nc_features = 1):\n",
        "            with torch.no_grad():\n",
        "                predictions = []\n",
        "                values = []\n",
        "                for x_test, z_test, y_test in test_loader:\n",
        "\n",
        "                    x_test = x_test.view([batch_size,-1, np_features]).to(device, non_blocking=True)\n",
        "                    y_test = y_test.to(device)\n",
        "                    z_test = z_test.view([batch_size,-1, nc_features]).to(device, non_blocking=True)\n",
        "                    self.model.eval()\n",
        "                    h,yhat = self.model(x_test, z_test)\n",
        "                    predictions.append(yhat.detach().cpu().numpy())\n",
        "                    values.append(y_test.detach().cpu().numpy())\n",
        "\n",
        "            return predictions, values\n",
        "\n",
        "    def plot_losses(self):\n",
        "            plt.plot(self.train_losses, label=\"Training loss\")\n",
        "            plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Losses\")\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.ylabel(\"Loss(MSE)\")\n",
        "            plt.show()\n",
        "            plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0211805",
      "metadata": {
        "id": "f0211805"
      },
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3febeddf",
      "metadata": {
        "id": "3febeddf"
      },
      "outputs": [],
      "source": [
        "#data load function\n",
        "#4 sets of data: FD001, FD002, FD003, FD004\n",
        "#FD001 and FD003 same operating condition 1\n",
        "#FD002 and FD004 same operating condition 6\n",
        "\n",
        "def dataload(filename):\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca73a50",
      "metadata": {
        "id": "4ca73a50"
      },
      "outputs": [],
      "source": [
        "# define path\n",
        "#path ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f51afef",
      "metadata": {
        "id": "5f51afef"
      },
      "outputs": [],
      "source": [
        "train_FD004 = dataload(path+'train_FD004')\n",
        "test_FD004 = dataload(path+'test_FD004')\n",
        "#train_FD002.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9ae58e26",
      "metadata": {
        "id": "9ae58e26"
      },
      "outputs": [],
      "source": [
        "#drop the frst unnamed column\n",
        "train_FD004.drop(columns = train_FD004.columns[0],axis=1, inplace=True)\n",
        "test_FD004.drop(columns = test_FD004.columns[0],axis=1, inplace=True)\n",
        "train_FD004.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b1b404",
      "metadata": {
        "id": "69b1b404"
      },
      "source": [
        "## 2. Data Prepreprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb158818",
      "metadata": {
        "id": "fb158818"
      },
      "source": [
        "### a) Smoothing - moving average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf6727f",
      "metadata": {
        "id": "caf6727f"
      },
      "outputs": [],
      "source": [
        "#Trailing moving average\n",
        "#trail_ma(t) = mean(obs(t-2), obs(t-1), obs(t))\n",
        "\n",
        "def moving_average(x, w):\n",
        "    #x: time series\n",
        "    #w: sliding window size\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f942246f",
      "metadata": {
        "id": "f942246f"
      },
      "outputs": [],
      "source": [
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3',\n",
        "                's_2','s_8','s_14','s_16','RUL']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3d8406",
      "metadata": {
        "id": "1a3d8406"
      },
      "source": [
        "### b) Normalisation - Transform and Inverse transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80d6598",
      "metadata": {
        "id": "b80d6598"
      },
      "outputs": [],
      "source": [
        "def data_transform(data,option ='std'):\n",
        "#data is numpy array\n",
        "#option is set to std for standardization or minmax\n",
        "\n",
        "    n = data.shape[0]\n",
        "\n",
        "    if option == 'std' :\n",
        "\n",
        "        #perform standardization of data\n",
        "        miu = np.mean(data,axis = 0)\n",
        "        sigma = np.std(data,axis=0,dtype=float)\n",
        "        temp_data = data-np.tile(miu,(n,1))\n",
        "        std_data = np.divide(temp_data,np.tile(sigma,(n,1)))\n",
        "\n",
        "        return std_data, miu, sigma\n",
        "\n",
        "    elif option == 'minmax':\n",
        "\n",
        "        #perform min-max normalization\n",
        "        max_val = np.max(data,0)\n",
        "        #print(max_val)\n",
        "        min_val = np.min(data,0)\n",
        "        #print(min_val)\n",
        "        rng = max_val-min_val\n",
        "        norm_data = np.divide(data - np.tile(min_val,(n,1)),np.tile(rng,(n,1)))\n",
        "\n",
        "        return norm_data, min_val, rng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f929d8",
      "metadata": {
        "id": "c3f929d8"
      },
      "outputs": [],
      "source": [
        "## Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def inv_trans(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # params:list of parameters applied while normalization\n",
        "    # data is 1-D column vector\n",
        "#     print(data)\n",
        "#     print(param1)\n",
        "#     print(param2)\n",
        "\n",
        "    if option == \"std\":\n",
        "         #perform standardization of data\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data = data*sigma + miu\n",
        "\n",
        "        return inv_data\n",
        "\n",
        "    else : #MinMax normalization\n",
        "\n",
        "        #perform min-max normalization\n",
        "        min_val = param1\n",
        "        rng = param2\n",
        "        inv_data = data*rng+min_val\n",
        "        return inv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b36f09",
      "metadata": {
        "id": "61b36f09"
      },
      "source": [
        "### c) Clustering and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53da9a51",
      "metadata": {
        "id": "53da9a51"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "select_data_train = np.array(train_FD004[feature_list].copy(deep=True))\n",
        "train_data, p1, p2 = data_transform(select_data_train[:,2:],option = 'minmax') #drop unit_number and time_cycles\n",
        "\n",
        "kmeans = KMeans(n_clusters=6, n_init=10, random_state=0).fit(train_data)\n",
        "\n",
        "#kmeans.labels_\n",
        "#kmeans.predict([[0, 0], [12, 3]])\n",
        "#kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86008bfc",
      "metadata": {
        "id": "86008bfc",
        "outputId": "967551a8-e6e5-47f2-a07a-feefdc34e348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(61249, 11)\n"
          ]
        }
      ],
      "source": [
        "col_names = ['setting_1','setting_2','setting_3','s_2','s_8','s_14','s_16','RUL']\n",
        "#del train_data_cluster\n",
        "\n",
        "train_data_cluster = train_FD004[['unit_number','time_cycles']].copy(deep=True)\n",
        "train_data_cluster[col_names] = pd.DataFrame(train_data, columns = col_names)\n",
        "train_data_cluster['label'] = kmeans.labels_.astype(str)\n",
        "print(train_data_cluster.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ededbe",
      "metadata": {
        "id": "99ededbe"
      },
      "source": [
        "### Train data normalisation with cluster centers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2cc300",
      "metadata": {
        "id": "ad2cc300"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Normalize train data using the clusters of operational settings\n",
        "'''\n",
        "def cluster_norm(clustered_data,opt='minmax'):\n",
        "#input: clustered data - data frame, option: minmax or std (z-score)\n",
        "#output: normalised data, parameter 1: miu/min value, parameter 2: sigma/range\n",
        "#col_names = ['unit_number','time_cycle',setting_1','setting_2','setting_3','s_1','s_2','s_8',\n",
        "#            's_13','s_14','s_19','RUL','label']\n",
        "\n",
        "    n = clustered_data.shape[0]\n",
        "    norm_data = clustered_data.copy(deep = True)\n",
        "\n",
        "\n",
        "    col_names = ['setting_1','setting_2','setting_3','s_2','s_8', 's_14','s_16']\n",
        "\n",
        "    if opt == 'std':\n",
        "        #get the standard deviation of each cluster\n",
        "        clust_sigma = []\n",
        "        clust_miu = []\n",
        "        for i in range(6):  #6 is number of clusters\n",
        "            idx = clustered_data[clustered_data['label']==str(i)].index\n",
        "            cluster = clustered_data[clustered_data['label']==str(i)].copy(deep = True)\n",
        "            sigma = cluster[col_names].std(axis=1)\n",
        "            miu = cluster[col_names].mean(axis=1)\n",
        "            for j in range(len(col_names)):  #if max and min values are same then cluster column has same values\n",
        "                if (sigma[col_names[j]] == 0):\n",
        "                    sigma[col_names[j]] = 1\n",
        "                    miu[col_names[j]] = 0\n",
        "            df_norm = (cluster-miu)/sigma\n",
        "            #norm_data.loc[idx.tolist(),2:11] = df_norm\n",
        "            norm_data.loc[clustered_data['label']==str(i),col_names] = df_norm\n",
        "            clust_sigma.append(sigma)\n",
        "            clust_miu.append(miu)\n",
        "\n",
        "\n",
        "        return norm_data, clust_miu, clust_sigma\n",
        "\n",
        "\n",
        "    elif opt == 'minmax':\n",
        "\n",
        "        clust_min = []\n",
        "        clust_range = []\n",
        "\n",
        "        for i in range(6):\n",
        "            cluster = clustered_data[clustered_data['label']==str(i)].copy(deep = True)\n",
        "            #print(cluster.head())\n",
        "            min_val = cluster[col_names].min(axis=0)\n",
        "            max_val = cluster[col_names].max(axis=0)\n",
        "            range_val = max_val-min_val\n",
        "            for j in range(len(col_names)):  #if max and min values are same then cluster column has same values\n",
        "                if (range_val[col_names[j]] == 0):\n",
        "                    range_val[col_names[j]] = 1\n",
        "                    min_val[col_names[j]] = 0\n",
        "            df_norm = (cluster[col_names]-min_val)/range_val\n",
        "            #print(df_norm.head())\n",
        "            #idx = clustered_data[clustered_data['label']==str(i)].index\n",
        "            #norm_data.iloc[idx.tolist(),2:11] = df_norm\n",
        "            norm_data.loc[clustered_data['label']==str(i),col_names]=df_norm\n",
        "            clust_min.append(min_val)\n",
        "            clust_range.append(range_val)\n",
        "\n",
        "        return norm_data, clust_min, clust_range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "984ff1c8",
      "metadata": {
        "id": "984ff1c8"
      },
      "outputs": [],
      "source": [
        "train_norm_data, param1, param2 = cluster_norm(train_data_cluster,'minmax')\n",
        "print(train_norm_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ac0fb8",
      "metadata": {
        "id": "64ac0fb8"
      },
      "source": [
        "### Test data normalisation with cluster centers of train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3657e228",
      "metadata": {
        "id": "3657e228",
        "outputId": "fa31b5e3-646f-4a9f-f4f0-1df1c5432f5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rashmi/PythonProjects/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but KMeans was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Normalize the test data using the train data cluster statistics\n",
        "'''\n",
        "col_names = ['setting_1','setting_2','setting_3','s_2','s_8', 's_14','s_16','RUL']\n",
        "col_names1 = ['setting_1','setting_2','setting_3','s_2','s_8', 's_14','s_16']\n",
        "\n",
        "#1. Normalize using training data statistics\n",
        "select_data_test = test_FD004[col_names].copy(deep=True)\n",
        "\n",
        "#perform min-max normalization\n",
        "min_val = p1\n",
        "rng = p2\n",
        "#norm_data = (smooth_data_test[:,2:]-min_val)/rng\n",
        "norm_data = (select_data_test-min_val)/rng\n",
        "#print(norm_data[0:5,0])\n",
        "\n",
        "#2. Predict the labels using kmeans model of training data\n",
        "\n",
        "labels = kmeans.predict(norm_data)\n",
        "test_data_cluster = test_FD004[['unit_number','time_cycles']].copy(deep = True)\n",
        "#test_data_cluster = pd.DataFrame(select_data_test[:,0:2],columns = ['unit_number','time_cycles'])\n",
        "test_data_cluster[col_names] = norm_data\n",
        "test_data_cluster['label'] = labels\n",
        "#print(test_data_cluster.head())\n",
        "\n",
        "#3. Normalise using cluster statistics\n",
        "clustered_data = test_data_cluster.copy(deep=True)\n",
        "\n",
        "for i in range(6):\n",
        "    cluster = clustered_data[clustered_data['label']== i].copy(deep = True)\n",
        "    #print(cluster.head())\n",
        "    min_val1 = param1[i]\n",
        "    range_val1 = param2[i]\n",
        "    df_norm = (cluster[col_names]-min_val1)/range_val1\n",
        "    #print(df_norm.head())\n",
        "    idx = clustered_data[clustered_data['label']== i].index\n",
        "    #clustered_data.iloc[idx.tolist(),2:11] = 100\n",
        "    clustered_data.loc[clustered_data['label']== i,col_names1] = df_norm\n",
        "\n",
        "\n",
        "test_norm_data = clustered_data.copy(deep = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "35ca0f74",
      "metadata": {
        "id": "35ca0f74"
      },
      "outputs": [],
      "source": [
        "#print(test_norm_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fa46bd2",
      "metadata": {
        "id": "9fa46bd2"
      },
      "source": [
        "### Smoothing the cluster normalised data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04857b8",
      "metadata": {
        "id": "b04857b8",
        "outputId": "8ca6112d-106c-4d1b-e94b-736aacc1d32b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60751, 10)\n"
          ]
        }
      ],
      "source": [
        "# print(train_norm_data.head())\n",
        "# print(test_norm_data.head())\n",
        "\n",
        "#smooth the normalised data\n",
        "# train_data = np.array(train_FD002[feature_list])\n",
        "# (n,m) = train_data.shape\n",
        "# print(train_data[0:4,:])\n",
        "\n",
        "train_data = np.array(train_norm_data[feature_list].copy(deep = True))\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = train_FD004['unit_number'].unique()\n",
        "l = len(feature_list)\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = train_data[train_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_train = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_train[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_train[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(l-3): #4 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_train[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = train_data[train_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_train1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_train1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_train1[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(l-3): #4 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_train1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_train = np.concatenate((smooth_data_train,smooth_data_train1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_train.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_train[smooth_data_train[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c903830b",
      "metadata": {
        "id": "c903830b",
        "outputId": "992e927a-ac28-4804-b4b5-4d3520efa4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40718, 11)\n"
          ]
        }
      ],
      "source": [
        "# print(train_norm_data.head())\n",
        "# print(test_norm_data.head())\n",
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3',\n",
        "                's_2','s_8','s_14','s_16','RUL','label']\n",
        "#smooth the normalised data\n",
        "# train_data = np.array(train_FD002[feature_list])\n",
        "# (n,m) = train_data.shape\n",
        "# print(train_data[0:4,:])\n",
        "\n",
        "test_data = np.array(test_norm_data[feature_list].copy(deep = True))\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = test_FD004['unit_number'].unique()\n",
        "l = len(feature_list)\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = test_data[test_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_test = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_test[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_test[:,l-2] = grp_data[(w-1):,l-2] #copy RUL\n",
        "smooth_data_test[:,l-1] = grp_data[(w-1):,l-1] #copy label\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(l-4): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_test[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = test_data[test_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_test1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_test1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_test1[:,l-2] = grp_data[(w-1):,l-2] #copy RUL\n",
        "    smooth_data_test1[:,l-1] = grp_data[(w-1):,l-1] #copy label\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(l-4): #4 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_test1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_test = np.concatenate((smooth_data_test,smooth_data_test1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_test.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_test[smooth_data_test[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b7fdb5",
      "metadata": {
        "id": "b6b7fdb5"
      },
      "source": [
        "### d) Denormalization (target) - 2 levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba34526",
      "metadata": {
        "id": "eba34526"
      },
      "outputs": [],
      "source": [
        "# Inverse transform the target/outout data from normalized to original\n",
        "# Note that there are two levels of denormalization\n",
        "\n",
        "def d_norm(data,option,label,cparam1, cparam2, param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # param:parameters applied while normalization (training data statistics)\n",
        "    # data is 1-D column vector\n",
        "    # cparam: list of parameters for each cluster (cluster data statistics)\n",
        "\n",
        "    #convert the vector to dataframe and add labels\n",
        "    target = pd.DataFrame(data, columns = ['actual'])\n",
        "    target['label'] = label\n",
        "    inv_data = target.copy(deep = True)\n",
        "    #print(inv_data.head())\n",
        "\n",
        "\n",
        "\n",
        "    if option == \"std\":  #z-score denormalization\n",
        "\n",
        "        for i in range(6):   #for 6 clusters\n",
        "            cluster = inv_data[inv_data['label']== i].copy(deep = True)\n",
        "            #print(cluster.head())\n",
        "            miu = cparam1[i]['RUL']\n",
        "            sigma = cparam2[i]['RUL']\n",
        "            df_norm = cluster['actual']*sigma+miu\n",
        "            #print(df_norm.head())\n",
        "            #idx = inv_data[inv_data['label']== i].index\n",
        "            #inv_data.iloc[idx.tolist(),0] = df_norm\n",
        "            inv_data.loc[inv_data['label']== i,'actual'] = df_norm\n",
        "\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data1 = inv_data['actual']*sigma+miu\n",
        "\n",
        "\n",
        "    else : #MinMax denormalization\n",
        "\n",
        "        for i in range(6):\n",
        "            cluster = inv_data[inv_data['label']== i].copy(deep = True)\n",
        "            #print(cluster.head())\n",
        "            min_val = cparam1[i]['RUL']\n",
        "            range_val = cparam2[i]['RUL']\n",
        "            df_norm = cluster['actual']*range_val+min_val\n",
        "            #print(df_norm.head())\n",
        "            idx = inv_data[inv_data['label']== i].index\n",
        "            inv_data.loc[inv_data['label']== i,'actual'] = df_norm\n",
        "\n",
        "        m = param1\n",
        "        r = param2\n",
        "        inv_data1 = inv_data['actual']*r+m\n",
        "\n",
        "    #print (inv_data1.to_numpy())\n",
        "\n",
        "    return inv_data1.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff23f058",
      "metadata": {
        "id": "ff23f058"
      },
      "source": [
        "### d) Denormalization (target) - 1 level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517b812a",
      "metadata": {
        "id": "517b812a"
      },
      "outputs": [],
      "source": [
        "# Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def d_norm_1(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # param:parameters applied while normalization (training data statistics)\n",
        "    # data is 1-D column vector\n",
        "\n",
        "\n",
        "\n",
        "    if option == \"std\":  #z-score denormalization\n",
        "\n",
        "\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data1 = data*sigma+miu\n",
        "\n",
        "\n",
        "    else : #MinMax denormalization\n",
        "\n",
        "            m = param1\n",
        "            r = param2\n",
        "            inv_data1 = data*r+m\n",
        "\n",
        "    #print (inv_data1.to_numpy())\n",
        "\n",
        "    return inv_data1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eee83bf",
      "metadata": {
        "id": "6eee83bf"
      },
      "source": [
        "### Minmax normalisation and smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97cd9b9",
      "metadata": {
        "id": "f97cd9b9"
      },
      "outputs": [],
      "source": [
        "#Train data normalisation and smoothing\n",
        "\n",
        "select_data_train = np.array(train_FD004[feature_list].copy(deep=True))\n",
        "train_data, p1, p2 = data_transform(select_data_train[:,2:],option = 'minmax') #drop unit_number and time_cycles\n",
        "\n",
        "#add unit_number and time_cycles to train_data\n",
        "train_data = np.concatenate((select_data_train[:,0:2], train_data),axis = 1)\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = train_FD004['unit_number'].unique()\n",
        "\n",
        "l = len(feature_list)\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = train_data[train_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_train = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_train[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_train[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(l-3): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_train[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = train_data[train_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_train1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_train1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_train1[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(l-3): #21 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_train1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_train = np.concatenate((smooth_data_train,smooth_data_train1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_train.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_train[smooth_data_train[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd1202c",
      "metadata": {
        "id": "7dd1202c",
        "outputId": "45b93fd7-b742-4683-cb78-cc38d7bcdd36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(40718, 10)\n"
          ]
        }
      ],
      "source": [
        "#Test data normalisation and smoothing\n",
        "#1. Normalize using training data statistics\n",
        "select_data_test = np.array(test_FD004[feature_list].copy(deep=True))\n",
        "\n",
        "#perform min-max normalization\n",
        "min_val = p1\n",
        "rng = p2\n",
        "test_data = (select_data_test[:,2:]-min_val)/rng\n",
        "\n",
        "#add unit_number and time_cycle\n",
        "test_data = np.concatenate((select_data_test[:,0:2], test_data),axis = 1)\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = test_FD004['unit_number'].unique()\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = test_data[test_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_test = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_test[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_test[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "\n",
        "for i in range(l-3): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_test[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = test_data[test_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_test1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_test1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_test1[:,l-1] = grp_data[(w-1):,l-1] #copy RUL\n",
        "\n",
        "\n",
        "    for i in range(l-3): #21 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_test1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_test = np.concatenate((smooth_data_test,smooth_data_test1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_test.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_test[smooth_data_test[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1465b2c",
      "metadata": {
        "id": "c1465b2c"
      },
      "source": [
        "## 3. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f2a335",
      "metadata": {
        "id": "02f2a335"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for RNN model such that the data is presented as (num_samples,seq_length,num_features)\n",
        "\n",
        "def data_preparation(data,n_past,n_future):\n",
        "    '''\n",
        "    input:\n",
        "        data :[unit_number, time_cycles,context inputs, primary inputs, output]\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'setting_1','setting_2', 'setting_3'\n",
        "        primary input (X): 's_1','s_2','s_8','s_13','s_14','s_19'\n",
        "        ouput/target (Y): 'RUL' at time step t\n",
        "        Engine unit and time cycles (U)\n",
        "    '''\n",
        "\n",
        "    n,m = data.shape\n",
        "\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    engine_data = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "\n",
        "        engine_data.append(data[i-t:i,0:2])  # first two are unit_number, time_cycles\n",
        "        context_data.append(data[i-t:i,2:5]) # then settings data\n",
        "        input_data.append(data[i-t:i, 5:m-1])  #next attributes are sensor data\n",
        "        output_data.append([data[i+k-1:i+k,m-1]])  #last column is the RUL\n",
        "\n",
        "\n",
        "\n",
        "    U = np.array(engine_data)\n",
        "    X = np.array(input_data)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(n,m)\n",
        "#    print(X.shape)\n",
        "#     print(Y.shape)\n",
        "#     print(Z.shape)\n",
        "\n",
        "\n",
        "    return U, X, Y, Z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e287f36",
      "metadata": {
        "id": "7e287f36"
      },
      "outputs": [],
      "source": [
        "#for test set label is also provided\n",
        "\n",
        "def data_preparation_test(data,n_past,n_future):\n",
        "\n",
        "    '''\n",
        "    input:\n",
        "        data :[unit_number, time_cycles,context inputs, primary inputs, output, label]\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'setting_1','setting_2', 'setting_3'\n",
        "        primary input (X): 's_1','s_2','s_8','s_13','s_14','s_19'\n",
        "        ouput/target (Y): 'RUL' at time step t\n",
        "        Engine unit and time cycles (U)\n",
        "        label : label at time step t required for denormalisation of dat\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    n,m = data.shape\n",
        "    #print(n,m)\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    engine_data = []\n",
        "\n",
        "    label_data = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "        engine_data.append(data[i-t:i,0:2])        # first two are unit_number, time_cycles\n",
        "        context_data.append(data[i-t:i,2:5])       # then settings data\n",
        "        input_data.append(data[i-t:i, 5:m-2])      # next six attributes are sensor data\n",
        "        output_data.append(data[i+k-1:i+k,m-2])    # second last column is the RUL\n",
        "        label_data.append(data[i+k-1:i+k,m-1])     #last column is label\n",
        "\n",
        "\n",
        "    U = np.array(engine_data)\n",
        "    X = np.array(input_data)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "    label = np.array(label_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return U, X, Y, Z, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee93f71a",
      "metadata": {
        "id": "ee93f71a"
      },
      "source": [
        "### a) Data preparation Training and Validation data (cluster normalised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead88267",
      "metadata": {
        "id": "ead88267",
        "outputId": "dc489640-f4a7-4312-cac2-4c5d1ae71664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(53510, 10, 4)\n",
            "(53510, 10, 3)\n",
            "(53510, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "prediction n_future = step ahead with n_past samples\n",
        "NOTE: n_future is set to 0 as the predicted step will not be k step ahead it will be at t\n",
        "unit_number is also present in columns, it will be used for selecting rows for validation set\n",
        "sensor_list = ['s_1','s_2','s_8','s_13','s_14','s_19']\n",
        "'''\n",
        "\n",
        "'''\n",
        "------------data normalised using cluster statistics----------------------------------------\n",
        "'''\n",
        "\n",
        "arr_data = train_norm_data.copy(deep = True)\n",
        "arr_data.drop('label',axis=1, inplace = True)\n",
        "# # print(arr_data.shape)\n",
        "# # print(arr_data.head())\n",
        "data = arr_data.to_numpy()\n",
        "#print(smooth_data_train.shape)\n",
        "#data = smooth_data_train\n",
        "\n",
        "'''\n",
        "The train and test data is availble. Divide the given train data into two parts train and validation,\n",
        "considering the engine unit number.\n",
        "'''\n",
        "seq_len = 10 #sequence length for lstm\n",
        "\n",
        "\n",
        "#take last rows equivalent to double the seq_len from each of the engine unit as validation data\n",
        "list_unit = train_FD004['unit_number'].unique()\n",
        "eng_data = data[data[:,0]==list_unit[0]]\n",
        "data_train = eng_data[:-2*seq_len,:]\n",
        "data_val = eng_data[-2*seq_len:,:]\n",
        "\n",
        "\n",
        "for i in range(1,len(list_unit)):\n",
        "    eng_data = data[data[:,0]==list_unit[i]]\n",
        "    data_train = np.concatenate((data_train,eng_data[:-2*seq_len,:]), axis=0)\n",
        "    data_val = np.concatenate((data_val,eng_data[-2*seq_len:,:]), axis=0)\n",
        "\n",
        "# print(data_train.shape)\n",
        "# print(data_val.shape)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "grp_data = data_train[data_train[:,0] == 1]\n",
        "U_train, X_train, Y_train, Z_train= data_preparation(grp_data,seq_len,1)  #last parameter 0 means context features excluded\n",
        "grp_data = data_val[data_val[:,0]==1]\n",
        "U_val, X_val, Y_val, Z_val = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "\n",
        "\n",
        "list_unit = list_unit[1:]\n",
        "for i in range(1,len(list_unit)):\n",
        "    grp_data = data_train[data_train[:,0] == list_unit[i]]\n",
        "    U_train1, X_train1, Y_train1, Z_train1 = data_preparation(grp_data,seq_len,1)\n",
        "    grp_data = data_val[data_val[:,0]==i]\n",
        "    U_val1, X_val1, Y_val1, Z_val1 = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    U_train = np.concatenate((U_train,U_train1),axis = 0)\n",
        "    X_train = np.concatenate((X_train,X_train1),axis = 0)\n",
        "    Y_train = np.concatenate((Y_train,Y_train1),axis = 0)\n",
        "    Z_train = np.concatenate((Z_train,Z_train1),axis = 0)\n",
        "\n",
        "\n",
        "    U_val = np.concatenate((U_val,U_val1),axis = 0)\n",
        "    X_val = np.concatenate((X_val,X_val1),axis = 0)\n",
        "    Y_val = np.concatenate((Y_val,Y_val1),axis = 0)\n",
        "    Z_val = np.concatenate((Z_val,Z_val1),axis = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Z_train.shape)\n",
        "print(Y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b604b4a2",
      "metadata": {
        "id": "b604b4a2"
      },
      "source": [
        "### b) Data preparation (min-max normalised and smooth data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473c2344",
      "metadata": {
        "id": "473c2344",
        "outputId": "4d4f840c-6488-46d2-d0a9-312e19c1dc8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(45574, 20, 4)\n",
            "(45574, 20, 3)\n",
            "(45574, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "prediction n_future = step ahead with n_past samples\n",
        "NOTE: n_future is set to 1 as the predicted step will not be k step ahead it will be at t+1\n",
        "unit_number is also present in columns, it will be used for selecting rows for validation set\n",
        "sensor_list = ['s_1','s_2','s_8','s_13','s_14','s_19']\n",
        "'''\n",
        "\n",
        "'''\n",
        "------------minmax normalised data----------------------------------------\n",
        "'''\n",
        "\n",
        "data = smooth_data_train\n",
        "\n",
        "'''\n",
        "The train and test data is availble. Divide the given train data into two parts train and validation,\n",
        "considering the engine unit number.\n",
        "'''\n",
        "seq_len = 20 #sequence length for lstm\n",
        "\n",
        "\n",
        "#take last rows equivalent to double the seq_len from each of the engine unit as validation data\n",
        "list_unit = train_FD004['unit_number'].unique()\n",
        "eng_data = data[data[:,0]==list_unit[0]]\n",
        "data_train = eng_data[:-2*seq_len,:]\n",
        "data_val = eng_data[-2*seq_len:,:]\n",
        "\n",
        "\n",
        "for i in range(1,len(list_unit)):\n",
        "    eng_data = data[data[:,0]==list_unit[i]]\n",
        "    data_train = np.concatenate((data_train,eng_data[:-2*seq_len,:]), axis=0)\n",
        "    data_val = np.concatenate((data_val,eng_data[-2*seq_len:,:]), axis=0)\n",
        "\n",
        "# print(data_train.shape)\n",
        "# print(data_val.shape)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "grp_data = data_train[data_train[:,0] == 1]\n",
        "U_train, X_train, Y_train, Z_train= data_preparation(grp_data,seq_len,1)  #last parameter 0 means context features excluded\n",
        "grp_data = data_val[data_val[:,0]==1]\n",
        "U_val, X_val, Y_val, Z_val = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "\n",
        "\n",
        "list_unit = list_unit[1:]\n",
        "for i in range(1,len(list_unit)):\n",
        "    grp_data = data_train[data_train[:,0] == list_unit[i]]\n",
        "    U_train1, X_train1, Y_train1, Z_train1 = data_preparation(grp_data,seq_len,1)\n",
        "    grp_data = data_val[data_val[:,0]==i]\n",
        "    U_val1, X_val1, Y_val1, Z_val1 = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    U_train = np.concatenate((U_train,U_train1),axis = 0)\n",
        "    X_train = np.concatenate((X_train,X_train1),axis = 0)\n",
        "    Y_train = np.concatenate((Y_train,Y_train1),axis = 0)\n",
        "    Z_train = np.concatenate((Z_train,Z_train1),axis = 0)\n",
        "\n",
        "\n",
        "    U_val = np.concatenate((U_val,U_val1),axis = 0)\n",
        "    X_val = np.concatenate((X_val,X_val1),axis = 0)\n",
        "    Y_val = np.concatenate((Y_val,Y_val1),axis = 0)\n",
        "    Z_val = np.concatenate((Z_val,Z_val1),axis = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Z_train.shape)\n",
        "print(Y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0528e02b",
      "metadata": {
        "id": "0528e02b"
      },
      "source": [
        "## 4. Loading data into PyTorch Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5510f9",
      "metadata": {
        "id": "aa5510f9",
        "outputId": "521bf472-029c-4496-f6af-5f10671be3ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 10, 4]) torch.Size([128, 10, 3]) torch.Size([128, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size =128\n",
        "\n",
        "#transform the arrays into torch tensors\n",
        "train_features = torch.Tensor(X_train)  #drop unit_number and test_cycles\n",
        "train_targets = torch.Tensor(Y_train)\n",
        "train_cx_features = torch.Tensor(Z_train)\n",
        "\n",
        "val_features = torch.Tensor(X_val)\n",
        "val_targets = torch.Tensor(Y_val)\n",
        "val_cx_features = torch.Tensor(Z_val)\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features,train_cx_features, train_targets)\n",
        "val = TensorDataset(val_features, val_cx_features,val_targets)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples,context,targets = examples.next()\n",
        "print(samples.shape, context.shape,targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Hyperparameter tuning using Optuna"
      ],
      "metadata": {
        "id": "zVBHHTluT_BW"
      },
      "id": "zVBHHTluT_BW"
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter optimization with optuna\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[2]\n",
        "output_dim = Y_train.shape[2]\n",
        "context_dim = Z_train.shape[2]\n",
        "\n",
        "weight_decay = 1e-6\n",
        "dropout = 0.1\n",
        "n_epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    params1 = {\n",
        "              'input_dim':input_dim,\n",
        "              'output_dim': output_dim,\n",
        "              'context_dim': context_dim,\n",
        "              'hidden_dim':trial.suggest_int('hidden_size',10,30,5),\n",
        "              }\n",
        "\n",
        "    params2 = {\n",
        "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
        "                'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              }\n",
        "\n",
        "    #model = get_model('gru',params1)\n",
        "    model = ContextGRU(input_dim, params1['hidden_dim'], output_dim, context_dim)\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"], weight_decay=weight_decay)\n",
        "    optimizer = getattr(optim, params2['optimizer'])(model.parameters(), lr= params2['learning_rate'], weight_decay=weight_decay)\n",
        "    opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "    train_loss = opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "    opt.plot_losses()\n",
        "\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "\n",
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))\n",
        "\n"
      ],
      "metadata": {
        "id": "92cotI_rUGm-"
      },
      "id": "92cotI_rUGm-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f263054",
      "metadata": {
        "id": "4f263054"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "76c3ad92",
      "metadata": {
        "id": "76c3ad92"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_dim = X_train.shape[2]\n",
        "output_dim = Y_train.shape[2]\n",
        "context_dim = Z_train.shape[2]\n",
        "\n",
        "hidden_dim = 10\n",
        "layer_dim = 1\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "n_epochs = 100\n",
        "learning_rate = 0.0008\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model = ContextGRU(input_dim, hidden_dim, output_dim, context_dim)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "params_list = model.parameters()\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "optimizer = optim.Adam(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "#optimizer = optim.RMSprop(params_list, lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=weight_decay)\n",
        "#optimizer = optim.SGD(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "opt.plot_losses()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fc8332",
      "metadata": {
        "id": "21fc8332"
      },
      "source": [
        "## 7. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5389658",
      "metadata": {
        "id": "c5389658",
        "outputId": "37b360db-0656-4377-8d3b-8dd9271eb687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Average RMSE: 11.5839\t Std RMSE: 3.2841]\n",
            "[Average SCORE: 319.6053\t Std SCORE: 235.8733]\n",
            "[Engine unit#: 52\t Min RMSE: 2.6958]\n",
            "[Engine unit#: 166\t Max RMSE: 20.5437]\n",
            "[Engine unit#: 19\t Min score: 9.9204]\n",
            "[Engine unit#: 180\t Max score: 1913.5248]\n",
            "torch.return_types.mode(\n",
            "values=tensor(2.6958, dtype=torch.float64),\n",
            "indices=tensor(51))\n",
            "torch.return_types.mode(\n",
            "values=tensor(9.9204),\n",
            "indices=tensor(18))\n"
          ]
        }
      ],
      "source": [
        "#Data prepartion for test data\n",
        "#colums: unit_number,time_cycles,setting_1,setting_2,setting_3,s_1,s_2,s_8,s_13,s_14,s_19,RUL,labels\n",
        "\n",
        "seq_len = 10  #sequence length for lstm\n",
        "#save_path = './Results/A-CiRNN/FD004/'\n",
        "\n",
        "test_arr_data = test_norm_data.copy(deep = True)\n",
        "#test_arr_data.drop('label',axis=1, inplace = True)\n",
        "data_test = test_arr_data.to_numpy()  #label is the last column, needed for denormalization\n",
        "\n",
        "#data_test = smooth_data_test\n",
        "\n",
        "list_unit = test_FD004['unit_number'].unique()\n",
        "\n",
        "\n",
        "#parameters required for inverse transform (cluster statistics)\n",
        "cpar1 = param1\n",
        "cpar2 = param2\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]  #parameter for 'RUL'  (mean/miu)\n",
        "par2 = p2[-1]  #parameter for 'RUL'  (range/sigma)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "#list_unit = []\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "fig_count = 0\n",
        "\n",
        "for i in list_unit:\n",
        "\n",
        "    fig_count=fig_count+1\n",
        "\n",
        "\n",
        "    grp_data = data_test[data_test[:,0] == i]\n",
        "    U_test, X_test, Y_test, Z_test, Y_labels = data_preparation_test(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    test_features = torch.Tensor(X_test)\n",
        "    test_targets = torch.Tensor(Y_test)\n",
        "    test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "    test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "    #test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "    #flatten the multi-dimension array to 1-D array\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "    #Apply inverse transform\n",
        "    #reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "    #target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "    #pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "\n",
        "    #1 level denormalise the target\n",
        "    target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "    pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "#     if (fig_count % 15 == 0):\n",
        "#         plot_results(i, target_val,pred_val)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['Engine'] = [i] * len(target_val)\n",
        "    df['Actual_RUL'] = list(target_val[0:,0])\n",
        "    df['Pred_RUL'] = list(pred_val[0:,0])\n",
        "    df.to_csv(save_path+ str(i) + '.csv', index = False)\n",
        "\n",
        "    result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "    result_rmse.append(result_metrics['rmse'])\n",
        "    result_r2.append(result_metrics['r2'])\n",
        "    score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "#calculate average and std of rmse,and score\n",
        "\n",
        "avg_rmse = np.mean(result_rmse)\n",
        "std_rmse = np.std(result_rmse)\n",
        "\n",
        "avg_score = np.mean(score)\n",
        "std_score = np.std(score)\n",
        "\n",
        "print(f\"[Average RMSE: {avg_rmse:.4f}\\t Std RMSE: {std_rmse:.4f}]\")\n",
        "print(f\"[Average SCORE: {avg_score:.4f}\\t Std SCORE: {std_score:.4f}]\")\n",
        "\n",
        "min_rmse = min(result_rmse)\n",
        "max_rmse = max(result_rmse)\n",
        "min_score = min(score)\n",
        "max_score = max(score)\n",
        "print(f\"[Engine unit#: {result_rmse.index(min_rmse)+1}\\t Min RMSE: {min_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {result_rmse.index(max_rmse)+1}\\t Max RMSE: {max_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(min_score)+1}\\t Min score: {min_score:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(max_score)+1}\\t Max score: {max_score:.4f}]\")\n",
        "\n",
        "\n",
        "print(torch.mode(torch.tensor(result_rmse),0))\n",
        "print(torch.mode(torch.tensor(score),0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab048d3",
      "metadata": {
        "id": "aab048d3",
        "outputId": "58726381-26b7-474d-b112-afba9ca8e145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Text(0.5, 0, 'SCORE values')]"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Plot the distribution of RMSE and score\n",
        "\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(8,4))\n",
        "plot1 = sns.histplot(result_rmse, kde = 'True', ax = axes[0])\n",
        "plot1.lines[0].set_color('crimson')\n",
        "plot1.set(xlabel = 'RMSE values')\n",
        "plot2 = sns.histplot(score, kde = 'True', ax = axes[1])\n",
        "plot2.lines[0].set_color('crimson')\n",
        "plot2.set(xlabel = 'SCORE values')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d22d38",
      "metadata": {
        "id": "89d22d38"
      },
      "source": [
        "### Testing (minmax normalised data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "07d82e07",
      "metadata": {
        "id": "07d82e07"
      },
      "outputs": [],
      "source": [
        "#Data prepartion for test data\n",
        "#colums: unit_number,time_cycles,setting_1,setting_2,setting_3,s_1,s_2,s_8,s_13,s_14,s_19,RUL,labels\n",
        "\n",
        "seq_len = 20  #sequence length for lstm\n",
        "\n",
        "\n",
        "\n",
        "data_test = smooth_data_test\n",
        "\n",
        "list_unit = test_FD004['unit_number'].unique()\n",
        "\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]  #parameter for 'RUL'  (mean/miu)\n",
        "par2 = p2[-1]  #parameter for 'RUL'  (range/sigma)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "#list_unit = [83]\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "for i in list_unit:\n",
        "\n",
        "    grp_data = data_test[data_test[:,0] == i]\n",
        "    U_test, X_test, Y_test, Z_test = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "    if len(X_test) == 0:\n",
        "        continue\n",
        "\n",
        "    test_features = torch.Tensor(X_test)\n",
        "    test_targets = torch.Tensor(Y_test)\n",
        "    test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "    test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "    #test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "    #flatten the multi-dimension array to 1-D array\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "    #Apply inverse transform\n",
        "    #reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "    #target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "    #pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "\n",
        "    #1 level denormalise the target\n",
        "    target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "    pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "    #plot_results(i, target_val,pred_val)\n",
        "\n",
        "    result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "    result_rmse.append(result_metrics['rmse'])\n",
        "    result_r2.append(result_metrics['r2'])\n",
        "    score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "#calculate average and std of rmse,and score\n",
        "\n",
        "avg_rmse = np.mean(result_rmse)\n",
        "std_rmse = np.std(result_rmse)\n",
        "\n",
        "avg_score = np.mean(score)\n",
        "std_score = np.std(score)\n",
        "\n",
        "print(f\"[Average RMSE: {avg_rmse:.4f}\\t Std RMSE: {std_rmse:.4f}]\")\n",
        "print(f\"[Average SCORE: {avg_score:.4f}\\t Std SCORE: {std_score:.4f}]\")\n",
        "\n",
        "\n",
        "min_rmse = min(result_rmse)\n",
        "max_rmse = max(result_rmse)\n",
        "min_score = min(score)\n",
        "max_score = max(score)\n",
        "print(f\"[Engine unit#: {result_rmse.index(min_rmse)+1}\\t Min RMSE: {min_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {result_rmse.index(max_rmse)+1}\\t Max RMSE: {max_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(min_score)+1}\\t Min score: {min_score:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(max_score)+1}\\t Max score: {max_score:.4f}]\")\n",
        "\n",
        "\n",
        "print(torch.mode(torch.tensor(result_rmse),0))\n",
        "print(torch.mode(torch.tensor(score),0))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b41d497e",
      "metadata": {
        "id": "b41d497e",
        "outputId": "c87e79e9-b2db-4637-a83c-ae4aeb4b17a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16.207552357403284]\n",
            "[4404462.044854962]\n"
          ]
        }
      ],
      "source": [
        "# Test the whole data (not engine-wise)\n",
        "#Data prepartion for test data\n",
        "\n",
        "seq_len = 10  #sequence length for lstm\n",
        "#cols = [0,1,2,3,4,5,6,13,18,19,24,26]   #0: unit number,1:time_cycles, 2,3,4 : 3 settings, 5,6,13,18,19: sensor data, 26:RUL\n",
        "test_arr_data = test_norm_data.copy(deep = True)\n",
        "\n",
        "#remove labels for prediction task\n",
        "#test_arr_data.drop('label',axis=1, inplace = True)\n",
        "data_test = test_arr_data.to_numpy()\n",
        "\n",
        "#data_test = smooth_data_test\n",
        "\n",
        "#parameters required for inverse transform (cluster statistics)\n",
        "cpar1 = param1\n",
        "cpar2 = param2\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]\n",
        "par2 = p2[-1]\n",
        "\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "\n",
        "U_test, X_test, Y_test, Z_test, Y_labels = data_preparation_test(data_test,seq_len,1)\n",
        "\n",
        "test_features = torch.Tensor(X_test)\n",
        "test_targets = torch.Tensor(Y_test)\n",
        "test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "#test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "#flatten the multi-dimension array to 1-D array\n",
        "vals = np.concatenate(values, axis=0).ravel()\n",
        "preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "\n",
        "#Apply denormalization transform\n",
        "#reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "# target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels, cpar1, cpar2, par1,par2)\n",
        "# pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels, cpar1, cpar2,par1,par2)\n",
        "\n",
        "\n",
        "target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "\n",
        "#plot_results(i, target_val,pred_val)\n",
        "\n",
        "#smooth the values\n",
        "#sm_pred_val = moving_average(pred_val, 10) #3 is window size\n",
        "\n",
        "result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "result_rmse.append(result_metrics['rmse'])\n",
        "result_r2.append(result_metrics['r2'])\n",
        "score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "print(result_rmse)\n",
        "print(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486c966b",
      "metadata": {
        "id": "486c966b",
        "outputId": "b847024d-2f9a-4192-a576-7bf2b369f2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(41204, 1)\n"
          ]
        }
      ],
      "source": [
        "print(target_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e21c8c",
      "metadata": {
        "id": "a5e21c8c",
        "outputId": "40384e48-3307-44da-9579-620fe1d879b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# sns.set_palette(\"bright\")\n",
        "# sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "series1 = moving_average(target_val[1000:2200,0],5)\n",
        "series2 = moving_average(pred_val[1000:2200,0],5)\n",
        "plot_results(10, series1, series2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c6e910",
      "metadata": {
        "id": "22c6e910"
      },
      "outputs": [],
      "source": [
        "#Plot the results Engine Unit wise\n",
        "def plot_results(unit_num, target_val,pred_val):\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1,2,1).set_title(\"Engine Unit #\" + str(unit_num))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(target_val,'r')\n",
        "    plt.plot(pred_val,'b')\n",
        "    plt.xlabel('Time (Cycles)')\n",
        "    plt.ylabel('RUL')\n",
        "    plt.legend(['Actual RUL','Predicted RUL'])\n",
        "\n",
        "#     plt.subplot(1,2,2).set_title(\"Engine Unit #\" + str(unit_num))\n",
        "#     plt.plot(target_val,pred_val,'.r')\n",
        "#     plt.xlabel('Actual RUL')\n",
        "#     plt.ylabel('Predcited RUL')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f129080",
      "metadata": {
        "id": "5f129080"
      },
      "source": [
        "### Calculate Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f8b7eb",
      "metadata": {
        "id": "79f8b7eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calculate_metrics(actual, predicted):\n",
        "\n",
        "    return {'mae' : mean_absolute_error(actual,predicted),\n",
        "            'rmse' : mean_squared_error(actual,predicted) ** 0.5,\n",
        "            'r2' : r2_score(actual,predicted)}\n",
        "\n",
        "# result_metrics = calculate_metrics(target_val, pred_val)\n",
        "# print(result_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1976db26",
      "metadata": {
        "id": "1976db26"
      },
      "source": [
        "### Calculate Asymmetric score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772cc745",
      "metadata": {
        "id": "772cc745"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "#call this function for each unit, and sum to get the overall score\n",
        "def calculate_score(actual, predicted):\n",
        "#calcualate score for one engine unit\n",
        "    s = 0\n",
        "    a1 = 10 #constant\n",
        "    a2 = 13\n",
        "    s_list = []\n",
        "    d_list = predicted - actual\n",
        "    for i in range(len(actual)):\n",
        "        d = predicted[i]-actual[i]\n",
        "\n",
        "        if d >= 0:\n",
        "            #s = s+(math.exp(d/a2)-1)\n",
        "            s = (math.exp(d/a2)-1)\n",
        "            s_list.append(s)\n",
        "\n",
        "        else:\n",
        "\n",
        "            #s = s+(math.exp(-d/a1)-1)\n",
        "            s = (math.exp(-d/a1)-1)\n",
        "            s_list.append(s)\n",
        "\n",
        "#     plt.figure()\n",
        "#     plt.plot(d_list,s_list,'.')\n",
        "\n",
        "    return sum(s_list)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}