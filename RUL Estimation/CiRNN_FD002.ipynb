{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8b105c",
      "metadata": {
        "id": "ab8b105c",
        "outputId": "c783a5ec-6de5-479d-ca66-abc86b533f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc2089ddeb0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "seed = 40\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "\n",
        "import random\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.pyplot import *\n",
        "#style.use('ggplot')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.profiler\n",
        "import torch.autograd.profiler as profiler\n",
        "from scipy import stats as st\n",
        "import sklearn.preprocessing as preprocess\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6be63e",
      "metadata": {
        "id": "9c6be63e"
      },
      "source": [
        "# Context Integrated RNN - CiRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85c75a2",
      "metadata": {
        "id": "e85c75a2",
        "outputId": "588f58db-3337-4e46-b3ef-e3ea375bd7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get CPU or GPU device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class ContextGRU(torch.nn.Module):\n",
        "    \"\"\"\n",
        "     simple GRU cell network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, context_dim):\n",
        "        super(ContextGRU, self).__init__()\n",
        "\n",
        "        self.n_x = input_dim\n",
        "        self.n_h = hidden_dim\n",
        "        self.n_y = output_dim\n",
        "        self.n_z = context_dim\n",
        "        self.m = 9  #dimension of basis function vector (polynomial features) for 3 context features\n",
        "\n",
        "\n",
        "        # reset gate components\n",
        "        self.linear_reset_w1 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r1 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "\n",
        "\n",
        "        self.linear_reset_w2 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r2 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_1 = nn.Sigmoid()\n",
        "\n",
        "        # update gate components\n",
        "        self.linear_gate_w3 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_gate_r3 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_2 = nn.Sigmoid()\n",
        "\n",
        "        self.activation_3 = nn.Tanh()\n",
        "\n",
        "        #output\n",
        "        self.linear_output = nn.Linear(self.n_h, self.n_y, bias=True)\n",
        "\n",
        "\n",
        "    def reset_gate(self, xg, h):  #xg is the kronecker product of x and  basis function G(z)\n",
        "        x_1 = self.linear_reset_w1(xg)\n",
        "        h_1 = self.linear_reset_r1(h)\n",
        "        # gate update\n",
        "        r = self.activation_1(x_1 + h_1)\n",
        "        return r\n",
        "\n",
        "    def update_gate(self, xg, h):\n",
        "        x_2 = self.linear_reset_w2(xg)\n",
        "        h_2 = self.linear_reset_r2(h)\n",
        "        s = self.activation_2( h_2 + x_2)\n",
        "        return s\n",
        "\n",
        "\n",
        "    def update_component(self, xg, h, r):\n",
        "        x_3 = self.linear_gate_w3(xg)\n",
        "        h_3 = r * self.linear_gate_r3(h)\n",
        "        h_tilda = self.activation_3(x_3+h_3)\n",
        "        return h_tilda\n",
        "\n",
        "\n",
        "    def compute_output(self,h):\n",
        "        y_pred = self.linear_output(h)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def cell_forward(self, x, h, G):\n",
        "\n",
        "        \"\"\"\n",
        "        Implements a single forward step of the Context GRU-cell\n",
        "\n",
        "        Input Arguments:\n",
        "            x (mini-batch): input x at time step t , (n,n_x) : (batch_size, input_dim)\n",
        "            h : hidden state at time step t-1, (n,n_h) : (batch_size, hidden_dim)\n",
        "            G : vector of basis funcitons (m,n)\n",
        "\n",
        "        Returns:\n",
        "            h_new: hidden state at time step t, (n,n_h)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # kronecker product of x and G(zt)\n",
        "        n = x.shape[0]\n",
        "        xg = torch.zeros(n,self.n_x*self.m).to(device)\n",
        "\n",
        "        for i in range(n):\n",
        "\n",
        "            xg[i,:] = torch.kron(x[i,:],G[:,i])\n",
        "\n",
        "\n",
        "        # Equation 1. reset gate vector\n",
        "        r = self.reset_gate(xg, h)\n",
        "\n",
        "        # Equation 2: the update gate - the shared update gate vector z\n",
        "        s = self.update_gate(xg, h)\n",
        "\n",
        "        # Equation 3: The almost output component\n",
        "        h_tilda = self.update_component(xg,h,r)\n",
        "\n",
        "        # Equation 4: the new hidden state\n",
        "        h_new = (1-s) * h_tilda  + s * h\n",
        "\n",
        "        #output\n",
        "\n",
        "        y_pred = self.compute_output(h)\n",
        "\n",
        "        return h_new, y_pred\n",
        "\n",
        "\n",
        "    def forward(self, x, z):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the forward propagation of the recurrent neural network\n",
        "\n",
        "        Input Arguments:\n",
        "        x (mini_batch): primary input for every time-step in mini-batches of shape (n, T, n_x)\n",
        "        z (mini_batch): context input for every time-step in mini-batches of shape (n,T,n_z)\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            h -- Hidden states for every time-step, numpy array of shape (n, T, n_h)\n",
        "            y_pred -- Predictions for every time-step, numpy array of shape (n, T, n_y),\n",
        "            here T is 1 for Seq to Vec RNN\n",
        "        \"\"\"\n",
        "\n",
        "        # Retrieve dimensions from shapes of x\n",
        "        #print(x.shape)\n",
        "        #print(z.shape)\n",
        "        n,T,n_x = x.shape\n",
        "        n_y = self.n_y\n",
        "        n_h = self.n_h\n",
        "        n_z = self.n_z\n",
        "\n",
        "\n",
        "\n",
        "        # initialize \"h\"\n",
        "\n",
        "        h = self.init_hidden(n,T,n_h)\n",
        "\n",
        "        #y_pred = np.zeros((m,T_x,n_y))\n",
        "        #y_pred is single value for one sample, m=1\n",
        "\n",
        "        #basis function vector\n",
        "        G = self.apply_basis(z[:,0,:])  #G: size of (n,m)\n",
        "\n",
        "        #for initial time step the hidden state is 0\n",
        "        h_temp = h.clone()\n",
        "        h_init = h_temp[:,0,:]\n",
        "        h_curr, y_curr = self.cell_forward(x[:,0,:],h_init,torch.t(G))\n",
        "\n",
        "        # loop over all time-steps\n",
        "        for t in range(1,T):\n",
        "\n",
        "            #compute the vector of basis functions\n",
        "\n",
        "            G = self.apply_basis(z[:,t,:])  #G: size of (n,m)\n",
        "\n",
        "            # Update next hidden state\n",
        "            # ignore yt_pred for seq to vector\n",
        "            h[:,t,:]= h_curr\n",
        "            h_temp = h.clone()\n",
        "            h_prev = h_temp[:,t,:]  #h_prev: (n,n_h)\n",
        "            h_curr, y_curr = self.cell_forward(x[:,t,:],h_prev, torch.t(G))\n",
        "\n",
        "            #y_pred[t,:] = yt_pred\n",
        "\n",
        "\n",
        "        #compute the predicted output from the last cell i.e at last time step T\n",
        "        y_pred = torch.zeros(n,1,1,device = 'cuda:0')\n",
        "\n",
        "        #get the value of y_pred from the last cell\n",
        "        y_pred[:,0,:] = y_curr\n",
        "\n",
        "        #print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "        return h, y_pred\n",
        "\n",
        "\n",
        "    def init_hidden(self, n:int,T:int, n_h:int):\n",
        "        #initialise the hidden state\n",
        "        #n : batch-size\n",
        "        #T : Input sequence length\n",
        "        #returns h of size (n,T,n_h)\n",
        "        return torch.zeros(n,T,n_h,device = 'cuda:0')\n",
        "\n",
        "\n",
        "    def apply_basis(self,zt):\n",
        "        '''\n",
        "        apply the basis function: polynomial degree 2\n",
        "        [z0, z1, z2, z0z0, z0z1, z0z2....]\n",
        "        input arguments:\n",
        "            zt: context vector (n,n_z) for mini-batch of size n and n_z context dim\n",
        "        Returns:\n",
        "            G : tensor of basis functions, (m,n)\n",
        "\n",
        "        for 3 context features m = 9\n",
        "        '''\n",
        "\n",
        "        #poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
        "        poly = PolynomialFeatures(2, include_bias=False)\n",
        "        G = torch.tensor(poly.fit_transform(zt.cpu().numpy())).to(device) #fit_transform returns nd array\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return G\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999d31f3",
      "metadata": {
        "id": "999d31f3"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.weights = []      #used for visualising weights\n",
        "        self.settings = []     #saving settings for visualising weights\n",
        "        self.inputs = []       #saving input for visualising\n",
        "\n",
        "    def train_step(self, x, y, z):\n",
        "\n",
        "       # with profiler.record_function(\"TRAIN STEP FUNCTION\"):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        h, yhat = self.model(x, z)\n",
        "\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        #with profiler.record_function(\"LOSS_BACKWARD\"):\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size, n_epochs=50, np_features=1, nc_features=1):\n",
        "        '''\n",
        "        np_features = # primary input features\n",
        "        nc_features = # context input features\n",
        "        '''\n",
        "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "        times = []\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "            start_epoch = time.time()\n",
        "\n",
        "            batch_losses = []\n",
        "            batch_count = 0\n",
        "            for x_batch, z_batch, y_batch in train_loader:\n",
        "                batch_count += 1\n",
        "                x_batch = x_batch.view([batch_size,-1, np_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                z_batch = z_batch.view([batch_size,-1, nc_features]).to(device)\n",
        "\n",
        "                #with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                loss = self.train_step(x_batch, y_batch, z_batch)\n",
        "                #print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                batch_losses.append(loss)\n",
        "\n",
        "            # if (epoch % 10 == 0):\n",
        "            #         #if (batch_count % 200 == 0):\n",
        "            #             #save the model weights for each batch for analysis\n",
        "            #             #self.save_model(self.model, batch_count, str(z_batch[-1,:,:].detach().cpu().numpy()))\n",
        "            #     for param_tensor in model.state_dict():\n",
        "            #         if (param_tensor == 'linear_reset_w1.weight'):\n",
        "            #             param_val = model.state_dict()[param_tensor].cpu().numpy().tolist()\n",
        "            #             self.weights.append(param_val)\n",
        "            #             self.settings.append(z_batch[-1,:,:].detach().cpu().numpy().tolist())\n",
        "            #self.model.to(device)\n",
        "\n",
        "\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, z_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, np_features]).to(device, non_blocking=True)\n",
        "                    y_val = y_val.to(device)\n",
        "                    z_val = z_val.view([batch_size, -1, nc_features]).to(device,non_blocking=True)\n",
        "                    self.model.eval()\n",
        "\n",
        "                    # with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                    h,yhat = self.model(x_val, z_val)\n",
        "                    # print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch % 5 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            end_epoch = time.time()\n",
        "            elapsed = end_epoch - start_epoch\n",
        "            times.append(elapsed)\n",
        "\n",
        "        total_time = sum(times)\n",
        "        avg_time = sum(times)/n_epochs\n",
        "\n",
        "        print(f\"Average Training time: {avg_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "        print(f\"Total Training time: {total_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "\n",
        "        #torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "        return validation_loss  #this will be used by otuna to optimize\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, np_features=1, nc_features = 1):\n",
        "            with torch.no_grad():\n",
        "                predictions = []\n",
        "                values = []\n",
        "                for x_test, z_test, y_test in test_loader:\n",
        "\n",
        "                    x_test = x_test.view([batch_size,-1, np_features]).to(device, non_blocking=True)\n",
        "                    y_test = y_test.to(device)\n",
        "                    z_test = z_test.view([batch_size,-1, nc_features]).to(device, non_blocking=True)\n",
        "                    self.model.eval()\n",
        "                    h,yhat = self.model(x_test, z_test)\n",
        "                    predictions.append(yhat.detach().cpu().numpy())\n",
        "                    values.append(y_test.detach().cpu().numpy())\n",
        "\n",
        "            return predictions, values\n",
        "\n",
        "    def plot_losses(self):\n",
        "            plt.plot(self.train_losses, label=\"Training loss\")\n",
        "            plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Losses\")\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.ylabel(\"Loss(MSE)\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "    # def save_model(self, model, batch_id, settings_val):\n",
        "\n",
        "    #     path = r'/home/rashmi/PythonProjects/codes/TURBOFAN_MODELS/savedmodels/'\n",
        "    #     #save model\n",
        "    #     file_name = 'FD002_Params.txt'\n",
        "    #     file_path = os.path.join(path,file_name)\n",
        "    #     f = open(file_path, 'a')\n",
        "    #     f.write('Batch'+ str(batch_id)+'\\n')\n",
        "    #     f.write('-------\\n')\n",
        "    #     for param_tensor in model.state_dict():\n",
        "    #         param_val = model.state_dict()[param_tensor].cpu().numpy().tolist()\n",
        "    #         f.write(param_tensor + \"\\t\" + str(param_val))\n",
        "    #         f.write('\\n---------------\\n')\n",
        "    #     f.write('Settings\\n')\n",
        "    #     f.write(settings_val + '\\n')\n",
        "    #     f.write('---------------\\n')\n",
        "    #     f.write('\\n')\n",
        "\n",
        "    #     f.close()\n",
        "\n",
        "\n",
        "    def visualise_weights(self):\n",
        "\n",
        "#         col = ['r','b','g']\n",
        "#         nrows = len(self.weights)\n",
        "#         for i in range(nrows):\n",
        "#             wtmatrix = np.array(self.weights[i])\n",
        "#             print(wtmatrix.shape)\n",
        "#             fig = plt.figure()\n",
        "#             print(wtmatrix[0:9, 0:9])\n",
        "#             #plt.imshow(wtmatrix[0:9, 0:9])\n",
        "#             sns.heatmap(wtmatrix[0:10, 0:10])\n",
        "\n",
        "#         fig = plt.figure()\n",
        "#         for i in range(nrows):\n",
        "#             wtmatrix = np.array(self.weights[i])\n",
        "#             plt.plot(wtmatrix[0:10],wtmatrix [0:10],color = col[i],marker = '.')\n",
        "\n",
        "        return self.weights, self.settings, self.inputs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0211805",
      "metadata": {
        "id": "f0211805"
      },
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3febeddf",
      "metadata": {
        "id": "3febeddf"
      },
      "outputs": [],
      "source": [
        "#data load function\n",
        "#4 sets of data: FD001, FD002, FD003, FD004\n",
        "#FD001 and FD003 same operating condition 1\n",
        "#FD002 and FD004 same operating condition 6\n",
        "\n",
        "def dataload(filename):\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca73a50",
      "metadata": {
        "id": "4ca73a50"
      },
      "outputs": [],
      "source": [
        "# define path for the data\n",
        "#path ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f51afef",
      "metadata": {
        "id": "5f51afef"
      },
      "outputs": [],
      "source": [
        "train_FD002 = dataload(path+'train_FD002')\n",
        "test_FD002 = dataload(path+'test_FD002')\n",
        "#train_FD002.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ae58e26",
      "metadata": {
        "id": "9ae58e26",
        "outputId": "ded04f79-54f2-4efc-a286-7a63e577df8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_number</th>\n",
              "      <th>time_cycles</th>\n",
              "      <th>setting_1</th>\n",
              "      <th>setting_2</th>\n",
              "      <th>setting_3</th>\n",
              "      <th>s_1</th>\n",
              "      <th>s_2</th>\n",
              "      <th>s_3</th>\n",
              "      <th>s_4</th>\n",
              "      <th>s_5</th>\n",
              "      <th>...</th>\n",
              "      <th>s_13</th>\n",
              "      <th>s_14</th>\n",
              "      <th>s_15</th>\n",
              "      <th>s_16</th>\n",
              "      <th>s_17</th>\n",
              "      <th>s_18</th>\n",
              "      <th>s_19</th>\n",
              "      <th>s_20</th>\n",
              "      <th>s_21</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.9983</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.32</td>\n",
              "      <td>1358.61</td>\n",
              "      <td>1137.23</td>\n",
              "      <td>5.48</td>\n",
              "      <td>...</td>\n",
              "      <td>2387.72</td>\n",
              "      <td>8048.56</td>\n",
              "      <td>9.3461</td>\n",
              "      <td>0.02</td>\n",
              "      <td>334</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.00</td>\n",
              "      <td>14.73</td>\n",
              "      <td>8.8071</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>41.9982</td>\n",
              "      <td>0.8408</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.90</td>\n",
              "      <td>1353.22</td>\n",
              "      <td>1125.78</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>2387.66</td>\n",
              "      <td>8072.30</td>\n",
              "      <td>9.3774</td>\n",
              "      <td>0.02</td>\n",
              "      <td>330</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.41</td>\n",
              "      <td>6.2665</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>24.9988</td>\n",
              "      <td>0.6218</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.31</td>\n",
              "      <td>1256.76</td>\n",
              "      <td>1047.45</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>2028.03</td>\n",
              "      <td>7864.87</td>\n",
              "      <td>10.8941</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.08</td>\n",
              "      <td>8.6723</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>42.0077</td>\n",
              "      <td>0.8416</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.51</td>\n",
              "      <td>1354.03</td>\n",
              "      <td>1126.38</td>\n",
              "      <td>3.91</td>\n",
              "      <td>...</td>\n",
              "      <td>2387.61</td>\n",
              "      <td>8068.66</td>\n",
              "      <td>9.3528</td>\n",
              "      <td>0.02</td>\n",
              "      <td>329</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.00</td>\n",
              "      <td>10.59</td>\n",
              "      <td>6.4701</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>25.0005</td>\n",
              "      <td>0.6203</td>\n",
              "      <td>60.0</td>\n",
              "      <td>462.54</td>\n",
              "      <td>537.07</td>\n",
              "      <td>1257.71</td>\n",
              "      <td>1047.93</td>\n",
              "      <td>7.05</td>\n",
              "      <td>...</td>\n",
              "      <td>2028.00</td>\n",
              "      <td>7861.23</td>\n",
              "      <td>10.8963</td>\n",
              "      <td>0.02</td>\n",
              "      <td>309</td>\n",
              "      <td>1915</td>\n",
              "      <td>84.93</td>\n",
              "      <td>14.13</td>\n",
              "      <td>8.5286</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   unit_number  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
              "0            1            1    34.9983     0.8400      100.0  449.44  555.32   \n",
              "1            1            2    41.9982     0.8408      100.0  445.00  549.90   \n",
              "2            1            3    24.9988     0.6218       60.0  462.54  537.31   \n",
              "3            1            4    42.0077     0.8416      100.0  445.00  549.51   \n",
              "4            1            5    25.0005     0.6203       60.0  462.54  537.07   \n",
              "\n",
              "       s_3      s_4   s_5  ...     s_13     s_14     s_15  s_16  s_17  s_18  \\\n",
              "0  1358.61  1137.23  5.48  ...  2387.72  8048.56   9.3461  0.02   334  2223   \n",
              "1  1353.22  1125.78  3.91  ...  2387.66  8072.30   9.3774  0.02   330  2212   \n",
              "2  1256.76  1047.45  7.05  ...  2028.03  7864.87  10.8941  0.02   309  1915   \n",
              "3  1354.03  1126.38  3.91  ...  2387.61  8068.66   9.3528  0.02   329  2212   \n",
              "4  1257.71  1047.93  7.05  ...  2028.00  7861.23  10.8963  0.02   309  1915   \n",
              "\n",
              "     s_19   s_20    s_21  RUL  \n",
              "0  100.00  14.73  8.8071  125  \n",
              "1  100.00  10.41  6.2665  125  \n",
              "2   84.93  14.08  8.6723  125  \n",
              "3  100.00  10.59  6.4701  125  \n",
              "4   84.93  14.13  8.5286  125  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#drop the frst unnamed column\n",
        "train_FD002.drop(columns = train_FD002.columns[0],axis=1, inplace=True)\n",
        "test_FD002.drop(columns = test_FD002.columns[0],axis=1, inplace=True)\n",
        "train_FD002.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b1b404",
      "metadata": {
        "id": "69b1b404"
      },
      "source": [
        "## 2. Data Prepreprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb158818",
      "metadata": {
        "id": "fb158818"
      },
      "source": [
        "### a) Smoothing - moving average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf6727f",
      "metadata": {
        "id": "caf6727f"
      },
      "outputs": [],
      "source": [
        "#Trailing moving average\n",
        "#trail_ma(t) = mean(obs(t-2), obs(t-1), obs(t))\n",
        "\n",
        "def moving_average(x, w):\n",
        "    #x: time series\n",
        "    #w: sliding window size\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f942246f",
      "metadata": {
        "id": "f942246f"
      },
      "outputs": [],
      "source": [
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3',\n",
        "                's_1','s_2','s_8','s_13','s_14','s_19','RUL']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3d8406",
      "metadata": {
        "id": "1a3d8406"
      },
      "source": [
        "### b) Normalisation - Transform and Inverse transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80d6598",
      "metadata": {
        "id": "b80d6598"
      },
      "outputs": [],
      "source": [
        "def data_transform(data,option ='std'):\n",
        "#data is numpy array\n",
        "#option is set to std for standardization or minmax\n",
        "\n",
        "    n = data.shape[0]\n",
        "\n",
        "    if option == 'std' :\n",
        "\n",
        "        #perform standardization of data\n",
        "        miu = np.mean(data,axis = 0)\n",
        "        sigma = np.std(data,axis=0,dtype=float)\n",
        "        temp_data = data-np.tile(miu,(n,1))\n",
        "        std_data = np.divide(temp_data,np.tile(sigma,(n,1)))\n",
        "\n",
        "        return std_data, miu, sigma\n",
        "\n",
        "    elif option == 'minmax':\n",
        "\n",
        "        #perform min-max normalization\n",
        "        max_val = np.max(data,0)\n",
        "        #print(max_val)\n",
        "        min_val = np.min(data,0)\n",
        "        #print(min_val)\n",
        "        rng = max_val-min_val\n",
        "        norm_data = np.divide(data - np.tile(min_val,(n,1)),np.tile(rng,(n,1)))\n",
        "\n",
        "        return norm_data, min_val, rng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f929d8",
      "metadata": {
        "id": "c3f929d8"
      },
      "outputs": [],
      "source": [
        "## Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def inv_trans(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # params:list of parameters applied while normalization\n",
        "    # data is 1-D column vector\n",
        "#     print(data)\n",
        "#     print(param1)\n",
        "#     print(param2)\n",
        "\n",
        "    if option == \"std\":\n",
        "         #perform standardization of data\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data = data*sigma + miu\n",
        "\n",
        "        return inv_data\n",
        "\n",
        "    else : #MinMax normalization\n",
        "\n",
        "        #perform min-max normalization\n",
        "        min_val = param1\n",
        "        rng = param2\n",
        "        inv_data = data*rng+min_val\n",
        "        return inv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b36f09",
      "metadata": {
        "id": "61b36f09"
      },
      "source": [
        "### c) Clustering and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53da9a51",
      "metadata": {
        "id": "53da9a51"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3','s_1','s_2','s_8','s_13','s_14','s_19', 'RUL']\n",
        "select_data_train = np.array(train_FD002[feature_list].copy(deep=True))\n",
        "train_data, p1, p2 = data_transform(select_data_train[:,2:],option = 'minmax') #drop unit_number and time_cycles\n",
        "\n",
        "kmeans = KMeans(n_clusters=6, n_init=10, random_state=0).fit(train_data)\n",
        "\n",
        "#kmeans.labels_\n",
        "#kmeans.predict([[0, 0], [12, 3]])\n",
        "#kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86008bfc",
      "metadata": {
        "id": "86008bfc",
        "outputId": "b4e642f3-782a-4922-cb08-6bf7ca97ad52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(53759, 13)\n"
          ]
        }
      ],
      "source": [
        "col_names = ['setting_1','setting_2','setting_3','s_1','s_2','s_8', 's_13','s_14','s_19','RUL']\n",
        "#del train_data_cluster\n",
        "\n",
        "train_data_cluster = train_FD002[['unit_number','time_cycles']].copy(deep=True)\n",
        "train_data_cluster[col_names] = pd.DataFrame(train_data, columns = col_names)\n",
        "train_data_cluster['label'] = kmeans.labels_.astype(str)\n",
        "print(train_data_cluster.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ededbe",
      "metadata": {
        "id": "99ededbe"
      },
      "source": [
        "### Train data normalisation with cluster centers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2cc300",
      "metadata": {
        "id": "ad2cc300"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Normalize train data using the clusters of operational settings\n",
        "'''\n",
        "def cluster_norm(clustered_data,opt='minmax'):\n",
        "#input: clustered data - data frame, option: minmax or std (z-score)\n",
        "#output: normalised data, parameter 1: miu/min value, parameter 2: sigma/range\n",
        "#col_names = ['unit_number','time_cycle',setting_1','setting_2','setting_3','s_1','s_2','s_8',\n",
        "#            's_13','s_14','s_19','RUL','label']\n",
        "\n",
        "    n = clustered_data.shape[0]\n",
        "    norm_data = clustered_data.copy(deep = True)\n",
        "\n",
        "\n",
        "    col_names = ['setting_1','setting_2','setting_3','s_1','s_2','s_8', 's_13','s_14','s_19']\n",
        "\n",
        "    if opt == 'std':\n",
        "        #get the standard deviation of each cluster\n",
        "        clust_sigma = []\n",
        "        clust_miu = []\n",
        "        for i in range(6):  #6 is number of clusters\n",
        "            idx = clustered_data[clustered_data['label']==str(i)].index\n",
        "            cluster = clustered_data[clustered_data['label']==str(i)].copy(deep = True)\n",
        "            sigma = cluster[col_names].std(axis=1)\n",
        "            miu = cluster[col_names].mean(axis=1)\n",
        "            for j in range(len(col_names)):  #if max and min values are same then cluster column has same values\n",
        "                if (sigma[col_names[j]] == 0):\n",
        "                    sigma[col_names[j]] = 1\n",
        "                    miu[col_names[j]] = 0\n",
        "            df_norm = (cluster-miu)/sigma\n",
        "            #norm_data.loc[idx.tolist(),2:11] = df_norm\n",
        "            norm_data.loc[clustered_data['label']==str(i),col_names] = df_norm\n",
        "            clust_sigma.append(sigma)\n",
        "            clust_miu.append(miu)\n",
        "\n",
        "\n",
        "        return norm_data, clust_miu, clust_sigma\n",
        "\n",
        "\n",
        "    elif opt == 'minmax':\n",
        "\n",
        "        clust_min = []\n",
        "        clust_range = []\n",
        "\n",
        "        for i in range(6):\n",
        "            cluster = clustered_data[clustered_data['label']==str(i)].copy(deep = True)\n",
        "            #print(cluster.head())\n",
        "            min_val = cluster[col_names].min(axis=0)\n",
        "            max_val = cluster[col_names].max(axis=0)\n",
        "            range_val = max_val-min_val\n",
        "            for j in range(len(col_names)):  #if max and min values are same then cluster column has same values\n",
        "                if (range_val[col_names[j]] == 0):\n",
        "                    range_val[col_names[j]] = 1\n",
        "                    min_val[col_names[j]] = 0\n",
        "            df_norm = (cluster[col_names]-min_val)/range_val\n",
        "            #print(df_norm.head())\n",
        "            #idx = clustered_data[clustered_data['label']==str(i)].index\n",
        "            #norm_data.iloc[idx.tolist(),2:11] = df_norm\n",
        "            norm_data.loc[clustered_data['label']==str(i),col_names]=df_norm\n",
        "            clust_min.append(min_val)\n",
        "            clust_range.append(range_val)\n",
        "\n",
        "        return norm_data, clust_min, clust_range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "984ff1c8",
      "metadata": {
        "id": "984ff1c8"
      },
      "outputs": [],
      "source": [
        "# train_norm_data, param1, param2 = cluster_norm(train_data_cluster,'minmax')\n",
        "# print(train_norm_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ac0fb8",
      "metadata": {
        "id": "64ac0fb8"
      },
      "source": [
        "### Test data normalisation with cluster centers of train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3657e228",
      "metadata": {
        "id": "3657e228"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Normalize the test data using the train data cluster statistics\n",
        "'''\n",
        "col_names = ['setting_1','setting_2','setting_3','s_1','s_2','s_8', 's_13','s_14','s_19','RUL']\n",
        "col_names1 = ['setting_1','setting_2','setting_3','s_1','s_2','s_8', 's_13','s_14','s_19']\n",
        "\n",
        "#1. Normalize using training data statistics\n",
        "select_data_test = test_FD002[col_names].copy(deep=True)\n",
        "\n",
        "#perform min-max normalization\n",
        "min_val = p1\n",
        "rng = p2\n",
        "#norm_data = (smooth_data_test[:,2:]-min_val)/rng\n",
        "norm_data = (select_data_test-min_val)/rng\n",
        "#print(norm_data[0:5,0])\n",
        "\n",
        "#2. Predict the labels using kmeans model of training data\n",
        "\n",
        "labels = kmeans.predict(norm_data)\n",
        "test_data_cluster = test_FD002[['unit_number','time_cycles']].copy(deep = True)\n",
        "#test_data_cluster = pd.DataFrame(select_data_test[:,0:2],columns = ['unit_number','time_cycles'])\n",
        "test_data_cluster[col_names] = norm_data\n",
        "test_data_cluster['label'] = labels\n",
        "#print(test_data_cluster.head())\n",
        "\n",
        "#3. Normalise using cluster statistics\n",
        "clustered_data = test_data_cluster.copy(deep=True)\n",
        "\n",
        "for i in range(6):\n",
        "    cluster = clustered_data[clustered_data['label']== i].copy(deep = True)\n",
        "    #print(cluster.head())\n",
        "    min_val1 = param1[i]\n",
        "    range_val1 = param2[i]\n",
        "    df_norm = (cluster[col_names]-min_val1)/range_val1\n",
        "    #print(df_norm.head())\n",
        "    idx = clustered_data[clustered_data['label']== i].index\n",
        "    #clustered_data.iloc[idx.tolist(),2:11] = 100\n",
        "    clustered_data.loc[clustered_data['label']== i,col_names1] = df_norm\n",
        "\n",
        "\n",
        "test_norm_data = clustered_data.copy(deep = True)\n",
        "\n",
        "print(test_norm_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fa46bd2",
      "metadata": {
        "id": "9fa46bd2"
      },
      "source": [
        "### Smoothing the cluster normalised data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04857b8",
      "metadata": {
        "id": "b04857b8",
        "outputId": "b0f7a684-dde8-4300-a5d4-06b085d0a27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(53239, 12)\n"
          ]
        }
      ],
      "source": [
        "# print(train_norm_data.head())\n",
        "# print(test_norm_data.head())\n",
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3',\n",
        "                's_1','s_2','s_8','s_13','s_14','s_19','RUL']\n",
        "#smooth the normalised data\n",
        "# train_data = np.array(train_FD002[feature_list])\n",
        "# (n,m) = train_data.shape\n",
        "# print(train_data[0:4,:])\n",
        "\n",
        "train_data = np.array(train_norm_data[feature_list].copy(deep = True))\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = train_FD002['unit_number'].unique()\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = train_data[train_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_train = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_train[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_train[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(9): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_train[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = train_data[train_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_train1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_train1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_train1[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(9): #21 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_train1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_train = np.concatenate((smooth_data_train,smooth_data_train1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_train.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_train[smooth_data_train[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c903830b",
      "metadata": {
        "id": "c903830b",
        "outputId": "9c0d94da-bd48-41c6-87f2-1307bc78a88f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(33473, 13)\n"
          ]
        }
      ],
      "source": [
        "# print(train_norm_data.head())\n",
        "# print(test_norm_data.head())\n",
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3',\n",
        "                's_1','s_2','s_8','s_13','s_14','s_19','RUL','label']\n",
        "#smooth the normalised data\n",
        "# train_data = np.array(train_FD002[feature_list])\n",
        "# (n,m) = train_data.shape\n",
        "# print(train_data[0:4,:])\n",
        "\n",
        "test_data = np.array(test_norm_data[feature_list].copy(deep = True))\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = test_FD002['unit_number'].unique()\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = test_data[test_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_test = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_test[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_test[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "smooth_data_test[:,12] = grp_data[(w-1):,12] #copy label\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(9): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_test[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = test_data[test_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_test1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_test1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_test1[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "    smooth_data_test1[:,12] = grp_data[(w-1):,12] #copy label\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(9): #21 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_test1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_test = np.concatenate((smooth_data_test,smooth_data_test1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_test.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_test[smooth_data_test[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b7fdb5",
      "metadata": {
        "id": "b6b7fdb5"
      },
      "source": [
        "### d) Denormalization (target) - 2 levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba34526",
      "metadata": {
        "id": "eba34526"
      },
      "outputs": [],
      "source": [
        "# Inverse transform the target/outout data from normalized to original\n",
        "# Note that there are two levels of denormalization\n",
        "\n",
        "def d_norm(data,option,label,cparam1, cparam2, param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # param:parameters applied while normalization (training data statistics)\n",
        "    # data is 1-D column vector\n",
        "    # cparam: list of parameters for each cluster (cluster data statistics)\n",
        "\n",
        "    #convert the vector to dataframe and add labels\n",
        "    target = pd.DataFrame(data, columns = ['actual'])\n",
        "    target['label'] = label\n",
        "    inv_data = target.copy(deep = True)\n",
        "    #print(inv_data.head())\n",
        "\n",
        "\n",
        "\n",
        "    if option == \"std\":  #z-score denormalization\n",
        "\n",
        "        for i in range(6):   #for 6 clusters\n",
        "            cluster = inv_data[inv_data['label']== i].copy(deep = True)\n",
        "            #print(cluster.head())\n",
        "            miu = cparam1[i]['RUL']\n",
        "            sigma = cparam2[i]['RUL']\n",
        "            df_norm = cluster['actual']*sigma+miu\n",
        "            #print(df_norm.head())\n",
        "            #idx = inv_data[inv_data['label']== i].index\n",
        "            #inv_data.iloc[idx.tolist(),0] = df_norm\n",
        "            inv_data.loc[inv_data['label']== i,'actual'] = df_norm\n",
        "\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data1 = inv_data['actual']*sigma+miu\n",
        "\n",
        "\n",
        "    else : #MinMax denormalization\n",
        "\n",
        "        for i in range(6):\n",
        "            cluster = inv_data[inv_data['label']== i].copy(deep = True)\n",
        "            #print(cluster.head())\n",
        "            min_val = cparam1[i]['RUL']\n",
        "            range_val = cparam2[i]['RUL']\n",
        "            df_norm = cluster['actual']*range_val+min_val\n",
        "            #print(df_norm.head())\n",
        "            idx = inv_data[inv_data['label']== i].index\n",
        "            inv_data.loc[inv_data['label']== i,'actual'] = df_norm\n",
        "\n",
        "        m = param1\n",
        "        r = param2\n",
        "        inv_data1 = inv_data['actual']*r+m\n",
        "\n",
        "    #print (inv_data1.to_numpy())\n",
        "\n",
        "    return inv_data1.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff23f058",
      "metadata": {
        "id": "ff23f058"
      },
      "source": [
        "### d) Denormalization (target) - 1 level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "517b812a",
      "metadata": {
        "id": "517b812a"
      },
      "outputs": [],
      "source": [
        "# Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def d_norm_1(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # param:parameters applied while normalization (training data statistics)\n",
        "    # data is 1-D column vector\n",
        "\n",
        "\n",
        "\n",
        "    if option == \"std\":  #z-score denormalization\n",
        "\n",
        "\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data1 = data*sigma+miu\n",
        "\n",
        "\n",
        "    else : #MinMax denormalization\n",
        "\n",
        "            m = param1\n",
        "            r = param2\n",
        "            inv_data1 = data*r+m\n",
        "\n",
        "    #print (inv_data1.to_numpy())\n",
        "\n",
        "    return inv_data1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eee83bf",
      "metadata": {
        "id": "6eee83bf"
      },
      "source": [
        "### Minmax normalisation and smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97cd9b9",
      "metadata": {
        "id": "f97cd9b9",
        "outputId": "ddc1ac87-9944-4f98-e0cd-30ed7dca6c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(53239, 12)\n"
          ]
        }
      ],
      "source": [
        "#Train data normalisation and smoothing\n",
        "feature_list = ['unit_number','time_cycles','setting_1','setting_2','setting_3','s_1','s_2','s_8','s_13','s_14','s_19', 'RUL']\n",
        "select_data_train = np.array(train_FD002[feature_list].copy(deep=True))\n",
        "train_data, p1, p2 = data_transform(select_data_train[:,2:],option = 'minmax') #drop unit_number and time_cycles\n",
        "\n",
        "#add unit_number and time_cycles to train_data\n",
        "train_data = np.concatenate((select_data_train[:,0:2], train_data),axis = 1)\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = train_FD002['unit_number'].unique()\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = train_data[train_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_train = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_train[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_train[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "#print(smooth_data[0:4,:])\n",
        "\n",
        "for i in range(9): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_train[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = train_data[train_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_train1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_train1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_train1[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "    #print(smooth_data[0:4,:])\n",
        "\n",
        "    for i in range(9): #21 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_train1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_train = np.concatenate((smooth_data_train,smooth_data_train1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_train.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_train[smooth_data_train[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd1202c",
      "metadata": {
        "id": "7dd1202c",
        "outputId": "a6b0522b-bdf2-477f-e345-e5ae4d08f71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(33473, 12)\n"
          ]
        }
      ],
      "source": [
        "#Test data normalisation and smoothing\n",
        "#1. Normalize using training data statistics\n",
        "select_data_test = np.array(test_FD002[feature_list].copy(deep=True))\n",
        "\n",
        "#perform min-max normalization\n",
        "min_val = p1\n",
        "rng = p2\n",
        "test_data = (select_data_test[:,2:]-min_val)/rng\n",
        "\n",
        "#add unit_number and time_cycle\n",
        "test_data = np.concatenate((select_data_test[:,0:2], test_data),axis = 1)\n",
        "\n",
        "w = 3   #window size for moving average smoothing\n",
        "\n",
        "#Apply data smoothing separately to each engine unit data group\n",
        "unit_numbers = test_FD002['unit_number'].unique()\n",
        "\n",
        "#for unit number 1\n",
        "grp_data = test_data[test_data[:,0] == 1]\n",
        "(n,m) = grp_data.shape\n",
        "smooth_data_test = np.zeros((n-w+1,m))  #array to store smooth data\n",
        "smooth_data_test[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number and  time_cycle\n",
        "smooth_data_test[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "\n",
        "for i in range(9): #6 sensors + 3 settings\n",
        "    series = grp_data[:,i+2]\n",
        "    smooth_series = moving_average(series,w)\n",
        "    smooth_data_test[:,i+2] = smooth_series\n",
        "\n",
        "unit_numbers = unit_numbers[1:]\n",
        "#for remaining unit numbers\n",
        "for i in unit_numbers:\n",
        "    grp_data = test_data[test_data[:,0] == i]\n",
        "    (n,m) = grp_data.shape\n",
        "    smooth_data_test1= np.zeros((n-w+1,m))  #array to store smooth data\n",
        "    smooth_data_test1[:,0:2] = grp_data[(w-1):,0:2]  #copy unit number, time_cycle, and 3 settings\n",
        "    smooth_data_test1[:,11] = grp_data[(w-1):,11] #copy RUL\n",
        "\n",
        "\n",
        "    for i in range(9): #21 sensors+3 settings\n",
        "        series = grp_data[:,i+2]\n",
        "        smooth_series = moving_average(series,w)\n",
        "        smooth_data_test1[:,i+2] = smooth_series\n",
        "\n",
        "    smooth_data_test = np.concatenate((smooth_data_test,smooth_data_test1), axis = 0)\n",
        "\n",
        "\n",
        "print(smooth_data_test.shape)\n",
        "\n",
        "#plot smooth data for selected engine unit\n",
        "\n",
        "# data = smooth_data_test[smooth_data_test[:,0] == 100]\n",
        "# #print(data[0:5,:])\n",
        "\n",
        "# plt.figure(figsize=(20, 10))\n",
        "# for i in range(2,11):\n",
        "#     plt.subplot(3, 3, i-1).set_title(feature_list[i])\n",
        "#     plt.plot(data[:,1], data[:,i])\n",
        "#     plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1465b2c",
      "metadata": {
        "id": "c1465b2c"
      },
      "source": [
        "## 3. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f2a335",
      "metadata": {
        "id": "02f2a335"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for RNN model such that the data is presented as (num_samples,seq_length,num_features)\n",
        "\n",
        "def data_preparation(data,n_past,n_future):\n",
        "    '''\n",
        "    input:\n",
        "        data :[unit_number, time_cycles,context inputs, primary inputs, output]\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'setting_1','setting_2', 'setting_3'\n",
        "        primary input (X): 's_1','s_2','s_8','s_13','s_14','s_19'\n",
        "        ouput/target (Y): 'RUL' at time step t\n",
        "        Engine unit and time cycles (U)\n",
        "    '''\n",
        "\n",
        "    n,m = data.shape\n",
        "\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    engine_data = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "\n",
        "        engine_data.append(data[i-t:i,0:2])  # first two are unit_number, time_cycles\n",
        "        context_data.append(data[i-t:i,2:5]) # then settings data\n",
        "        input_data.append(data[i-t:i, 5:m-1])  #next six attributes are sensor data\n",
        "        output_data.append([data[i+k-1:i+k,m-1]])  #last column is the RUL\n",
        "\n",
        "\n",
        "\n",
        "    U = np.array(engine_data)\n",
        "    X = np.array(input_data)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(n,m)\n",
        "#    print(X.shape)\n",
        "#     print(Y.shape)\n",
        "#     print(Z.shape)\n",
        "\n",
        "\n",
        "    return U, X, Y, Z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e287f36",
      "metadata": {
        "id": "7e287f36"
      },
      "outputs": [],
      "source": [
        "#for test set label is also provided\n",
        "\n",
        "def data_preparation_test(data,n_past,n_future):\n",
        "\n",
        "    '''\n",
        "    input:\n",
        "        data :[unit_number, time_cycles,context inputs, primary inputs, output, label]\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'setting_1','setting_2', 'setting_3'\n",
        "        primary input (X): 's_1','s_2','s_8','s_13','s_14','s_19'\n",
        "        ouput/target (Y): 'RUL' at time step t\n",
        "        Engine unit and time cycles (U)\n",
        "        label : label at time step t required for denormalisation of dat\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    n,m = data.shape\n",
        "    #print(n,m)\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    engine_data = []\n",
        "\n",
        "    label_data = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "        engine_data.append(data[i-t:i,0:2])        # first two are unit_number, time_cycles\n",
        "        context_data.append(data[i-t:i,2:5])       # then settings data\n",
        "        input_data.append(data[i-t:i, 5:m-2])      # next six attributes are sensor data\n",
        "        output_data.append(data[i+k-1:i+k,m-2])    # second last column is the RUL\n",
        "        label_data.append(data[i+k-1:i+k,m-1])     #last column is label\n",
        "\n",
        "\n",
        "    U = np.array(engine_data)\n",
        "    X = np.array(input_data)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "    label = np.array(label_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return U, X, Y, Z, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee93f71a",
      "metadata": {
        "id": "ee93f71a"
      },
      "source": [
        "### a) Data preparation Training and Validation data (cluster normalised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead88267",
      "metadata": {
        "id": "ead88267",
        "outputId": "21442ad4-0210-4c28-bfa6-d7021b2d0659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(45720, 10, 6)\n",
            "(45720, 10, 3)\n",
            "(45720, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "prediction n_future = step ahead with n_past samples\n",
        "NOTE: n_future is set to 0 as the predicted step will not be k step ahead it will be at t\n",
        "unit_number is also present in columns, it will be used for selecting rows for validation set\n",
        "sensor_list = ['s_1','s_2','s_8','s_13','s_14','s_19']\n",
        "'''\n",
        "\n",
        "'''\n",
        "------------data normalised using cluster statistics----------------------------------------\n",
        "'''\n",
        "\n",
        "arr_data = train_norm_data.copy(deep = True)\n",
        "arr_data.drop('label',axis=1, inplace = True)\n",
        "# # print(arr_data.shape)\n",
        "# # print(arr_data.head())\n",
        "data = arr_data.to_numpy()\n",
        "#print(smooth_data_train.shape)\n",
        "#data = smooth_data_train\n",
        "\n",
        "'''\n",
        "The train and test data is availble. Divide the given train data into two parts train and validation,\n",
        "considering the engine unit number.\n",
        "'''\n",
        "seq_len = 10 #sequence length for lstm\n",
        "\n",
        "\n",
        "#take last rows equivalent to double the seq_len from each of the engine unit as validation data\n",
        "list_unit = train_FD002['unit_number'].unique()\n",
        "eng_data = data[data[:,0]==list_unit[0]]\n",
        "data_train = eng_data[:-2*seq_len,:]\n",
        "data_val = eng_data[-2*seq_len:,:]\n",
        "\n",
        "\n",
        "for i in range(1,len(list_unit)):\n",
        "    eng_data = data[data[:,0]==list_unit[i]]\n",
        "    data_train = np.concatenate((data_train,eng_data[:-2*seq_len,:]), axis=0)\n",
        "    data_val = np.concatenate((data_val,eng_data[-2*seq_len:,:]), axis=0)\n",
        "\n",
        "# print(data_train.shape)\n",
        "# print(data_val.shape)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "grp_data = data_train[data_train[:,0] == 1]\n",
        "U_train, X_train, Y_train, Z_train= data_preparation(grp_data,seq_len,1)  #last parameter 0 means context features excluded\n",
        "grp_data = data_val[data_val[:,0]==1]\n",
        "U_val, X_val, Y_val, Z_val = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "\n",
        "\n",
        "list_unit = list_unit[1:]\n",
        "for i in range(1,len(list_unit)):\n",
        "    grp_data = data_train[data_train[:,0] == list_unit[i]]\n",
        "    U_train1, X_train1, Y_train1, Z_train1 = data_preparation(grp_data,seq_len,1)\n",
        "    grp_data = data_val[data_val[:,0]==i]\n",
        "    U_val1, X_val1, Y_val1, Z_val1 = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    U_train = np.concatenate((U_train,U_train1),axis = 0)\n",
        "    X_train = np.concatenate((X_train,X_train1),axis = 0)\n",
        "    Y_train = np.concatenate((Y_train,Y_train1),axis = 0)\n",
        "    Z_train = np.concatenate((Z_train,Z_train1),axis = 0)\n",
        "\n",
        "\n",
        "    U_val = np.concatenate((U_val,U_val1),axis = 0)\n",
        "    X_val = np.concatenate((X_val,X_val1),axis = 0)\n",
        "    Y_val = np.concatenate((Y_val,Y_val1),axis = 0)\n",
        "    Z_val = np.concatenate((Z_val,Z_val1),axis = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Z_train.shape)\n",
        "print(Y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b604b4a2",
      "metadata": {
        "id": "b604b4a2"
      },
      "source": [
        "### b) Data preparation (min-max normalised and smooth data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "473c2344",
      "metadata": {
        "id": "473c2344",
        "outputId": "273a0da1-c0c4-4f43-dd37-acc0b4cdee19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(37432, 20, 6)\n",
            "(37432, 20, 3)\n",
            "(37432, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "prediction n_future = step ahead with n_past samples\n",
        "NOTE: n_future is set to 1 as the predicted step will not be k step ahead it will be at t+1\n",
        "unit_number is also present in columns, it will be used for selecting rows for validation set\n",
        "sensor_list = ['s_1','s_2','s_8','s_13','s_14','s_19']\n",
        "'''\n",
        "\n",
        "'''\n",
        "------------minmax normalised data----------------------------------------\n",
        "'''\n",
        "\n",
        "data = smooth_data_train\n",
        "\n",
        "'''\n",
        "The train and test data is availble. Divide the given train data into two parts train and validation,\n",
        "considering the engine unit number.\n",
        "'''\n",
        "seq_len = 20 #sequence length for lstm\n",
        "\n",
        "\n",
        "#take last rows equivalent to double the seq_len from each of the engine unit as validation data\n",
        "list_unit = train_FD002['unit_number'].unique()\n",
        "eng_data = data[data[:,0]==list_unit[0]]\n",
        "data_train = eng_data[:-2*seq_len,:]\n",
        "data_val = eng_data[-2*seq_len:,:]\n",
        "\n",
        "\n",
        "for i in range(1,len(list_unit)):\n",
        "    eng_data = data[data[:,0]==list_unit[i]]\n",
        "    data_train = np.concatenate((data_train,eng_data[:-2*seq_len,:]), axis=0)\n",
        "    data_val = np.concatenate((data_val,eng_data[-2*seq_len:,:]), axis=0)\n",
        "\n",
        "# print(data_train.shape)\n",
        "# print(data_val.shape)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "grp_data = data_train[data_train[:,0] == 1]\n",
        "U_train, X_train, Y_train, Z_train= data_preparation(grp_data,seq_len,1)  #last parameter 0 means context features excluded\n",
        "grp_data = data_val[data_val[:,0]==1]\n",
        "U_val, X_val, Y_val, Z_val = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "\n",
        "\n",
        "list_unit = list_unit[1:]\n",
        "for i in range(1,len(list_unit)):\n",
        "    grp_data = data_train[data_train[:,0] == list_unit[i]]\n",
        "    U_train1, X_train1, Y_train1, Z_train1 = data_preparation(grp_data,seq_len,1)\n",
        "    grp_data = data_val[data_val[:,0]==i]\n",
        "    U_val1, X_val1, Y_val1, Z_val1 = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    U_train = np.concatenate((U_train,U_train1),axis = 0)\n",
        "    X_train = np.concatenate((X_train,X_train1),axis = 0)\n",
        "    Y_train = np.concatenate((Y_train,Y_train1),axis = 0)\n",
        "    Z_train = np.concatenate((Z_train,Z_train1),axis = 0)\n",
        "\n",
        "\n",
        "    U_val = np.concatenate((U_val,U_val1),axis = 0)\n",
        "    X_val = np.concatenate((X_val,X_val1),axis = 0)\n",
        "    Y_val = np.concatenate((Y_val,Y_val1),axis = 0)\n",
        "    Z_val = np.concatenate((Z_val,Z_val1),axis = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Z_train.shape)\n",
        "print(Y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0528e02b",
      "metadata": {
        "id": "0528e02b"
      },
      "source": [
        "## 4. Loading data into PyTorch Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5510f9",
      "metadata": {
        "id": "aa5510f9",
        "outputId": "f1bdda77-0e6c-4f6d-a03c-c4e66e21fbbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 10, 6]) torch.Size([128, 10, 3]) torch.Size([128, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size =128\n",
        "\n",
        "#transform the arrays into torch tensors\n",
        "train_features = torch.Tensor(X_train)  #drop unit_number and test_cycles\n",
        "train_targets = torch.Tensor(Y_train)\n",
        "train_cx_features = torch.Tensor(Z_train)\n",
        "\n",
        "val_features = torch.Tensor(X_val)\n",
        "val_targets = torch.Tensor(Y_val)\n",
        "val_cx_features = torch.Tensor(Z_val)\n",
        "\n",
        "\n",
        "train = TensorDataset(train_features,train_cx_features, train_targets)\n",
        "val = TensorDataset(val_features, val_cx_features,val_targets)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples,context,targets = examples.next()\n",
        "print(samples.shape, context.shape,targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Hyperparameter Optimization using Optuna"
      ],
      "metadata": {
        "id": "FTQmB9q0OLRS"
      },
      "id": "FTQmB9q0OLRS"
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter optimization with optuna\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[2]\n",
        "output_dim = Y_train.shape[2]\n",
        "context_dim = Z_train.shape[2]\n",
        "\n",
        "weight_decay = 1e-6\n",
        "dropout = 0.1\n",
        "n_epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    params1 = {\n",
        "              'input_dim':input_dim,\n",
        "              'output_dim': output_dim,\n",
        "              'context_dim': context_dim,\n",
        "              'hidden_dim':trial.suggest_int('hidden_size',10,30,5),\n",
        "              }\n",
        "\n",
        "    params2 = {\n",
        "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
        "                'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              }\n",
        "\n",
        "    #model = get_model('gru',params1)\n",
        "    model = ContextGRU(input_dim, params1['hidden_dim'], output_dim, context_dim)\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"], weight_decay=weight_decay)\n",
        "    optimizer = getattr(optim, params2['optimizer'])(model.parameters(), lr= params2['learning_rate'], weight_decay=weight_decay)\n",
        "    opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "    train_loss = opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "    opt.plot_losses()\n",
        "\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "\n",
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))\n",
        "\n"
      ],
      "metadata": {
        "id": "BFcsDRQKOUZ6"
      },
      "id": "BFcsDRQKOUZ6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f263054",
      "metadata": {
        "id": "4f263054"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76c3ad92",
      "metadata": {
        "id": "76c3ad92"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_dim = X_train.shape[2]\n",
        "output_dim = Y_train.shape[2]\n",
        "context_dim = Z_train.shape[2]\n",
        "\n",
        "hidden_dim = 10\n",
        "layer_dim = 1\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "n_epochs = 100\n",
        "learning_rate = 0.0007\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model = ContextGRU(input_dim, hidden_dim, output_dim, context_dim)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "params_list = model.parameters()\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "optimizer = optim.Adam(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "#optimizer = optim.RMSprop(params_list, lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=weight_decay)\n",
        "#optimizer = optim.SGD(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "opt.plot_losses()\n",
        "#opt.visualise_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb9d7563",
      "metadata": {
        "id": "cb9d7563"
      },
      "source": [
        "## Analysis of model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7ad850",
      "metadata": {
        "id": "9d7ad850",
        "outputId": "8a600109-5ace-46c4-b897-87128b64de94"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 12 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# # Print model's state_dict\n",
        "# print(\"Model's state_dict:\")\n",
        "# for param_tensor in model.state_dict():\n",
        "#     print(param_tensor, \"\\t\", str(model.state_dict()[param_tensor].size()))\n",
        "\n",
        "wts, sets, ips = opt.visualise_weights()\n",
        "\n",
        "l = len(wts)\n",
        "wtmatrix = np.array(wts[l-1])\n",
        "fig = plt.figure(figsize=(15, 8))\n",
        "\n",
        "for i in range(6) :  #nx = 6 and m = 9\n",
        "\n",
        "    plt.subplot(2,3,i+1)\n",
        "\n",
        "    sns.heatmap(wtmatrix[:,i*9:i*9+9], cmap = 'Spectral')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fc8332",
      "metadata": {
        "id": "21fc8332"
      },
      "source": [
        "## 7. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c5389658",
      "metadata": {
        "id": "c5389658"
      },
      "outputs": [],
      "source": [
        "#Data prepartion for test data\n",
        "#colums: unit_number,time_cycles,setting_1,setting_2,setting_3,s_1,s_2,s_8,s_13,s_14,s_19,RUL,labels\n",
        "\n",
        "seq_len = 10  #sequence length for lstm\n",
        "#save_path = './Results/CiRNN/'\n",
        "\n",
        "test_arr_data = test_norm_data.copy(deep = True)\n",
        "#test_arr_data.drop('label',axis=1, inplace = True)\n",
        "data_test = test_arr_data.to_numpy()  #label is the last column, needed for denormalization\n",
        "\n",
        "#data_test = smooth_data_test\n",
        "\n",
        "list_unit = test_FD002['unit_number'].unique()\n",
        "\n",
        "\n",
        "#parameters required for inverse transform (cluster statistics)\n",
        "cpar1 = param1\n",
        "cpar2 = param2\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]  #parameter for 'RUL'  (mean/miu)\n",
        "par2 = p2[-1]  #parameter for 'RUL'  (range/sigma)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "#list_unit = [120]\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "for i in list_unit:\n",
        "\n",
        "    grp_data = data_test[data_test[:,0] == i]\n",
        "    U_test, X_test, Y_test, Z_test, Y_labels = data_preparation_test(grp_data,seq_len,1)\n",
        "\n",
        "\n",
        "    test_features = torch.Tensor(X_test)\n",
        "    test_targets = torch.Tensor(Y_test)\n",
        "    test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "    test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "    #test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "    #flatten the multi-dimension array to 1-D array\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "    #Apply inverse transform\n",
        "    #reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "    #target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "    #pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "\n",
        "    #1 level denormalise the target\n",
        "    target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "    pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "    #plot_results(i, target_val,pred_val)\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['Engine'] = [i] * len(target_val)\n",
        "    df['Actual_RUL'] = list(target_val[0:,0])\n",
        "    df['Pred_RUL'] = list(pred_val[0:,0])\n",
        "    df.to_csv(save_path+ str(i) + '.csv', index = False)\n",
        "\n",
        "    result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "    result_rmse.append(result_metrics['rmse'])\n",
        "    result_r2.append(result_metrics['r2'])\n",
        "    score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "#calculate average and std of rmse,and score\n",
        "\n",
        "avg_rmse = np.mean(result_rmse)\n",
        "std_rmse = np.std(result_rmse)\n",
        "\n",
        "avg_score = np.mean(score)\n",
        "std_score = np.std(score)\n",
        "\n",
        "print(f\"[Average RMSE: {avg_rmse:.4f}\\t Std RMSE: {std_rmse:.4f}]\")\n",
        "print(f\"[Average SCORE: {avg_score:.4f}\\t Std SCORE: {std_score:.4f}]\")\n",
        "\n",
        "\n",
        "min_rmse = min(result_rmse)\n",
        "max_rmse = max(result_rmse)\n",
        "min_score = min(score)\n",
        "max_score = max(score)\n",
        "print(f\"[Engine unit#: {result_rmse.index(min_rmse)+1}\\t Min RMSE: {min_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {result_rmse.index(max_rmse)+1}\\t Max RMSE: {max_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(min_score)+1}\\t Min score: {min_score:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(max_score)+1}\\t Max score: {max_score:.4f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ce15f4e",
      "metadata": {
        "id": "6ce15f4e"
      },
      "outputs": [],
      "source": [
        "print(torch.mode(torch.tensor(result_rmse),0))\n",
        "print(torch.mode(torch.tensor(score),0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c424b9e",
      "metadata": {
        "scrolled": true,
        "id": "4c424b9e",
        "outputId": "48d7d0ca-b956-400c-eddc-ba7b13250ed7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Plot the distribution of RMSE and score\n",
        "\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(8,4))\n",
        "plot1 = sns.histplot(result_rmse, kde = 'True', ax = axes[0])\n",
        "plot1.lines[0].set_color('crimson')\n",
        "plot1.set(xlabel = 'RMSE values')\n",
        "plot2 = sns.histplot(score, kde = 'True', ax = axes[1])\n",
        "plot2.lines[0].set_color('crimson')\n",
        "plot2.set(xlabel = 'SCORE values')\n",
        "#plt.savefig('FD002_dist.eps', format = 'eps', dpi = 1000, Transparent = True)\n",
        "plt.savefig(\"FD002_dist.pdf\", format=\"pdf\", dpi=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d22d38",
      "metadata": {
        "id": "89d22d38"
      },
      "source": [
        "### Testing (minmax normalised data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "07d82e07",
      "metadata": {
        "id": "07d82e07"
      },
      "outputs": [],
      "source": [
        "#Data prepartion for test data\n",
        "#colums: unit_number,time_cycles,setting_1,setting_2,setting_3,s_1,s_2,s_8,s_13,s_14,s_19,RUL,labels\n",
        "\n",
        "seq_len = 20  #sequence length for lstm\n",
        "\n",
        "\n",
        "\n",
        "data_test = smooth_data_test\n",
        "\n",
        "list_unit = test_FD002['unit_number'].unique()\n",
        "\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]  #parameter for 'RUL'  (mean/miu)\n",
        "par2 = p2[-1]  #parameter for 'RUL'  (range/sigma)\n",
        "\n",
        "#prepare the data for each engine unit grp separately\n",
        "#X, Y, Z are 3 dim (num_samples,Sequence length, num_features)\n",
        "#list_unit = [83]\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "for i in list_unit:\n",
        "\n",
        "    grp_data = data_test[data_test[:,0] == i]\n",
        "    U_test, X_test, Y_test, Z_test = data_preparation(grp_data,seq_len,1)\n",
        "\n",
        "    if len(X_test) == 0:\n",
        "        continue\n",
        "\n",
        "    test_features = torch.Tensor(X_test)\n",
        "    test_targets = torch.Tensor(Y_test)\n",
        "    test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "    test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "    #test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "    #flatten the multi-dimension array to 1-D array\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "    #Apply inverse transform\n",
        "    #reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "    #target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "    #pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels,cpar1,cpar2,par1,par2)\n",
        "\n",
        "    #1 level denormalise the target\n",
        "    target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "    pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "    #plot_results(i, target_val,pred_val)\n",
        "\n",
        "    result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "    result_rmse.append(result_metrics['rmse'])\n",
        "    result_r2.append(result_metrics['r2'])\n",
        "    score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "#calculate average and std of rmse,and score\n",
        "\n",
        "avg_rmse = np.mean(result_rmse)\n",
        "std_rmse = np.std(result_rmse)\n",
        "\n",
        "avg_score = np.mean(score)\n",
        "std_score = np.std(score)\n",
        "\n",
        "print(f\"[Average RMSE: {avg_rmse:.4f}\\t Std RMSE: {std_rmse:.4f}]\")\n",
        "print(f\"[Average SCORE: {avg_score:.4f}\\t Std SCORE: {std_score:.4f}]\")\n",
        "\n",
        "\n",
        "min_rmse = min(result_rmse)\n",
        "max_rmse = max(result_rmse)\n",
        "min_score = min(score)\n",
        "max_score = max(score)\n",
        "print(f\"[Engine unit#: {result_rmse.index(min_rmse)+1}\\t Min RMSE: {min_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {result_rmse.index(max_rmse)+1}\\t Max RMSE: {max_rmse:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(min_score)+1}\\t Min score: {min_score:.4f}]\")\n",
        "print(f\"[Engine unit#: {score.index(max_score)+1}\\t Max score: {max_score:.4f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7711c181",
      "metadata": {
        "id": "7711c181"
      },
      "outputs": [],
      "source": [
        "print(torch.mode(torch.tensor(result_rmse),0))\n",
        "print(torch.mode(torch.tensor(score),0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b41d497e",
      "metadata": {
        "id": "b41d497e"
      },
      "outputs": [],
      "source": [
        "# Test the whole data (not engine-wise)\n",
        "#Data prepartion for test data\n",
        "\n",
        "seq_len = 10  #sequence length for lstm\n",
        "#cols = [0,1,2,3,4,5,6,13,18,19,24,26]   #0: unit number,1:time_cycles, 2,3,4 : 3 settings, 5,6,13,18,19: sensor data, 26:RUL\n",
        "test_arr_data = test_norm_data.copy(deep = True)\n",
        "\n",
        "#remove labels for prediction task\n",
        "#test_arr_data.drop('label',axis=1, inplace = True)\n",
        "data_test = test_arr_data.to_numpy()\n",
        "\n",
        "#data_test = smooth_data_test\n",
        "\n",
        "#parameters required for inverse transform (cluster statistics)\n",
        "cpar1 = param1\n",
        "cpar2 = param2\n",
        "\n",
        "#parameters from train data statistics\n",
        "par1 = p1[-1]\n",
        "par2 = p2[-1]\n",
        "\n",
        "result_rmse = []\n",
        "result_r2 = []\n",
        "score = []\n",
        "\n",
        "\n",
        "U_test, X_test, Y_test, Z_test, Y_labels = data_preparation_test(data_test,seq_len,1)\n",
        "\n",
        "test_features = torch.Tensor(X_test)\n",
        "test_targets = torch.Tensor(Y_test)\n",
        "test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "\n",
        "#test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "#flatten the multi-dimension array to 1-D array\n",
        "vals = np.concatenate(values, axis=0).ravel()\n",
        "preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "\n",
        "#Apply denormalization transform\n",
        "#reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "# target_val = d_norm(np.reshape(vals,(len(vals),1)), \"minmax\",Y_labels, cpar1, cpar2, par1,par2)\n",
        "# pred_val = d_norm(np.reshape(preds,(len(preds),1)),\"minmax\",Y_labels, cpar1, cpar2,par1,par2)\n",
        "\n",
        "\n",
        "target_val = d_norm_1(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "pred_val = d_norm_1(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "\n",
        "#plot_results(i, target_val,pred_val)\n",
        "\n",
        "#smooth the values\n",
        "#sm_pred_val = moving_average(pred_val, 10) #3 is window size\n",
        "\n",
        "result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "result_rmse.append(result_metrics['rmse'])\n",
        "result_r2.append(result_metrics['r2'])\n",
        "score.append(calculate_score(target_val, pred_val))\n",
        "\n",
        "print(result_rmse)\n",
        "print(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a5e21c8c",
      "metadata": {
        "id": "a5e21c8c"
      },
      "outputs": [],
      "source": [
        "# sns.set_palette(\"bright\")\n",
        "# sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "#plot_results(10, target_val[0:1000],pred_val[0:1000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c6e910",
      "metadata": {
        "id": "22c6e910"
      },
      "outputs": [],
      "source": [
        "#Plot the results Engine Unit wise\n",
        "def plot_results(unit_num, target_val,pred_val):\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    #plt.subplot(1,2,1).set_title(\"Engine Unit #\" + str(unit_num))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(target_val,'r')\n",
        "    plt.plot(pred_val,'b')\n",
        "    plt.xlabel('Time (Cycles)')\n",
        "    plt.ylabel('RUL')\n",
        "    plt.legend(['Actual RUL','Predicted RUL'])\n",
        "\n",
        "#     plt.subplot(1,2,2).set_title(\"Engine Unit #\" + str(unit_num))\n",
        "#     plt.plot(target_val,pred_val,'.r')\n",
        "#     plt.xlabel('Actual RUL')\n",
        "#     plt.ylabel('Predcited RUL')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f129080",
      "metadata": {
        "id": "5f129080"
      },
      "source": [
        "### Calculate Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f8b7eb",
      "metadata": {
        "id": "79f8b7eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calculate_metrics(actual, predicted):\n",
        "\n",
        "    return {'mae' : mean_absolute_error(actual,predicted),\n",
        "            'rmse' : mean_squared_error(actual,predicted) ** 0.5,\n",
        "            'r2' : r2_score(actual,predicted)}\n",
        "\n",
        "# result_metrics = calculate_metrics(target_val, pred_val)\n",
        "# print(result_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1976db26",
      "metadata": {
        "id": "1976db26"
      },
      "source": [
        "### Calculate Asymmetric score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772cc745",
      "metadata": {
        "id": "772cc745"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "#call this function for each unit, and sum to get the overall score\n",
        "def calculate_score(actual, predicted):\n",
        "#calcualate score for one engine unit\n",
        "    s = 0\n",
        "    a1 = 10 #constant\n",
        "    a2 = 13\n",
        "    s_list = []\n",
        "    d_list = predicted - actual\n",
        "    for i in range(len(actual)):\n",
        "        d = predicted[i]-actual[i]\n",
        "\n",
        "        if d >= 0:\n",
        "            #s = s+(math.exp(d/a2)-1)\n",
        "            s = (math.exp(d/a2)-1)\n",
        "            s_list.append(s)\n",
        "\n",
        "        else:\n",
        "\n",
        "            #s = s+(math.exp(-d/a1)-1)\n",
        "            s = (math.exp(-d/a1)-1)\n",
        "            s_list.append(s)\n",
        "\n",
        "#     plt.figure()\n",
        "#     plt.plot(d_list,s_list,'.')\n",
        "\n",
        "    return sum(s_list)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}