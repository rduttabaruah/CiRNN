{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8b105c",
      "metadata": {
        "id": "ab8b105c",
        "outputId": "4c908fbc-6892-40e1-e563-181024898d45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7efc90102470>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "seed = 40\n",
        "os.environ['PYTHONHASHSEED']=str(seed)\n",
        "\n",
        "import random\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.pyplot import *\n",
        "style.use('ggplot')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.profiler\n",
        "import torch.autograd.profiler as profiler\n",
        "from scipy import stats as st\n",
        "import sklearn.preprocessing as preprocess\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6be63e",
      "metadata": {
        "id": "9c6be63e"
      },
      "source": [
        "# Context Integrated RNN - CiRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85c75a2",
      "metadata": {
        "id": "e85c75a2",
        "outputId": "6ff2c4d0-cfc8-4721-9fe6-e6220725b7d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get CPU or GPU device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "class ContextGRU(torch.nn.Module):\n",
        "    \"\"\"\n",
        "     simple GRU cell network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, context_dim):\n",
        "        super(ContextGRU, self).__init__()\n",
        "\n",
        "        self.n_x = input_dim\n",
        "        self.n_h = hidden_dim\n",
        "        self.n_y = output_dim\n",
        "        self.n_z = context_dim\n",
        "        self.m = 9  #dimension of basis function vector (polynomial features) for 3 context features\n",
        "\n",
        "\n",
        "        # reset gate components\n",
        "        self.linear_reset_w1 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r1 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "\n",
        "\n",
        "        self.linear_reset_w2 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_reset_r2 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_1 = nn.Sigmoid()\n",
        "\n",
        "        # update gate components\n",
        "        self.linear_gate_w3 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
        "        self.linear_gate_r3 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
        "        self.activation_2 = nn.Sigmoid()\n",
        "\n",
        "        self.activation_3 = nn.Tanh()\n",
        "\n",
        "        #output\n",
        "        self.linear_output = nn.Linear(self.n_h, self.n_y, bias=True)\n",
        "\n",
        "\n",
        "    def reset_gate(self, xg, h):  #xg is the kronecker product of x and  basis function G(z)\n",
        "        x_1 = self.linear_reset_w1(xg)\n",
        "        h_1 = self.linear_reset_r1(h)\n",
        "        # gate update\n",
        "        r = self.activation_1(x_1 + h_1)\n",
        "        return r\n",
        "\n",
        "    def update_gate(self, xg, h):\n",
        "        x_2 = self.linear_reset_w2(xg)\n",
        "        h_2 = self.linear_reset_r2(h)\n",
        "        s = self.activation_2( h_2 + x_2)\n",
        "        return s\n",
        "\n",
        "\n",
        "    def update_component(self, xg, h, r):\n",
        "        x_3 = self.linear_gate_w3(xg)\n",
        "        h_3 = r * self.linear_gate_r3(h)\n",
        "        h_tilda = self.activation_3(x_3+h_3)\n",
        "        return h_tilda\n",
        "\n",
        "\n",
        "    def compute_output(self,h):\n",
        "        y_pred = self.linear_output(h)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def cell_forward(self, x, h, G):\n",
        "\n",
        "        \"\"\"\n",
        "        Implements a single forward step of the Context GRU-cell\n",
        "\n",
        "        Input Arguments:\n",
        "            x (mini-batch): input x at time step t , (n,n_x) : (batch_size, input_dim)\n",
        "            h : hidden state at time step t-1, (n,n_h) : (batch_size, hidden_dim)\n",
        "            G : vector of basis funcitons (m,n)\n",
        "\n",
        "        Returns:\n",
        "            h_new: hidden state at time step t, (n,n_h)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # kronecker product of x and G(zt)\n",
        "        n = x.shape[0]\n",
        "        xg = torch.zeros(n,self.n_x*self.m).to(device)\n",
        "\n",
        "        for i in range(n):\n",
        "\n",
        "            xg[i,:] = torch.kron(x[i,:],G[:,i])\n",
        "\n",
        "\n",
        "        # Equation 1. reset gate vector\n",
        "        r = self.reset_gate(xg, h)\n",
        "\n",
        "        # Equation 2: the update gate - the shared update gate vector z\n",
        "        s = self.update_gate(xg, h)\n",
        "\n",
        "        # Equation 3: The almost output component\n",
        "        h_tilda = self.update_component(xg,h,r)\n",
        "\n",
        "        # Equation 4: the new hidden state\n",
        "        h_new = (1-s) * h_tilda  + s * h\n",
        "\n",
        "        #output\n",
        "\n",
        "        y_pred = self.compute_output(h)\n",
        "\n",
        "        return h_new, y_pred\n",
        "\n",
        "\n",
        "    def forward(self, x, z):\n",
        "\n",
        "        \"\"\"\n",
        "        Implement the forward propagation of the recurrent neural network\n",
        "\n",
        "        Input Arguments:\n",
        "        x (mini_batch): primary input for every time-step in mini-batches of shape (n, T, n_x)\n",
        "        z (mini_batch): context input for every time-step in mini-batches of shape (n,T,n_z)\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            h -- Hidden states for every time-step, numpy array of shape (n, T, n_h)\n",
        "            y_pred -- Predictions for every time-step, numpy array of shape (n, T, n_y),\n",
        "            here T is 1 for Seq to Vec RNN\n",
        "        \"\"\"\n",
        "\n",
        "        # Retrieve dimensions from shapes of x\n",
        "        #print(x.shape)\n",
        "        #print(z.shape)\n",
        "        n,T,n_x = x.shape\n",
        "        n_y = self.n_y\n",
        "        n_h = self.n_h\n",
        "        n_z = self.n_z\n",
        "\n",
        "\n",
        "\n",
        "        # initialize \"h\"\n",
        "\n",
        "        h = self.init_hidden(n,T,n_h)\n",
        "\n",
        "        #y_pred = np.zeros((m,T_x,n_y))\n",
        "        #y_pred is single value for one sample, m=1\n",
        "\n",
        "        #basis function vector\n",
        "        G = self.apply_basis(z[:,0,:])  #G: size of (n,m)\n",
        "\n",
        "        #for initial time step the hidden state is 0\n",
        "        h_temp = h.clone()\n",
        "        h_init = h_temp[:,0,:]\n",
        "        h_curr, y_curr = self.cell_forward(x[:,0,:],h_init,torch.t(G))\n",
        "\n",
        "        # loop over all time-steps\n",
        "        for t in range(1,T):\n",
        "\n",
        "            #compute the vector of basis functions\n",
        "\n",
        "            G = self.apply_basis(z[:,t,:])  #G: size of (n,m)\n",
        "\n",
        "            # Update next hidden state\n",
        "            # ignore yt_pred for seq to vector\n",
        "            h[:,t,:]= h_curr\n",
        "            h_temp = h.clone()\n",
        "            h_prev = h_temp[:,t,:]  #h_prev: (n,n_h)\n",
        "            h_curr, y_curr = self.cell_forward(x[:,t,:],h_prev, torch.t(G))\n",
        "\n",
        "            #y_pred[t,:] = yt_pred\n",
        "\n",
        "\n",
        "        #compute the predicted output from the last cell i.e at last time step T\n",
        "        y_pred = torch.zeros(n,1,1,device = 'cuda:0')\n",
        "\n",
        "        #get the value of y_pred from the last cell\n",
        "        y_pred[:,0,:] = y_curr\n",
        "\n",
        "        #print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "        return h, y_pred\n",
        "\n",
        "\n",
        "    def init_hidden(self, n:int,T:int, n_h:int):\n",
        "        #initialise the hidden state\n",
        "        #n : batch-size\n",
        "        #T : Input sequence length\n",
        "        #returns h of size (n,T,n_h)\n",
        "        return torch.zeros(n,T,n_h,device = 'cuda:0')\n",
        "\n",
        "\n",
        "    def apply_basis(self,zt):\n",
        "        '''\n",
        "        apply the basis function: polynomial degree 2\n",
        "        [z0, z1, z2, z0z0, z0z1, z0z2....]\n",
        "        input arguments:\n",
        "            zt: context vector (n,n_z) for mini-batch of size n and n_z context dim\n",
        "        Returns:\n",
        "            G : tensor of basis functions, (m,n)\n",
        "\n",
        "        for 3 context features m = 9\n",
        "        '''\n",
        "\n",
        "        #poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
        "        poly = PolynomialFeatures(2, include_bias=False)\n",
        "        G = torch.tensor(poly.fit_transform(zt.cpu().numpy())).to(device) #fit_transform returns nd array\n",
        "        #print(G.shape)\n",
        "\n",
        "\n",
        "\n",
        "        return G\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "999d31f3",
      "metadata": {
        "id": "999d31f3"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.weights = []      #used for visualising weights\n",
        "        self.settings = []     #saving settings for visualising weights\n",
        "        self.inputs = []       #saving input for visualising\n",
        "\n",
        "    def train_step(self, x, y, z):\n",
        "\n",
        "       # with profiler.record_function(\"TRAIN STEP FUNCTION\"):\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        h, yhat = self.model(x, z)\n",
        "\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        #with profiler.record_function(\"LOSS_BACKWARD\"):\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size, n_epochs=50, np_features=1, nc_features=1):\n",
        "        '''\n",
        "        np_features = # primary input features\n",
        "        nc_features = # context input features\n",
        "        '''\n",
        "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "        times = []\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "            start_epoch = time.time()\n",
        "\n",
        "            batch_losses = []\n",
        "            batch_count = 0\n",
        "            for x_batch, z_batch, y_batch in train_loader:\n",
        "                batch_count += 1\n",
        "                x_batch = x_batch.view([batch_size,-1, np_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                z_batch = z_batch.view([batch_size,-1, nc_features]).to(device)\n",
        "\n",
        "                #with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                loss = self.train_step(x_batch, y_batch, z_batch)\n",
        "                #print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                batch_losses.append(loss)\n",
        "\n",
        "            # if (epoch % 10 == 0):\n",
        "            #         #if (batch_count % 200 == 0):\n",
        "            #             #save the model weights for each batch for analysis\n",
        "            #             #self.save_model(self.model, batch_count, str(z_batch[-1,:,:].detach().cpu().numpy()))\n",
        "            #     for param_tensor in model.state_dict():\n",
        "            #         if (param_tensor == 'linear_reset_w1.weight'):\n",
        "            #             param_val = model.state_dict()[param_tensor].cpu().numpy().tolist()\n",
        "            #             self.weights.append(param_val)\n",
        "            #             self.settings.append(z_batch[-1,:,:].detach().cpu().numpy().tolist())\n",
        "            # #self.model.to(device)\n",
        "\n",
        "\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, z_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, np_features]).to(device, non_blocking=True)\n",
        "                    y_val = y_val.to(device)\n",
        "                    z_val = z_val.view([batch_size, -1, nc_features]).to(device,non_blocking=True)\n",
        "                    self.model.eval()\n",
        "\n",
        "                    # with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
        "                    h,yhat = self.model(x_val, z_val)\n",
        "                    # print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
        "\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch % 5 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "            end_epoch = time.time()\n",
        "            elapsed = end_epoch - start_epoch\n",
        "            times.append(elapsed)\n",
        "\n",
        "        total_time = sum(times)\n",
        "        avg_time = sum(times)/n_epochs\n",
        "\n",
        "        print(f\"Average Training time: {avg_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "        print(f\"Total Training time: {total_time:.4f} s for epochs {n_epochs}\")\n",
        "\n",
        "\n",
        "        #torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "        return validation_loss  #this will be used by otuna to optimize\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, np_features=1, nc_features = 1):\n",
        "            with torch.no_grad():\n",
        "                predictions = []\n",
        "                values = []\n",
        "                for x_test, z_test, y_test in test_loader:\n",
        "\n",
        "                    x_test = x_test.view([batch_size,-1, np_features]).to(device, non_blocking=True)\n",
        "                    y_test = y_test.to(device)\n",
        "                    z_test = z_test.view([batch_size,-1, nc_features]).to(device, non_blocking=True)\n",
        "                    self.model.eval()\n",
        "                    h,yhat = self.model(x_test, z_test)\n",
        "                    predictions.append(yhat.detach().cpu().numpy())\n",
        "                    values.append(y_test.detach().cpu().numpy())\n",
        "\n",
        "            return predictions, values\n",
        "\n",
        "    def plot_losses(self):\n",
        "            plt.plot(self.train_losses, label=\"Training loss\")\n",
        "            plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "            plt.legend()\n",
        "            plt.title(\"Losses\")\n",
        "            plt.xlabel(\"Epochs\")\n",
        "            plt.ylabel(\"Loss(MSE)\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "    def save_model(self, model, batch_id, settings_val):\n",
        "\n",
        "        # path = r'/home/rashmi/PythonProjects/codes/TURBOFAN_MODELS/savedmodels/'\n",
        "        # #save model\n",
        "        # file_name = 'FD002_Params.txt'\n",
        "        # file_path = os.path.join(path,file_name)\n",
        "        # f = open(file_path, 'a')\n",
        "        # f.write('Batch'+ str(batch_id)+'\\n')\n",
        "        # f.write('-------\\n')\n",
        "        # for param_tensor in model.state_dict():\n",
        "        #     param_val = model.state_dict()[param_tensor].cpu().numpy().tolist()\n",
        "        #     f.write(param_tensor + \"\\t\" + str(param_val))\n",
        "        #     f.write('\\n---------------\\n')\n",
        "        # f.write('Settings\\n')\n",
        "        # f.write(settings_val + '\\n')\n",
        "        # f.write('---------------\\n')\n",
        "        # f.write('\\n')\n",
        "\n",
        "        # f.close()\n",
        "\n",
        "\n",
        "    def visualise_weights(self):\n",
        "\n",
        "#         col = ['r','b','g']\n",
        "#         nrows = len(self.weights)\n",
        "#         for i in range(nrows):\n",
        "#             wtmatrix = np.array(self.weights[i])\n",
        "#             print(wtmatrix.shape)\n",
        "#             fig = plt.figure()\n",
        "#             print(wtmatrix[0:9, 0:9])\n",
        "#             #plt.imshow(wtmatrix[0:9, 0:9])\n",
        "#             sns.heatmap(wtmatrix[0:10, 0:10])\n",
        "\n",
        "#         fig = plt.figure()\n",
        "#         for i in range(nrows):\n",
        "#             wtmatrix = np.array(self.weights[i])\n",
        "#             plt.plot(wtmatrix[0:10],wtmatrix [0:10],color = col[i],marker = '.')\n",
        "\n",
        "        return self.weights, self.settings, self.inputs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0211805",
      "metadata": {
        "id": "f0211805"
      },
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3febeddf",
      "metadata": {
        "id": "3febeddf"
      },
      "outputs": [],
      "source": [
        "#data load function\n",
        "\n",
        "def dataload(filename):\n",
        "\n",
        "    df = pd.read_csv(filename)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6447d69",
      "metadata": {
        "id": "b6447d69"
      },
      "outputs": [],
      "source": [
        "#load the combined sensor and weather data\n",
        "#207 is number of sensors\n",
        "\n",
        "df_w = []\n",
        "#path3 =       #define path\n",
        "for i in range(0,207):\n",
        "    filename = 'sw_' + str(i+1)\n",
        "    df_w.append(dataload(path3+filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a85cce",
      "metadata": {
        "id": "31a85cce"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df_w)):\n",
        "    df_w[i].drop(columns = [df_w[i].columns[0]], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5115ec2",
      "metadata": {
        "id": "f5115ec2",
        "outputId": "6de53624-8347-45ff-a0d9-3107c2a0b261"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>StationId</th>\n",
              "      <th>AvgSpeed</th>\n",
              "      <th>AvgSpeed1</th>\n",
              "      <th>AvgSpeed2</th>\n",
              "      <th>AvgSpeed3</th>\n",
              "      <th>AvgSpeed4</th>\n",
              "      <th>AvgSpeed5</th>\n",
              "      <th>AvgSpeed6</th>\n",
              "      <th>AvgSpeed7</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>Temp</th>\n",
              "      <th>WindSpeed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>69.3</td>\n",
              "      <td>69.4</td>\n",
              "      <td>69.6</td>\n",
              "      <td>69.8</td>\n",
              "      <td>69.3</td>\n",
              "      <td>70.5</td>\n",
              "      <td>69.6</td>\n",
              "      <td>68.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>68.4</td>\n",
              "      <td>68.4</td>\n",
              "      <td>69.8</td>\n",
              "      <td>69.4</td>\n",
              "      <td>68.9</td>\n",
              "      <td>68.1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>67.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>69.1</td>\n",
              "      <td>68.8</td>\n",
              "      <td>66.7</td>\n",
              "      <td>67.6</td>\n",
              "      <td>67.2</td>\n",
              "      <td>68.7</td>\n",
              "      <td>66.7</td>\n",
              "      <td>68.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>69.2</td>\n",
              "      <td>67.8</td>\n",
              "      <td>67.6</td>\n",
              "      <td>67.6</td>\n",
              "      <td>68.8</td>\n",
              "      <td>71.2</td>\n",
              "      <td>65.7</td>\n",
              "      <td>69.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>68.3</td>\n",
              "      <td>69.0</td>\n",
              "      <td>65.1</td>\n",
              "      <td>67.9</td>\n",
              "      <td>68.6</td>\n",
              "      <td>71.3</td>\n",
              "      <td>68.2</td>\n",
              "      <td>67.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Year  Month  Day  Hour  Weekday  StationId  AvgSpeed  AvgSpeed1  \\\n",
              "0  2012.0    3.0  8.0   0.0      3.0   773869.0      69.3       69.4   \n",
              "1  2012.0    3.0  8.0   0.0      3.0   773869.0      68.4       68.4   \n",
              "2  2012.0    3.0  8.0   0.0      3.0   773869.0      69.1       68.8   \n",
              "3  2012.0    3.0  8.0   0.0      3.0   773869.0      69.2       67.8   \n",
              "4  2012.0    3.0  8.0   0.0      3.0   773869.0      68.3       69.0   \n",
              "\n",
              "   AvgSpeed2  AvgSpeed3  AvgSpeed4  AvgSpeed5  AvgSpeed6  AvgSpeed7  \\\n",
              "0       69.6       69.8       69.3       70.5       69.6       68.9   \n",
              "1       69.8       69.4       68.9       68.1       70.0       67.5   \n",
              "2       66.7       67.6       67.2       68.7       66.7       68.7   \n",
              "3       67.6       67.6       68.8       71.2       65.7       69.1   \n",
              "4       65.1       67.9       68.6       71.3       68.2       67.2   \n",
              "\n",
              "   Precipitation  Temp  WindSpeed  \n",
              "0            0.0   5.2       2.15  \n",
              "1            0.0   5.2       2.15  \n",
              "2            0.0   5.2       2.15  \n",
              "3            0.0   5.2       2.15  \n",
              "4            0.0   5.2       2.15  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_w[0].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b1b404",
      "metadata": {
        "id": "69b1b404"
      },
      "source": [
        "## 2. Data Prepreprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb158818",
      "metadata": {
        "id": "fb158818"
      },
      "source": [
        "### a) Smoothing - moving average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf6727f",
      "metadata": {
        "id": "caf6727f"
      },
      "outputs": [],
      "source": [
        "#Trailing moving average\n",
        "#trail_ma(t) = mean(obs(t-2), obs(t-1), obs(t))\n",
        "\n",
        "def moving_average(x, w):\n",
        "    #x: time series\n",
        "    #w: sliding window size\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3d8406",
      "metadata": {
        "id": "1a3d8406"
      },
      "source": [
        "### b) Normalisation - Transform and Inverse transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80d6598",
      "metadata": {
        "id": "b80d6598"
      },
      "outputs": [],
      "source": [
        "def data_transform(data,option ='minmax'):\n",
        "#data is numpy array\n",
        "#option is set to std for standardization or minmax\n",
        "\n",
        "    n = data.shape[0]\n",
        "\n",
        "    if option == 'std' :\n",
        "\n",
        "        #perform standardization of data\n",
        "        miu = np.mean(data,axis = 0)\n",
        "        sigma = np.std(data,axis=0,dtype=float)\n",
        "        temp_data = data-np.tile(miu,(n,1))\n",
        "        std_data = np.divide(temp_data,np.tile(sigma,(n,1)))\n",
        "\n",
        "        return std_data, miu, sigma\n",
        "\n",
        "    elif option == 'minmax':\n",
        "\n",
        "        #perform min-max normalization\n",
        "        max_val = np.max(data,0)\n",
        "        #print(max_val)\n",
        "        min_val = np.min(data,0)\n",
        "        #print(min_val)\n",
        "        rng = max_val-min_val\n",
        "        norm_data = np.divide(data - np.tile(min_val,(n,1)),np.tile(rng,(n,1)))\n",
        "\n",
        "        return norm_data, min_val, rng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f929d8",
      "metadata": {
        "id": "c3f929d8"
      },
      "outputs": [],
      "source": [
        "## Inverse transform the target/outout data from normalized to original\n",
        "\n",
        "def inv_trans(data,option,param1, param2):\n",
        "    # apply inverse of standardization or normalization for 1-D column/row vector\n",
        "    # option: standard or minmax normalization\n",
        "    # params:list of parameters applied while normalization\n",
        "    # data is 1-D column vector\n",
        "#     print(data)\n",
        "#     print(param1)\n",
        "#     print(param2)\n",
        "\n",
        "    if option == \"std\":\n",
        "         #perform standardization of data\n",
        "        miu = param1\n",
        "        sigma = param2\n",
        "        inv_data = data*sigma + miu\n",
        "\n",
        "        return inv_data\n",
        "\n",
        "    else : #MinMax normalization\n",
        "\n",
        "        #perform min-max normalization\n",
        "        min_val = param1\n",
        "        rng = param2\n",
        "        inv_data = data*rng+min_val\n",
        "        return inv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eee83bf",
      "metadata": {
        "id": "6eee83bf"
      },
      "source": [
        "### Minmax normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97cd9b9",
      "metadata": {
        "id": "f97cd9b9"
      },
      "outputs": [],
      "source": [
        "df_arr = []  #list of arrays -207\n",
        "min_val = []  #list of minimum value used for normalization\n",
        "rng = []  #list of range values used for normalization\n",
        "for i in range(len(df_w)):\n",
        "    arr = np.array(df_w[i])\n",
        "    norm_arr, m_val, r_val = data_transform(arr[:,6:17])  #Year, Month, ..., StationID are not normalised\n",
        "    final_arr = np.concatenate((arr[:,0:6], norm_arr), axis=1)\n",
        "    df_arr.append(final_arr)\n",
        "    min_val.append(m_val)\n",
        "    rng.append(r_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "512d02d5",
      "metadata": {
        "id": "512d02d5",
        "outputId": "385dde52-3aeb-475c-e830-91161d4faf6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32724, 17)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_arr[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1465b2c",
      "metadata": {
        "id": "c1465b2c"
      },
      "source": [
        "## 3. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85778102",
      "metadata": {
        "id": "85778102",
        "outputId": "9e81d293-e774-4674-cc6e-c1aed1d582d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Year', 'Month', 'Day', 'Hour', 'Weekday', 'StationId', 'AvgSpeed',\n",
              "       'AvgSpeed1', 'AvgSpeed2', 'AvgSpeed3', 'AvgSpeed4', 'AvgSpeed5',\n",
              "       'AvgSpeed6', 'AvgSpeed7', 'Precipitation', 'Temp', 'WindSpeed'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_w[0].columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f2a335",
      "metadata": {
        "id": "02f2a335"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for RNN model such that the data is presented as (num_samples,seq_length,num_features)\n",
        "\n",
        "def data_preparation(data,n_past,n_future):\n",
        "    '''\n",
        "    input:\n",
        "        data : input data\n",
        "        n_past : number of past steps to be used for prediction\n",
        "        n_future :  number of steps ahead\n",
        "\n",
        "    returns:\n",
        "        context input (Z): 'Precipitation','Temp', 'WindSpeed'\n",
        "        primary input (X): 'AvgSpeed', AvgSpeed1..AvgSpeed7'\n",
        "        ouput/target (Y): 'AvgSpeed' at time step t\n",
        "        Additional Information (U) : Year, Month, ...StationId\n",
        "    '''\n",
        "\n",
        "    n,m = data.shape\n",
        "\n",
        "\n",
        "    k = n_future\n",
        "    t = n_past\n",
        "\n",
        "\n",
        "    input_data = []\n",
        "    periodic_input = []\n",
        "    output_data = []\n",
        "    context_data = []\n",
        "    info_data = []\n",
        "    comb_input = []\n",
        "\n",
        "\n",
        "    for i in range(t, (n-k+1)):\n",
        "\n",
        "        #info_data.append(data[i-t:i,0:6])  #first 6 columns are additional information\n",
        "        input_data.append(data[i-t:i,6:7])  #Avg Speed\n",
        "        context_data.append(data[i-t:i,14:17]) # weather data\n",
        "        periodic_input.append(data[i+k-t:i+k,7:14])\n",
        "        output_data.append([data[i+k-1:i+k,6]])  #Target AvgSpeed\n",
        "        info_data.append(data[i+k-1:i+k,0:6])  #first 6 columns are additional information\n",
        "\n",
        "#     print(np.array(input_data).shape)\n",
        "#     print(np.array(periodic_input).shape)\n",
        "#     print(np.array(context_data).shape)\n",
        "#     print(np.array(output_data).shape)\n",
        "\n",
        "    #combine input_data and periodic_data\n",
        "    X = np.concatenate((np.array(input_data), np.array(periodic_input)), axis = 2)\n",
        "    Y = np.array(output_data)\n",
        "    Z = np.array(context_data)\n",
        "    U = np.array(info_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(n,m)\n",
        "#    print(X.shape)\n",
        "#     print(Y.shape)\n",
        "#     print(Z.shape)\n",
        "\n",
        "\n",
        "    return X, Y, Z, U\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee93f71a",
      "metadata": {
        "id": "ee93f71a"
      },
      "source": [
        "### a) Data preparation (Minmax normalised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead88267",
      "metadata": {
        "id": "ead88267"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "prediction n_future = step ahead with n_past samples\n",
        "n_future = 12 steps (next hour)\n",
        "n_past = 12 steps\n",
        "prediction of one hour ahead using lone hour past samples.\n",
        "Example:  8:00, 8:05, ...9:00 past data (same day) and 9:00, 9:05...10:00 past data (last week\n",
        "during same time slot and day as target = periodic data) --> predicting 10:00 traffic avg speed\n",
        "'''\n",
        "\n",
        "'''\n",
        "Divide the data into 70:10:20 Train:Validation:Test\n",
        "'''\n",
        "\n",
        "seq_len = 12 #sequence length for lstm  #n_past\n",
        "k = 12  #k steps ahead prediction (one hour ahead prediction)\n",
        "\n",
        "\n",
        "#prepare the data for each sensor separately\n",
        "#X, Y, Z, U are 3 dim (num_samples,Sequence length, num_features)\n",
        "\n",
        "df_X = []  #list for saving input data (X) for each sensor (StationID)\n",
        "df_Y = []\n",
        "df_Z = []\n",
        "df_U = []\n",
        "\n",
        "for i in range(len(df_arr)):\n",
        "    X, Y, Z, U = data_preparation(df_arr[i],seq_len,k)\n",
        "    df_X.append(X)\n",
        "    df_Y.append(Y)\n",
        "    df_Z.append(Z)\n",
        "    df_U.append(U)\n",
        "\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_val.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8988d16a",
      "metadata": {
        "id": "8988d16a",
        "outputId": "cb5d388a-eddb-4cac-83b4-0b26bbc8e033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32701, 12, 8)\n",
            "(32701, 1, 1)\n",
            "(32701, 12, 3)\n",
            "(32701, 1, 6)\n"
          ]
        }
      ],
      "source": [
        "print(df_X[0].shape)\n",
        "print(df_Y[0].shape)\n",
        "print(df_Z[0].shape)\n",
        "print(df_U[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0528e02b",
      "metadata": {
        "id": "0528e02b"
      },
      "source": [
        "## 4. Loading data into PyTorch Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5510f9",
      "metadata": {
        "id": "aa5510f9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def dataloader_pytorch (train_data, val_data, batch_size = 128):\n",
        "\n",
        "    #train_data and val_data is tuple with X, Y, Z\n",
        "\n",
        "    X_train = train_data[0]\n",
        "    Y_train = train_data[1]\n",
        "    Z_train = train_data[2]\n",
        "\n",
        "    X_val = val_data[0]\n",
        "    Y_val = val_data[1]\n",
        "    Z_val = val_data[2]\n",
        "\n",
        "    #transform the arrays into torch tensors\n",
        "    train_features = torch.Tensor(X_train)  #drop unit_number and test_cycles\n",
        "    train_targets = torch.Tensor(Y_train)\n",
        "    train_cx_features = torch.Tensor(Z_train)\n",
        "\n",
        "    val_features = torch.Tensor(X_val)\n",
        "    val_targets = torch.Tensor(Y_val)\n",
        "    val_cx_features = torch.Tensor(Z_val)\n",
        "\n",
        "\n",
        "    train = TensorDataset(train_features,train_cx_features, train_targets)\n",
        "    val = TensorDataset(val_features, val_cx_features,val_targets)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n",
        "    examples = iter(train_loader)\n",
        "    samples,context,targets = examples.next()\n",
        "    print(samples.shape, context.shape,targets.shape)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9e9cad5",
      "metadata": {
        "id": "d9e9cad5"
      },
      "source": [
        "#### Seprate the train val and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78d8ea2",
      "metadata": {
        "id": "f78d8ea2",
        "outputId": "47a39d82-e982-4c35-c119-f53b8617bf33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 12, 8]) torch.Size([128, 12, 3]) torch.Size([128, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "# train_loader = []\n",
        "# val_loader = []\n",
        "\n",
        "test_data = []\n",
        "\n",
        "#for first sensor data\n",
        "X = df_X[0].copy()\n",
        "Y = df_Y[0].copy()\n",
        "Z = df_Z[0].copy()\n",
        "U = df_U[0].copy()\n",
        "\n",
        "# split the data in 70:10:20 for train:valid:test dataset\n",
        "train_size=0.7\n",
        "\n",
        "# In the first step we will split the data in training and remaining dataset\n",
        "X_train, X_rem, Y_train, Y_rem, Z_train, Z_rem, U_train, U_rem = train_test_split(X,Y,Z,U, train_size=0.7)\n",
        "\n",
        "test_size = 0.6\n",
        "X_val, X_test, Y_val, Y_test, Z_val, Z_test, U_val, U_test = train_test_split(X_rem,Y_rem, Z_rem, U_rem, test_size = 0.6)\n",
        "\n",
        "\n",
        "test_data.append((X_test,Y_test,Z_test,U_test))\n",
        "\n",
        "\n",
        "#for remaining sensor data\n",
        "for i in range(1, len(df_X)):\n",
        "\n",
        "    #prepared data: df_X, df_Y, df_Z, df_U\n",
        "\n",
        "    X = df_X[i].copy()\n",
        "    Y = df_Y[i].copy()\n",
        "    Z = df_Z[i].copy()\n",
        "    U = df_U[i].copy()\n",
        "\n",
        "    # split the data in 70:10:20 for train:valid:test dataset\n",
        "    train_size=0.7\n",
        "\n",
        "    # In the first step we will split the data in training and remaining dataset\n",
        "    X_train1, X_rem1, Y_train1, Y_rem1, Z_train1, Z_rem1, U_train1, U_rem1 = train_test_split(X,Y,Z,U, train_size=0.7)\n",
        "\n",
        "\n",
        "    test_size = 0.6\n",
        "    X_val1, X_test1, Y_val1, Y_test1, Z_val1, Z_test1, U_val1, U_test1 = train_test_split(X_rem,Y_rem, Z_rem, U_rem, test_size = 0.6)\n",
        "\n",
        "#     print(X_train.shape), print(Y_train.shape), print(Z_train.shape)\n",
        "#     print(X_val.shape), print(Y_val.shape), print(Z_val.shape)\n",
        "#     print(X_test.shape), print(Y_test.shape), print(Z_test.shape)\n",
        "\n",
        "#     train_data.append = (X_train, Y_train, Z_train)\n",
        "#     val_data.append = (X_val, Y_val, Z_val)\n",
        "\n",
        "    #combine the X, Y, Z from all the sensors for training and validation\n",
        "    X_train = np.concatenate((X_train,X_train1), axis = 0)\n",
        "    Y_train = np.concatenate((Y_train,Y_train1), axis = 0)\n",
        "    Z_train = np.concatenate((Z_train,Z_train1), axis = 0)\n",
        "\n",
        "    X_val = np.concatenate((X_val,X_val1), axis = 0)\n",
        "    Y_val = np.concatenate((Y_val,Y_val1), axis = 0)\n",
        "    Z_val = np.concatenate((Z_val,Z_val1), axis = 0)\n",
        "\n",
        "\n",
        "\n",
        "    test_data.append((X_test1,Y_test1,Z_test1,U_test1))\n",
        "\n",
        "    #train_l, val_l = dataloader_pytorch (train_data, val_data,batch_size)\n",
        "    #train_loader.append(train_l)\n",
        "    #val_loader.append(val_l)\n",
        "\n",
        "train_data = (X_train,Y_train,Z_train)\n",
        "val_data = (X_val, Y_val, Z_val)\n",
        "train_loader, val_loader = dataloader_pytorch (train_data, val_data,batch_size)\n",
        "#train_loader.append(train_l)\n",
        "#val_loader.append(val_l)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Hyperparameter Optimization using Optuna"
      ],
      "metadata": {
        "id": "Z1tvSheL3kkD"
      },
      "id": "Z1tvSheL3kkD"
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter optimization with optuna\n",
        "\n",
        "\n",
        "input_dim = df_X[0].shape[2]\n",
        "output_dim = df_Y[0].shape[2]\n",
        "context_dim = df_Z[0].shape[2]\n",
        "\n",
        "weight_decay = 1e-6\n",
        "dropout = 0.1\n",
        "n_epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "#dimensions of fully connected layer\n",
        "#fc_dim = 5\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    params1 = {\n",
        "              'input_dim':input_dim,\n",
        "              'output_dim': output_dim,\n",
        "              'context_dim': context_dim,\n",
        "              'hidden_dim':trial.suggest_int('hidden_size',10,30,5),\n",
        "              #'fc_dim': trial.suggest_int('fc_size',5,30,5),\n",
        "              }\n",
        "\n",
        "    params2 = {\n",
        "                'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
        "                'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "              }\n",
        "\n",
        "    #model = get_model('gru',params1)\n",
        "    model = ContextGRU(input_dim, params1['hidden_dim'], output_dim, context_dim, params1['fc_dim'])\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"], weight_decay=weight_decay)\n",
        "    optimizer = getattr(optim, params2['optimizer'])(model.parameters(), lr= params2['learning_rate'], weight_decay=weight_decay)\n",
        "    opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "    train_loss = opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "    opt.plot_losses()\n",
        "\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "##----------------------------------------------------------------------------------------------\n",
        "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "\n",
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))\n"
      ],
      "metadata": {
        "id": "twsmRTtW4Ygv"
      },
      "id": "twsmRTtW4Ygv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f263054",
      "metadata": {
        "id": "4f263054"
      },
      "source": [
        "## 6. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c3ad92",
      "metadata": {
        "id": "76c3ad92"
      },
      "outputs": [],
      "source": [
        "input_dim = df_X[0].shape[2]\n",
        "output_dim = df_Y[0].shape[2]\n",
        "context_dim = df_Z[0].shape[2]\n",
        "\n",
        "hidden_dim = 15\n",
        "layer_dim = 1\n",
        "batch_size = 128\n",
        "dropout = 0.2\n",
        "n_epochs = 50\n",
        "learning_rate = 0.001\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model = ContextGRU(input_dim, hidden_dim, output_dim, context_dim)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "params_list = model.parameters()\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "#optimizer = optim.Adam(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "optimizer = optim.RMSprop(params_list, lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=weight_decay)\n",
        "#optimizer = optim.SGD(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
        "opt.plot_losses()\n",
        "#opt.visualise_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb9d7563",
      "metadata": {
        "id": "cb9d7563"
      },
      "source": [
        "## Analysis of model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7ad850",
      "metadata": {
        "id": "9d7ad850"
      },
      "outputs": [],
      "source": [
        "# # Print model's state_dict\n",
        "# print(\"Model's state_dict:\")\n",
        "# for param_tensor in model.state_dict():\n",
        "#     print(param_tensor, \"\\t\", str(model.state_dict()[param_tensor].size()))\n",
        "\n",
        "wts, sets, ips = opt.visualise_weights()\n",
        "\n",
        "l = len(wts)\n",
        "wtmatrix = np.array(wts[l-1])\n",
        "fig = plt.figure(figsize=(15, 8))\n",
        "\n",
        "for i in range(6) :  #nx = 6 and m = 9\n",
        "\n",
        "    plt.subplot(2,3,i+1)\n",
        "\n",
        "    sns.heatmap(wtmatrix[:,i*9:i*9+9], cmap = 'Spectral')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fc8332",
      "metadata": {
        "id": "21fc8332"
      },
      "source": [
        "## 7. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5389658",
      "metadata": {
        "id": "c5389658"
      },
      "outputs": [],
      "source": [
        " #test_data-list of tuples (X_test,Y_test,Z_test,U_test)\n",
        "\n",
        "result_rmse = []  #list of rmse for each sensor id\n",
        "result_mae = []\n",
        "result_r2 = []\n",
        "s = 207 #number of sensors\n",
        "\n",
        "\n",
        "for i in range(0, s):\n",
        "\n",
        "#for i in range(30,31):\n",
        "\n",
        "    (X_test, Y_test, Z_test, U_test) = test_data[i]\n",
        "\n",
        "\n",
        "    test_features = torch.Tensor(X_test)\n",
        "    test_targets = torch.Tensor(Y_test)\n",
        "    test_cx_features = torch.Tensor(Z_test)\n",
        "\n",
        "    test = TensorDataset(test_features,test_cx_features, test_targets)\n",
        "    #test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
        "    test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    predictions, values = opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
        "    #flatten the multi-dimension array to 1-D array\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "\n",
        "    #Apply inverse transform\n",
        "    #reshape vals and preds as inverse transform accepts 2-D array\n",
        "\n",
        "\n",
        "    #parameters from train data statistics\n",
        "    p1 = min_val[i]\n",
        "    par1 = p1[6]   #parameter for 'AvgSpeed'  (mean/miu)\n",
        "    p2 = rng[i]\n",
        "    par2 = p2[6]  #parameter for 'AvgSpeed'  (range/sigma)\n",
        "\n",
        "\n",
        "    #denormalise the target\n",
        "    target_val = inv_trans(np.reshape(vals,(len(vals),1)), \"minmax\",par1,par2)\n",
        "    pred_val = inv_trans(np.reshape(preds,(len(preds),1)),\"minmax\",par1,par2)\n",
        "\n",
        "    #plot_results(i+1, target_val[0:200],pred_val[0:200])\n",
        "\n",
        "    result_metrics = calculate_metrics(target_val, pred_val)  #result_metrics is a dictionary\n",
        "\n",
        "    result_rmse.append(result_metrics['rmse'])\n",
        "    result_r2.append(result_metrics['r2'])\n",
        "    result_mae.append(result_metrics['mae'])\n",
        "\n",
        "\n",
        "#calculate average and std of rmse,and score\n",
        "\n",
        "avg_rmse = np.mean(result_rmse)\n",
        "std_rmse = np.std(result_rmse)\n",
        "\n",
        "avg_mae = np.mean(result_mae)\n",
        "std_mae = np.std(result_mae)\n",
        "\n",
        "print(f\"[Average RMSE: {avg_rmse:.4f}\\t Std RMSE: {std_rmse:.4f}]\")\n",
        "print(f\"[Average MAE: {avg_mae:.4f}\\t Std MAE: {std_mae:.4f}]\")\n",
        "\n",
        "\n",
        "min_rmse = min(result_rmse)\n",
        "max_rmse = max(result_rmse)\n",
        "min_mae = min(result_mae)\n",
        "max_mae = max(result_mae)\n",
        "\n",
        "print(f\"[Sensor #: {result_rmse.index(min_rmse)+1}\\t Min RMSE: {min_rmse:.4f}]\")\n",
        "print(f\"[Sensor #: {result_rmse.index(max_rmse)+1}\\t Max RMSE: {max_rmse:.4f}]\")\n",
        "print(f\"[Sensor #: {result_mae.index(min_mae)+1}\\t Min MAE: {min_mae:.4f}]\")\n",
        "print(f\"[Sensor #: {result_mae.index(max_mae)+1}\\t Max MAE: {max_mae:.4f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39340934",
      "metadata": {
        "id": "39340934",
        "outputId": "438c9c9a-2261-4def-a152-637a03c68006"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5887, 6)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "info = U_test[:,0,:]\n",
        "info.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40dab1fe",
      "metadata": {
        "id": "40dab1fe"
      },
      "outputs": [],
      "source": [
        "#combine info,target, and perd_val\n",
        "data_result = np.concatenate((info,target_val,pred_val), axis =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e346bbec",
      "metadata": {
        "id": "e346bbec"
      },
      "outputs": [],
      "source": [
        "df_result = pd.DataFrame(data_result, columns =['Year', 'Month', 'Day', 'Hour', 'Weekday', 'StationId', 'Target', 'Predicted'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0049ddfa",
      "metadata": {
        "id": "0049ddfa",
        "outputId": "6818983c-454f-47a8-d938-32404873a335"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>StationId</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>67.499992</td>\n",
              "      <td>67.720848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>68.099998</td>\n",
              "      <td>69.193779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>66.899994</td>\n",
              "      <td>67.107353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>68.017006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>67.899994</td>\n",
              "      <td>66.763290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Year  Month   Day  Hour  Weekday  StationId     Target  Predicted\n",
              "0  2012.0    3.0  20.0   4.0      1.0   773869.0  67.499992  67.720848\n",
              "1  2012.0    4.0  16.0  19.0      0.0   773869.0  68.099998  69.193779\n",
              "2  2012.0    6.0  15.0  14.0      4.0   773869.0  66.899994  67.107353\n",
              "3  2012.0    5.0  11.0  22.0      4.0   773869.0  70.000000  68.017006\n",
              "4  2012.0    4.0  19.0   8.0      3.0   773869.0  67.899994  66.763290"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_result.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3861f798",
      "metadata": {
        "id": "3861f798"
      },
      "outputs": [],
      "source": [
        "df_select_mon = df_result[df_result['Month'] == 5.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c87c66a",
      "metadata": {
        "id": "6c87c66a"
      },
      "outputs": [],
      "source": [
        "df_select_day = df_select_mon[df_select_mon['Day'] == 15.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b669b7",
      "metadata": {
        "id": "09b669b7",
        "outputId": "3c6d6ef1-4d6d-4968-aaf2-1decce00aba1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>StationId</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>65.299995</td>\n",
              "      <td>65.338074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>15.099998</td>\n",
              "      <td>12.385771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>46.100002</td>\n",
              "      <td>66.639671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>62.158409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>66.399994</td>\n",
              "      <td>65.154655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Year  Month   Day  Hour  Weekday  StationId     Target  Predicted\n",
              "178  2012.0    5.0  15.0   5.0      1.0   773869.0  65.299995  65.338074\n",
              "348  2012.0    5.0  15.0   3.0      1.0   773869.0  15.099998  12.385771\n",
              "398  2012.0    5.0  15.0   9.0      1.0   773869.0  46.100002  66.639671\n",
              "692  2012.0    5.0  15.0  12.0      1.0   773869.0  65.000000  62.158409\n",
              "893  2012.0    5.0  15.0   9.0      1.0   773869.0  66.399994  65.154655"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_select_day.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f020e057",
      "metadata": {
        "id": "f020e057"
      },
      "outputs": [],
      "source": [
        "plot_data = df_select_day.sort_values(by=['Hour'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a9731c",
      "metadata": {
        "id": "73a9731c"
      },
      "outputs": [],
      "source": [
        "plot_data.reset_index(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041c1006",
      "metadata": {
        "id": "041c1006",
        "outputId": "6f7f216b-28f7-4457-8d83-150925cd8863"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>StationId</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5572</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>66.799995</td>\n",
              "      <td>65.273506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4190</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>61.099998</td>\n",
              "      <td>62.943649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5303</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>62.299999</td>\n",
              "      <td>64.882828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4358</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>67.650780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1714</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>65.699997</td>\n",
              "      <td>66.177315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index    Year  Month   Day  Hour  Weekday  StationId     Target  Predicted\n",
              "0   5572  2012.0    5.0  15.0   1.0      1.0   773869.0  66.799995  65.273506\n",
              "1   4190  2012.0    5.0  15.0   1.0      1.0   773869.0  61.099998  62.943649\n",
              "2   5303  2012.0    5.0  15.0   2.0      1.0   773869.0  62.299999  64.882828\n",
              "3   4358  2012.0    5.0  15.0   2.0      1.0   773869.0  64.000000  67.650780\n",
              "4   1714  2012.0    5.0  15.0   2.0      1.0   773869.0  65.699997  66.177315"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f987eb6",
      "metadata": {
        "id": "6f987eb6"
      },
      "outputs": [],
      "source": [
        "plot_data.drop(columns=['index'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63584de3",
      "metadata": {
        "id": "63584de3"
      },
      "outputs": [],
      "source": [
        "plot_data.drop_duplicates(subset=['Hour'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18126383",
      "metadata": {
        "id": "18126383",
        "outputId": "150bd98b-b3c7-4dc3-f0b4-5aea68059a6e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>StationId</th>\n",
              "      <th>Target</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>66.799995</td>\n",
              "      <td>65.273506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>62.299999</td>\n",
              "      <td>64.882828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>15.099998</td>\n",
              "      <td>12.385771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>65.699997</td>\n",
              "      <td>66.747032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2012.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>773869.0</td>\n",
              "      <td>66.699997</td>\n",
              "      <td>68.316055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Year  Month   Day  Hour  Weekday  StationId     Target  Predicted\n",
              "0   2012.0    5.0  15.0   1.0      1.0   773869.0  66.799995  65.273506\n",
              "2   2012.0    5.0  15.0   2.0      1.0   773869.0  62.299999  64.882828\n",
              "5   2012.0    5.0  15.0   3.0      1.0   773869.0  15.099998  12.385771\n",
              "8   2012.0    5.0  15.0   4.0      1.0   773869.0  65.699997  66.747032\n",
              "11  2012.0    5.0  15.0   5.0      1.0   773869.0  66.699997  68.316055"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f8301e",
      "metadata": {
        "scrolled": true,
        "id": "d6f8301e"
      },
      "outputs": [],
      "source": [
        "date = '15-05-2012'\n",
        "plot_results(plot_data,date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c6e910",
      "metadata": {
        "id": "22c6e910"
      },
      "outputs": [],
      "source": [
        "#Plot the results Engine Unit wise\n",
        "def plot_results(plot_data, date):\n",
        "\n",
        "    plot_data.reset_index(inplace=True)\n",
        "    #print(plot_data)\n",
        "\n",
        "    target_val = plot_data['Target']\n",
        "    pred_val = plot_data['Predicted']\n",
        "\n",
        "    #fig = plt.figure(figsize=(14, 4))\n",
        "    fig = plt.figure()\n",
        "    ax = plt.subplot(1,2,1)\n",
        "    #plt.subplot(1,2,1)\n",
        "    plt.subplot(1,2,1).set_title(date, fontsize= 10)\n",
        "    ax.plot(target_val,'r')\n",
        "    ax.plot(pred_val,'b')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Avg. Speed (Mph)')\n",
        "    plt.legend(['Actual Avg. Speed','Predicted Avg. Speed'])\n",
        "\n",
        "    ticks = list(range(0,len(plot_data)))\n",
        "    tick_labels = plot_data['Hour']\n",
        "    ax.set_xticks(ticks[::3])\n",
        "    ax.set_xticklabels(tick_labels[::3])\n",
        "#     ax.set_xticks(ticks)\n",
        "#     ax.set_xticklabels(tick_labels)\n",
        "    ax.tick_params(axis='x')\n",
        "    plt.savefig('traffic_result.eps', format = eps, dpi=1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f129080",
      "metadata": {
        "id": "5f129080"
      },
      "source": [
        "### Calculate Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f8b7eb",
      "metadata": {
        "id": "79f8b7eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calculate_metrics(actual, predicted):\n",
        "\n",
        "    return {'mae' : mean_absolute_error(actual,predicted),\n",
        "            'rmse' : mean_squared_error(actual,predicted) ** 0.5,\n",
        "            'r2' : r2_score(actual,predicted)}\n",
        "\n",
        "# result_metrics = calculate_metrics(target_val, pred_val)\n",
        "# print(result_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41e7dee",
      "metadata": {
        "id": "c41e7dee"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}